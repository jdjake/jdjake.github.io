{"Notes/Broad-Narrow-Analysis":{"slug":"Notes/Broad-Narrow-Analysis","filePath":"Notes/Broad-Narrow Analysis.md","title":"Broad-Narrow Analysis","links":["2015---Guth---A-Restriction-Estimate-Using-Polynomial-Partitioning","1998---Tao-Vargas-Vega---A-Bilinear-ApproachT-to-the-Restriction-and-Kakeya-Conjectures"],"tags":[],"content":"Fix K &gt; 0, and divide a hypersurface \\Sigma in \\mathbb{R}^d into caps \\tau of diameter O(K^{-1}). Given a function f on \\Sigma, let g = Ef. Then a point x \\in \\mathbb{R}^d is \\alpha broad if \\max |Ef_\\tau(x)| \\leq \\alpha |Ef(x)|. If a point is not \\alpha broad, then it is \\alpha narrow, which means there is some \\tau_0 with |Ef(x)| \\leq \\alpha^{-1} |Ef_{\\tau_0}(x)|. This gives a smaller scale which can bound the current scale of analysis, so induction on scales often allows us to bound the behavior of the extension operator at narrow points, and we may thus restrict our attention to the behavior at broad points.\nMore precisely, if we define \\text{Br}_\\alpha(g) to be equal to g at broad points, and equal to zero at narrow points, then we have a pointwise bound\n |g| \\leq |\\text{Br}_\\alpha(g)| + \\alpha^{-1} \\max\\nolimits_{\\tau_0} |Ef_{\\tau_0}|\nInduction on scales bounds |Ef_{\\tau_0}| uniformly, so it suffices to estimate |\\text{Br}_\\alpha(g)|. The advantage of reducing to the broad case is that one can often reduce to multilinear estimates, given that the caps \\{ \\tau_0 \\} are suitably transverse to one another.\nIn more sophisticated contexts, it is useful to be more quantitative, especially when considering estimates closer to k-linear analysis. We define a measure \\mu = \\mu_a^p, locally constant at a scale K^2, so that for a  ball of radius K^2,\n \\mu^p(f,B) = \\min\\nolimits_{V_1,\\dots,V_a} \\max\\nolimits_{\\tau \\in \\text{Tr}(V_1,\\dots,V_a)} \\int_B |Ef_\\tau|^p\nwhere V_1,\\dots,V_a are k-dimensional subspaces, and \\text{Tr}(V_1,\\dots,V_A) is the set of caps transverse to all V_1,\\dots,V_a, more precisely, making an angle greater than 1/K with each subspace. We then define, for a set U constant at a scale K^2,\n \\| Ef \\|_{\\text{BL}_{k,a}^p(U)} = \\left( \\sum\\nolimits_{B \\subset U} \\mu^p(f,B) \\right)^{1/p}\nThe need to choose a &gt; 1 is required so that the broad norm is semi-additive and satisfies the Holder inequality. We often choose a \\sim 1. On a particular ball of radius K^2, we are only bounding those \\| Ef_{\\tau_0} \\|_{L^p(B)} for which there exists \\tau_1,\\dots,\\tau_{k-1} with \\tau_0 \\wedge \\cdots \\wedge \\tau_{k-1} \\gtrsim 1 and \\| Ef_{\\tau_i} \\|_{L^p(B)} \\gtrsim \\| Ef_\\tau \\|_{L^p(B)}. The most useful property of the broad norm is that if we are only studying tubes that are tangent to a k-1 dimensional variety, then the broad norm of Ef is essentially zero (for whenever the tubes intersect, they do so in a way that is not k transverse).\nWhen estimating the broad norm rather than the usual L^p norm, tubes that are concentrated on k-1 dimensional varieties are\nIn the multilinear case, what gets thrown out?\n\nGuth uses the method to prove his L^\\infty(\\Sigma) \\to L^p(\\mathbb{R}^3) restriction estimate for p &gt; 3.25.\nGuth states that his broad narrow analysis is similar to the bilinear restriction methods of Tao, Vargas, and Vega, but I have not looked into this paper.\n"},"Notes/Enemies-in-Multilinear-Restriction":{"slug":"Notes/Enemies-in-Multilinear-Restriction","filePath":"Notes/Enemies in Multilinear Restriction.md","title":"Enemies in Multilinear Restriction","links":["Notes/Wave-Packet-Decomposition-For-Extension"],"tags":[],"content":"A regulus S is a degree 2 algebraic surface in \\mathbb{R}^3 which is doubly ruled, i.e. there are two families of lines, which we might call horizontal and vertical, and each point lies in a horizontal line and a vertical line.\n\nPlanar Examples:\nReguli: Consider Wave Packets f = \\sum f_T, where the sum is restricted to R^{1/2} \\times R tubes taking from the ruling of S \\cap B_R, with each wave packet having the same L^2 norm. This example is sharp for some bilinear restriction estimates.\n"},"Notes/Induction-on-Scales":{"slug":"Notes/Induction-on-Scales","filePath":"Notes/Induction on Scales.md","title":"Induction on Scales","links":["2006---Bennett-Carbery-Tao---On-The-Multilinear-Restriction-And-Kakeya-Conjectures","1998---Tao-Vargas-Vega---A-Bilinear-Approach-to-the-Restriction-and-Kakeya-Conjectures"],"tags":[],"content":"Suppose C(R) is a finite quantity chosen for each integer R &gt; 0, such that, by some (hopefully trivial) argument, we can justify C(R) = R^{O(1)}. The goal of induction on scales is, by bounding C(R) in terms of C(R&#039;) for a small R&#039;, to obtain a bound C(R) \\lesssim_\\varepsilon R^\\varepsilon for all \\varepsilon &gt; 0. We write A \\lessapprox B if A \\lesssim_\\varepsilon R^\\varepsilon B for all \\varepsilon &gt; 0.\n\nIf C(R) \\lessapprox C(R^\\alpha) for some 0 &lt; \\alpha &lt; 1 and all \\varepsilon &gt; 0, and we know that C(R) \\lesssim R^{O(1)}, then induction on scales can guarantee that C(R) \\lessapprox 1. This is used, for instance in the Bennett Carbery Tao Multilinear Restriction Theorem.\nIf C(R) \\lessapprox C(R^{1 - \\delta}) + R^{O(\\delta)} for all \\delta &gt; 0, then C(R) \\lessapprox 1. This is used, for instance, in Tao Vargas Vega.\nIf C(R) \\lesssim_\\varepsilon (1 + \\varepsilon) C(R/10) then we obtain that C(R) \\lessapprox 1.\n"},"Notes/Polynomial-Partitioning":{"slug":"Notes/Polynomial-Partitioning","filePath":"Notes/Polynomial Partitioning.md","title":"Polynomial Partitioning","links":["2015---Guth-Katz---On-The-Erdos-Distinct-Distances-Problem-in-the-Plane","2008---Dvir---On-the-Size-of-Kakeya-Sets-in-Finite-Fields","1990---Clarkson-Edelsbrunner-Guibas-Sharir-Welzl---Combinatorial-Complexity-Bounds-for-Arrangements-of-Curves-and-Spheres"],"tags":[],"content":"The idea of polynomial partitioning, introduced by Guth and Katz in their 2015 Paper on the Erdos distinct distances problem, is to combine the polynomial incidence geometric methods of Dvir with the divide and conquer approaches of divide and conquer partitioning approach introduced by CEGSW in incidence geometry.\nGiven a set X \\subset \\mathbb{R}^d of N points, the polynomial method allows us to find a polynomial of degree O(N^{1/d}) vanishing on X. In polynomial partitioning, for any D, we can choose a polynomial of degree D defining a hypersurface Z, such that \\mathbb{R}^d - Z is divided into O(D^d) cells, each containing O(N/D^d) points from X. The surface Z is called the cell wall, and the connected components of \\mathbb{R}^d - Z are called the cells. The problem then breaks down into two regimes:\n\nIf X contains few points in the cell wall, it must be evenly divided into each of the cells, so methods akin to  CEGSW apply.\nIf X contains many points in the cell wall, then we obtain structural information akin to Dvir’s Method.\n\nThe problem can also be applied to continuous problems. If f is a function on \\mathbb{R}^d, then for any D we can find a hypersurface Z defined by a polynomial of degree D so that the L^1 norm of f on each cell cut out by the surface Z is the same. However, to fully exploit the polynomial structure in the continuous setting we must often thicken the cell wall, so that e.g. any ‘transverse’ tube passes through the surface Z at most D times, and thus enters at most D + 1 cells. If the tubes we are considering have thickness \\delta, then we should let the \\delta neighborhood Z_\\delta of Z be the cell wall, and let the cells be the connected components of \\mathbb{R}^d - Z_\\delta. This is because it then follows that if a tube passes through a cell of \\mathbb{R}^d - Z_\\delta, then it’s central line passes through the corresponding cell in \\mathbb{R}^d - Z, and can only do this at most D + 1 times."},"Notes/Random-Rotations-Trick":{"slug":"Notes/Random-Rotations-Trick","filePath":"Notes/Random Rotations Trick.md","title":"Random Rotations Trick","links":[],"tags":[],"content":""},"Notes/Shadings":{"slug":"Notes/Shadings","filePath":"Notes/Shadings.md","title":"Shadings","links":["Notes/We-Can-Remove-Exceptional-Sets-From-Lp-Estimates","Notes/Random-Rotations-Trick","Problem-Statements/The-Kakeya-Maximal-Inequality"],"tags":[],"content":"Suppose we have a family of subsets \\mathbb{A} in \\mathbb{R}^n, with |A| \\sim V for each A \\in \\mathbb{A}. Suppose we are trying to prove an inequality\n\\left\\| \\sum\\nolimits_{A \\in \\mathbb{A}} 1_A \\right\\|_{L^p(\\mathbb{R}^n)} \\lesssim C. \\tag{1}\nBy real interpolation, (1) is roughly equivalent to a restricted bound of the form\n\\sum |A \\cap X| \\leq C |X|^{1/d}, \\tag{2}\nwhere d = p&#039;. By dyadic pigeonholing, we may find \\mathbb{A}&#039; \\subset \\mathbb{A} and \\lambda \\in (0,1) so that |A \\cap X| \\sim \\lambda |A| for each A \\in \\mathbb{A}&#039;, and such that \\sum_{A \\in \\mathbb{A}} |A \\cap X| \\approx \\sum_{A \\in \\mathbb{A}&#039;} |A \\cap X|. Normally we have \\# \\mathbb{A} \\lesssim V^{-1}, so that M = (\\# (\\mathbb{A}&#039;) V)^{-1} is large. Then, rearranging, we find (2) is equivalent to\n|X| \\gtrapprox \\left( \\lambda / CM \\right)^d. \\tag{3}\nWe can state this process in the language of shadings. For each A \\in \\mathbb{A}, we pick X(A) \\subset A so that X(A) \\sim \\lambda |A| for each A. Such a choice is called a \\lambda-shading. The L^p inequality we wished to prove above is equivalent to proving that for any subset \\mathbb{A}&#039; of \\mathbb{A}, and any \\lambda-shading of \\mathbb{A}&#039;, the set X = \\bigcup X(A) satisfies |X| \\gtrapprox (\\lambda / CM)^d. Thus we see that upper bounds on L^p sum of indicator functions are roughly equivalent to lower bounding the size of shadings, which is a Kakeya type problem.\nThe Generic Multiplicity of Shadings\nSuppose that each set in \\mathbb{A} is \\delta-discretized (roughly speaking, a union of \\delta balls). For each \\delta ball Q, let M(Q) denote the number of sets in \\mathbb{A} containing Q. Then Markov’s inequality, applied to (1), implies that\n\\# \\{ Q : M(Q) \\geq M_0 \\} \\leq \\delta^{-n} C^p / M_0^p. \\tag{4}\nIf X is a \\delta-discretized \\lambda-shading of \\mathbb{A}&#039;, then (3) implies that X contains at least \\delta^{-n} (\\lambda / CM)^d balls of radius \\lambda. So (3) and (4) together imply that at least half the cubes in X have multiplicity at most O( C^d (M/\\lambda)^{d - 1} ). Conversely, if (3) and (4) hold, then we can obtain inequalities of the form (1) because We Can Remove Exceptional Sets From Lp Estimates.\nThe Special Case of Tubes\nIn the special case where we are studying the Kakeya inequality, \\mathbb{A} is a family of direction separated \\delta-tubes, V = \\delta^{1-n}, and C = \\delta^{1 - n/d}, The Random Rotations Trick allows us to assume that M \\sim 1, so the The Kakeya Maximal Inequality is roughly equivalent to prove that for any family \\mathbb{T} of \\sim \\delta^{1-n} direction separated \\delta tubes, and any \\lambda-shading X of \\mathbb{T}, |X| \\gtrapprox \\lambda^d \\delta^{n-d}. In particular, at least half the cubes in any \\lambda-shading of \\mathbb{T} must have multiplicity at most O(\\delta^{d - n} \\lambda^{1-d}).\nGeometric Means\nSuppose we have proved\n\\left\\| \\left( \\sum\\nolimits_{A_1 \\in \\mathbb{A}, \\dots, A_k \\in \\mathbb{A}_k} 1_{A_1} \\cdots 1_{A_k} \\right)^{1/k} \\right\\|_{L^p(\\mathbb{R}^n)} \\lesssim C. \\tag{1}\nwhere \\mathbb{A}_1,\\dots, \\mathbb{A}_k are families of \\delta discretized sets. The analogous weak bound is that if we let M_i(Q) denote the number of elements of \\mathbb{A}_i which contain a \\delta ball Q, then for any \\delta discretized set X,\n\\sum\\nolimits_{Q \\subset X} [M_1(Q) \\cdots M_k(Q)]^{1/k} \\lesssim C.\nPigeonholing, we may assume that X is a \\lambda-shading of the set of intersections\n\\mathbb{A} = \\{ A_1 \\cap \\cdots \\cap A_k : A_1 \\in \\mathbb{A}_1, \\dots, A_k \\in \\mathbb{A}_k \\}."},"Notes/The-Polynomial-Wolff-Axioms":{"slug":"Notes/The-Polynomial-Wolff-Axioms","filePath":"Notes/The Polynomial Wolff Axioms.md","title":"The Polynomial Wolff Axioms","links":["2024-12-HongWangShukunWu-RestrictionEstimatesUsingDecouplingTheoremsAndTwoEndsFurstenbergInequalities.pdf"],"tags":[],"content":"A set of \\delta-tubes \\mathbb{T} satisfy the Polynomial Wolff axioms if, for any semi-algebraic set S,\n\\# \\{ T \\in \\mathbb{T}: |T \\cap S| \\geq \\lambda |T| \\} \\lesssim |S| \\delta^{1-n} \\lambda^{-n} \\tag{1}\nwhere the implicit constants depend only on the complexity of the semi-algebraic set S. Guth, Zahl, Katz, and Rogers proved that a family of tubes pointing in a \\delta-separated family of directions satisfy the Polynomial Wolff Axioms.\nLet us say a tube T is tangent to a \\delta neighborhood S of an algebraic surface \\Sigma if |T \\cap S| \\geq 0.1 |T|. Since |S|  \\lesssim \\delta the Polynomial Wolff Axioms tell us that at most O(\\delta^{2-n}) tubes in \\mathbb{T} are tangent to the surface. If \\mathbb{T} are \\delta separated, we can have \\#(\\mathbb{T}) \\sim \\delta^{1-n}, and so the Polynomial Wolff Axioms tell us most of the tubes in \\mathbb{T} are not tangent to S.\nSuppose \\mathbb{T} contains at most m tubes in each direction. A natural question is to understand how (1) may be quantified in terms of m - this may have applications to restriction theory, e.g. to the methods of Wang and Wu."},"Notes/Wave-Packet-Decomposition-For-Extension":{"slug":"Notes/Wave-Packet-Decomposition-For-Extension","filePath":"Notes/Wave Packet Decomposition For Extension.md","title":"Wave Packet Decomposition For Extension","links":["1991---Bourgain---Besicovitch-Type-Multiplier-Operators-And-Applications-To-Fourier-Analysis","1969-Fefferman-InequalitiesForStronglySingularConvolutionOperators","1982---Cordoba---Geometric-Fourier-Analysis","1991---Seeger-Sogge-Stein---Regularity-Properties-of-Fourier-Integral-Operators"],"tags":[],"content":"Given any function f supported on a compact neighborhood of a curved hypersurface \\Sigma, and each R &gt; 0, we can break \\Sigma down finitely overlapping caps \\Theta, each having dimensions R^{-1/2} tangent to \\Sigma, and dimension R^{-1} in the normal direction to \\Sigma. If, for each \\theta \\in \\Theta, we consider a family of tubes \\mathbb{T}(\\theta) pointing in the normal direction to the cap, with dimensions R^{1/2} by R, and then write \\mathbb{T} = \\bigcup \\mathbb{T}(\\theta), then we have an orthogonal decomposition f = \\sum f_T, where for T \\in \\mathbb{T}(\\theta) the following is true:\n\nf_T is supported on \\theta.\nFor x \\in B_R, E_\\Sigma f_T(x) \\approx a_T \\chi_T e^{2 \\pi i \\omega_\\theta x}, where \\omega_\\theta is the center of \\theta, |a_T| \\sim R^{-1/2} \\| f_T \\|_{L^2(\\Sigma)}., and \\chi_T is smooth and adapted to T. In particular, \\| E_\\Sigma f_T \\|_{L^2(B_R)} \\sim R^{1/2} \\| f_T \\|_{L^2(\\Sigma)}.\nThe functions E f_T are locally orthogonal on balls of radius R^{1/2}. That is, for any ball B of radius at least R^{1/2}, \\| Ef \\|_{L^2(B)} \\approx \\sum \\| Ef_T \\|_{L^2(B)}^2.\n\nThe method was widely brought to the attention by Bourgain’s use of the result in a 1991 paper (some claim he introduced the method, though it is also in use by Fefferman and Cordoba in their work on the restriction problem), and is highly similar to the second dyadic decomposition introduced in 1991 by Seeger, Sogge and Stein to analyze Fourier Integral Operators."},"Notes/We-Can-Remove-Exceptional-Sets-From-Lp-Estimates":{"slug":"Notes/We-Can-Remove-Exceptional-Sets-From-Lp-Estimates","filePath":"Notes/We Can Remove Exceptional Sets From Lp Estimates.md","title":"We Can Remove Exceptional Sets From Lp Estimates","links":[],"tags":[],"content":"Suppose X_0 has finite measure, and we have to prove an inequality of the form\n\\| f \\|_{L^p(X_0)} \\lesssim C. \\tag{1}\nEquation (1) is almost equivalent to proving that for any subset X of X_0, there exists E \\subset X with |E \\cap X| \\leq 1/2 so that\n\\| f \\|_{L^p(X - E)} \\lesssim C |X|^{1/p&#039;}. \\tag{2}\nCertainly (1) implies (2) by Hölder’s inequality. Conversely, if (2) holds, then we may find E_1 so that if X_1 = X_0 - E_1, then\n\\| f \\|_{L^p(X_1)} \\lesssim C |X|^{1/p&#039;}. \\tag{3}\nIterating, for each n \\geq 1, we can apply (2) with X = X_n to find E_n \\subset X_n so that if X_{n+1} = X_n - E_n,\n\\| f \\|_{L^p(X_{n+1})} \\lesssim C |X_n|^{1/p} \\lesssim 2^{-n/p} C |X_0|^{1/p&#039;}. \\tag{4}\nApplying the triangle inequality, since X - \\bigcup X_n is measure zero, we find\n\\| f \\|_{L^p(X)} \\leq \\sum_n \\| f \\|_{L^p(X_n)} \\lesssim \\sum 2^{-n/p} C |X_0|^{1/p&#039;} \\lesssim C |X_0|^{1/p&#039;}. \\tag{5}"},"Problem-Statements/Generalization-of-Decoupling-and-Restricted-Decoupling":{"slug":"Problem-Statements/Generalization-of-Decoupling-and-Restricted-Decoupling","filePath":"Problem Statements/Generalization of Decoupling and Restricted Decoupling.md","title":"Generalization of Decoupling and Restricted Decoupling","links":[],"tags":[],"content":"During a talk, Tony Carbery proposed the following result, which generalizes decoupling and restricted decoupling. It states that\n\\int_{B_R} |Eg|^2 w \\lessapprox \\sum\\nolimits_\\nu \\sum\\nolimits_{T \\perp S_\\nu} \\| g_T \\|_{L^2}^2 w_T^\\nu,\nwhere w_T^\\nu = w^{\\frac{n+1}{2}}(T)^{\\frac{2}{n+1}}."},"Problem-Statements/The-Kakeya-Maximal-Inequality":{"slug":"Problem-Statements/The-Kakeya-Maximal-Inequality","filePath":"Problem Statements/The Kakeya Maximal Inequality.md","title":"The Kakeya Maximal Inequality","links":[],"tags":[],"content":"The Kakeya maximal conjecture states that for a family \\mathbb{T} of \\delta-tubes which are direction separated, then for 0 \\leq d \\leq n,\n \\left\\| \\sum 1_T \\right\\|_{L^{\\frac{d}{d-1}}(\\mathbb{R}^n)} \\lessapprox \\delta^{1-n/d}."},"Problem-Statements/The-Multilinear-Restriction-Conjecture":{"slug":"Problem-Statements/The-Multilinear-Restriction-Conjecture","filePath":"Problem Statements/The Multilinear Restriction Conjecture.md","title":"The Multilinear Restriction Conjecture","links":["2003---Tao---A-Sharp-Bilinear-Restriction-Estimate-for-Paraboloids-1","2006-BennettCarberyTao-OnTheMultilinearRestrictionAndKakeyaConjectures","Harmonic-Analysis/Multilinear-Methods-in-Restriction-Theory/2022---Bejenaru---The-Almost-Optimal-Multilinear-Restriction-Estimate-For-Hypersurfaces-With-Curvature","2011---Bourgain-Guth---Bounds-on-Oscillatory-Integrals-Using-Multilinear-Estimates","Harmonic-Analysis/Polynomial-Methods-in-Restriction-Theory/2018---Guth---Restriction-Estimates-Using-Polynomial-Partitioning-2","2006---Bennett-Carbery-Tao---On-The-Multilinear-Restriction-And-Kakeya-Conjectures"],"tags":[],"content":"The restriction conjecture states that for 2d/(d-1) &lt; q &lt; \\infty and  1 - \\left( \\frac{d+1}{d-1} \\right) (1/q) \\geq 1/p,\n\\| Ef \\|_{L^q(\\mathbb{R}^d)} \\lesssim \\| f \\|_{L^p(\\Sigma)}.\nThe multilinear restriction conjectures says that for 2 \\leq k \\leq n, if f_1,\\dots,f_k are restricted to transverse subsets of \\Sigma, then for q &gt; 2(d+k)/(d+k-2),\n\\left\\| \\prod\\nolimits_j |Ef_j|^{1/k} \\right\\|_{L^q(B_R)} \\lessapprox \\prod\\nolimits_j \\| f_j \\|_{L^2(\\Sigma)}.\n\nThe case k = 1 is essentially the Stein-Tomas theorem (but the exponents are not sharp).\nThe conjecture has been proved for k = 2 by Tao.\nThe conjecture has been proved for k = n by Bennett, Carbery, and Tao.\nThe conjecture has been proved for k = n-1 by Bejenaru.\n\nThe methods of Bourgain and Guth show that multilinear estimates for the restriction conjecture imply some restriction estimates. In particular, if the multilinear restriction conjecture was established, then it would imply the results of Guth, who was able to get around using multilinear estimates by using the broad norms.\n\nApparently, the methods of Bennett, Carbery, and Tao imply the result is true for p &gt; 2/(k-1).\nJennifer Duncan has claimed in talks to prove the result for p &gt; 2(k+1)/k.\n"},"Proof-Attempts/Multilinear-Restriction-Using-Wang-Wu-Refined-Decoupling":{"slug":"Proof-Attempts/Multilinear-Restriction-Using-Wang-Wu-Refined-Decoupling","filePath":"Proof Attempts/Multilinear Restriction Using Wang-Wu Refined Decoupling.md","title":"Multilinear Restriction Using Wang-Wu Refined Decoupling","links":["Notes/Broad-Narrow-Analysis","Notes/Random-Rotations-Trick","2015---Guth---A-Restriction-Estimate-Using-Polynomial-Partioning"],"tags":[],"content":"Setup\nJust to simplify things, let’s focus first on bilinear restriction. Define\nT(f,g) = |E f|^{1/2} |E g|^{1/2}. \\tag{1}\nOur goal is to prove an estimate of the form\n\\| T(f,g) \\|_{L^q(B_R)} \\lessapprox \\| f \\|_{L^2(\\Sigma)}^{1/2} \\| g \\|_{L^2(\\Sigma)}^{1/2}. \\tag{2}\nfor q &gt; 2 + 4/n.\nWe may need to split (2) into an inequality involving a decomposition of f and g into caps of sidelength K = O(1), but I’m not sure how necessary this is in the multilinear setting as compared to the Broad Norm setting.\nBy pigeonholing, we may assume in (2) that\n\nThe L^2 norms of all of the wave packets \\{ f_T \\} and \\{ g_T \\} are proportional.\nFor each cap \\theta for which f_\\theta \\neq 0, the number \\mu(\\theta) = \\# \\{ T \\in \\mathbb{T}_\\theta \\} of tubes associated with each cap are proportional to some common constant \\mu. Similarly, for each \\theta&#039; for which g_{\\theta&#039;} \\neq 0 we assume that \\mu(\\theta&#039;) \\sim \\mu&#039;.\nBy homogeneity, we may assume that \\| f_\\theta \\|_{L^2} \\leq 1 for all \\theta.\n\nBy the Random Rotations Trick, we might be able to make the simplifying assumption that \\mu \\sim \\mu&#039;, but I am not sure about this.\nLet C(R,E) denote the smallest constant so that for any functions f and g with the property that \\| f_\\theta \\|_{L^2(\\Sigma)} \\sim 1 and \\| g_{\\theta&#039;} \\|_{L^2(\\Sigma)} \\sim 1 for all R^{-1/2} caps \\theta and \\theta&#039; where f_\\theta \\neq 0 and g_{\\theta&#039;} \\neq 0, and with E(f,g) \\leq E, Equation (6) holds with implicit constant C(R,E). By Hölder’s inequality, local constancy and L^2 bounds,\n\\begin{aligned}\n\\| T(f,g) \\|_{L^q(B_R)} &amp;\\leq \\| E f \\|_{L^q(B_R)} \\| Eg \\|_{L^q(B_R)}\\\\\n&amp;\\lesssim \\| Ef \\|_{L^2(B_R)} \\| Eg \\|_{L^2(B_R)}\\\\\n&amp;\\lesssim R \\| f \\|_{L^2(\\Sigma)} \\| g \\|_{L^2(\\Sigma)}.\n\\end{aligned} \\tag{7}\nThus C(R,E) \\lesssim R. Conversely, if E \\leq 1/10, then any f and g satisfying the assumptions of the definition of C(R,E) are equal to zero since e.g. if f_\\theta \\neq 0 and g_\\theta \\neq 0 then\n\\| f \\|_{L^2(\\Sigma)} \\geq \\| f_\\theta \\|_{L^2(\\Sigma)} \\sim 1 \\quad\\text{and}\\quad \\| g \\|_{L^2(\\Sigma)} \\geq \\| g_\\theta \\|_{L^2(\\Sigma)} \\sim 1,\nso E(f,g) \\gtrsim 1. Thus C(R,E) = 0 if E \\leq 1/10.\nAn Alternate Inductive Setup\nWe might need to set\nE(f,g) = \\left( \\sum\\nolimits_{\\tau,\\tau&#039;} \\| T(f_\\tau, g_{\\tau&#039;}) \\|_{L^2(\\Sigma)}^4 \\right)^{1/4}. \\tag{3}\nOur goal would then be to show a bound of the form\n\\| T(f,g) \\|_{L^q(B_{R})} \\lessapprox R^{-1/2} E(f,g) \\tag{4}\nHölder’s inequality and L^2 bounds then imply bilinear restriction. But for now, let’s set\nE(f,g) = \\| f \\|_{L^2(\\Sigma)} \\| g \\|_{L^2(\\Sigma)}, \\tag{5}\nand try and prove\n\\| T(f,g) \\|_{L^q(B_{R})} \\lessapprox E(f,g), \\tag{6}\nwhich is precisely the multilinear bound we hope to obtain.\nBreaking Up Into Cases\nOur goal will be use induction on scales to either solve the problem.\nFor a given R and E, Pick f and g so that\n\\| T(f,g) \\|_{L^q(B_R)} \\approx C(R,E) E. \\tag{8}\nConsider a non-singular algebraic hypersurface Z of degree D which cuts \\mathbb{R}^n into \\Theta(D^n) cells, such that for any two cells O and O&#039;,\n\\| T(f,g) \\|_{L^q(O \\cap B_R)} = \\| T(f,g) \\|_{L^q(O&#039; \\cap B_R)}. \\tag{9}\nLet W be the R^{-1/2} neighborhood of Z, and define O^\\circ = O - W and let W_{O} = O - O^\\circ. We have\n\\| T(f,g) \\|_{L^q(B_R)} = \\left( \\sum \\| T(f,g) \\|_{L^q(O)}^q \\right)^{1/q} = \\left( \\sum \\| T(f,g) \\|_{L^q(O^\\circ)}^q + \\| T(f,g) \\|_{L^q(W_{O})}^q \\right)^{1/q}. \\tag{10}\nThe Cellular Case\nWe say we are in the cellular case if\n\\sum \\| T(f,g) \\|_{L^q(O^\\circ)}^q \\geq \\sum \\| T(f,g) \\|_{L^q(W_{O})}^q. \\tag{11}\nThen\n\nSuppose there are N cells, and let A = \\| T(f,g) \\|_{L^q(B_R)}. Then \\| T(f,g) \\|_{L^q(O)} \\sim A N^{-1/q} for each cell O. If we suppose \\| T(f,g) \\|_{L^q(O)} \\leq 2 A N^{-1/q} for each cell, and we let B be the number of cells O such that \\| T(f,g) \\|_{L^q(O^\\circ)} \\leq (1/10) AN^{-1/q}, then we conclude that\n\\begin{aligned}\nA &amp;\\leq 2^{1/q} \\left( \\sum \\| T(f,g) \\|_{L^q(O^\\circ)}^q \\right)^{1/q}\\\\\n&amp;\\leq 2^{1/q} \\left( B (1/10) A^q N^{-1} + 2 (N - B) A^q N^{-1} \\right)^{1/q}\\\\\n&amp;= 2^{1/q} A N^{-1/q}( 2N - 1.9B )^{1/q}\n\\end{aligned} \\tag{13}\nRearranging gives 2N - 1.9B \\geq N/2, or B \\leq 0.8N.\nSince there are \\Theta(D^n) cells, we can find a subfamily \\mathcal{O} with \\#(\\mathcal{O}) \\sim D^n and for O \\in \\mathcal{O},\n\\| T(f,g) \\|_{L^q(O^\\circ)} \\geq (1/10) AN^{-1/q}.\nIt thus follows that for each O \\in \\mathcal{O},\n\\| T(f,g) \\|_{L^q(B_R)} \\lesssim D^{n/q} \\| T(f,g) \\|_{L^q(\\mathcal{O}^\\circ)}. \\tag{14}\nFor each cell O \\in \\mathcal{O}, define f_O to be the sum of wave packets over tubes that pass through O^\\circ Since a tube can only pass through the interior of D + 1 cells, it follows that\n\\sum\\nolimits_{O} E(f_{O},g_{O}) \\lesssim D E(f,g). \\tag{15}\nSince \\mathcal{O} contains \\Theta(D^n) cells, it follows by the pigeonhole principle that there is some O with\nE(f_{O},g_{O}) \\lesssim D^{1-n} E(f,g). \\tag{16}\nThus the energy in this cell is much smaller than the energy associated with f and g if we choose D to be large. So it makes sense to apply induction, i.e. concluding that\n\\begin{aligned} \\| T(f,g) \\|_{L^q(B_R)} &amp;\\lesssim D^{n/q} \\| T(f,g) \\|_{L^q(\\mathcal{O}^\\circ)}\\\\\n&amp;=  D^{n/q} \\| T(f_O,g_O) \\|_{L^q(\\mathcal{O}^\\circ)}\\\\\n&amp;\\leq D^{n/q} R^{-1/2} C(R,D^{1-n} E) E(f_O,g_O)\\\\\n&amp;\\lesssim D^{n/q + 1 -n} R^{-1/2} C(R,D^{1-n} E) E(f,g).\\end{aligned} \\tag{17}\nSince \\| T(f,g) \\|_{L^q(B_R)} \\sim C(R,E) E, we can rearrange this inequality to read that\nC(R,E) \\lesssim D^{n/q + 1 - n} C(R, D^{1-n} E). \\tag{18}\nProvided that n/q + 1 - n &lt; 0, i.e. q &gt; n/(n-1), this is likely strong enough to obtain the required inequality if we pick D \\gg 1 to kill any of the implicit constants arising from iterating induction on scales. It turns out that choosing D = R^\\varepsilon will suffice for some \\varepsilon &gt; 0 will suffice.\nThe Algebraic Case\nIf we are not in the tangential case, then it follows that\n\\| T(f,g) \\|_{L^q(O \\cap W \\cap B_R)} \\geq (1/2) \\| T(f,g) \\|_{L^q(O \\cap B_R)}. \\tag{19}\nWe call this the algebraic case. The case where the behavior of f and g on W are both dominated by transverse intersections and tangential intersections is likely simple to deal with using the method of Guth, so we focus now on the case that the L^q behavior of f and g on W is dominated by the behaviour when f is transverse to W, and g is tangential.\nThe Transverse-Tangential Case\nSuppose that f consists only of transverse tubes to the wall W, and g consists only of tangential tubes to the wall W. For simplicity, assume that the wall behaves like a hyperplane in most respects aside from those relating to the degree of the surface.\nBy pigeonholing, we may assume that all of the tubes in f make an angle \\sim R^{\\alpha - 1/2} with the wall for some \\alpha \\leq 1/2. It then follows that all the wave packets in f are concentrated in a ball of radius R^{\\alpha - 1/2}. and thus f is locally constant at a scale R^{1/2 - \\alpha}. Moreover, the intersections of the tubes in f are tubes of dimension R^{1/2} \\times R^{1-\\alpha}.\nOn the other hand, since g is tangent, all the wave packets of g are concentrated in a ball of radius R^{-1/2}, so g is locally constant at a scale R^{1/2}, which is the thickness of the wall W.\nThe more transverse the tubes of f are, the less transverse equidistribution holds, but the more shortening occurs. The less transverse, the more transverse equidistribution holds, but the less shortening occurs. Hopefully we can make some tradeoff between shortening and equidistribution to obtain an efficient bound.\nIt is likely true that we do not want to reduce to analysis on some translation of Z, since the exponents in refined decoupling are better the higher the dimension we are working in. So perhaps there is a different way to exploit equidistribution without having to work in the lower dimensional variety.\nBecause the tubes in the decomposition of f are cut in length, for each tube T we obtain a bound\n\\| Ef_T \\|_{L^2(Z)} \\lesssim R^{1/2 - \\alpha} \\| f_T \\|_{L^2(\\Sigma)}.\nWe can then obtain a more efficient L^2 bound\n\\| T(f,g) \\|_{L^2(W)} \\lesssim R^{1 - \\alpha} \\| f \\|_{L^2(\\Sigma)} \\| g \\|_{L^2(\\Sigma)}\nWe hope to interpolate this with a more efficient L^{q_D} bound where q_D = 2 + 4/(n-1) is the dual Stein-Tomas exponent / decoupling exponent in \\mathbb{R}^d. In order to obtain efficient bounds in L^q for q &gt; 2(n + 2)/n, we need to obtain a bound of the form\n\\| T(f,g) \\|_{L^{q_D}(W)} \\lesssim R^{-\\beta} \\| f \\|_{L^2(\\Sigma)} \\| g \\|_{L^2(\\Sigma)},\nwhere\n\\beta \\geq \\frac{1 - \\alpha}{1/2 - 1/q} \\left( \\frac{1}{q} - \\frac{1}{2} \\frac{n-1}{n+1} \\right).\nFor the full range q &gt; 2 + 4/n, we must obtain that\n\\beta \\geq \\frac{1 - \\alpha}{n+1}\nTo obtain these bounds, we hope to apply the multilinear Kakeya inequality.\nTo simplify a first hash at the analysis, let us assume that \\alpha \\sim 1/2, i.e. where tubes intersect completely transversally. Assume f and g have \\sim m_1 and \\sim m_2 tubes in each of their directions. Let’s suppose that we have an inequality of the form\n \\left\\| \\left( \\sum \\chi_T \\chi_{T&#039;} \\right)^{1/2} \\right\\|_{L^{\\frac{n}{n-1}}(\\mathbb{R}^n)} \\lessapprox R^{(1 - \\kappa) \\frac{n-1}{2}} \\#(\\mathbb{T})^{\\kappa/2} \\#(\\mathbb{T}&#039;)^{\\kappa/2}. \\tag{MLK}\nfor direction separated families of transverse tubes. If, for a R^{1/2} ball Q, we define M(Q) to be the number of pairs of tubes T and T&#039; such that T \\cap T&#039; contain Q, then the Markov inequality\n\\# \\{ Q : M(Q) \\geq M_0 \\} \\lesssim R^{- (\\kappa/2) n} \\#(\\mathbb{T})^{(\\kappa/2) \\left( \\frac{n}{n-1} \\right)} \\#(\\mathbb{T}&#039;)^{(\\kappa/2) \\left( \\frac{n}{n-1} \\right)} M_0^{- \\frac{1}{2} \\left( \\frac{n}{n-1} \\right)}\nholds.\nNow suppose X is a union of N cubes from the set \\mathbb{A}. If f has m_1 tubes in each direction, and g has m_2 tubes in each direction, and we set m = m_1m_2, then the Markov inequality above implies that a generic cube in X has multiplicity\nO \\left(  m^{2 \\left( \\frac{n-1}{n} \\right)} R^{- \\kappa (n-1)} \\#(\\mathbb{T})^{\\kappa} \\#(\\mathbb{T}&#039;)^{\\kappa} N^{-2 \\left( \\frac{n-1}{n} \\right)} \\right)\nGiven an R^{1/2} discretized subset X of the support of T(f,g), if we can prove that each ball in X intersects at most M_1 tubes in f, and at most M_2 tubes in g, where M_1 M_2 \\lesssim M, and that f has m_1 tubes in each direction, and g has m_2 tubes in each direction, where m_1m_2 \\sim m, then simply by Hölder’s inequality and refined we conclude that\n \\| T(f,g) \\|_{L^{q_D}(X)} \\lesssim (M/m)^{\\frac{1}{n+1}} R^{- \\frac{1}{2} \\frac{n-1}{n+1}} \\| f \\|_{L^{q_D}(\\Sigma)} \\| g \\|_{L^{q_D}(\\Sigma)}\nIf we could guarantee that M/m \\lesssim R^{\\frac{n+1}{2} - \\alpha}, then this would complete the argument. In particular\n\nIn the completely transverse case \\alpha \\sim 1/2, we must prove M/m \\lesssim R^{n/2}.\nIn the least transverse case \\alpha \\sim 0, we must prove that M/m \\lesssim R^{\\frac{n+1}{2}}.\n\nHowever, in the argument above, we only have M \\lesssim m^{2 \\left( \\frac{n-1}{n} \\right)} R^{- \\kappa (n-1)} \\#(\\mathbb{T})^{\\kappa} \\#(\\mathbb{T}&#039;)^{\\kappa} N^{-2 \\left( \\frac{n-1}{n} \\right)}, which doesn’t seem to be the right numerology to obtain the right bounds."},"index":{"slug":"index","filePath":"index.md","title":"Multilinear Restriction","links":[],"tags":[],"content":"These are some quick notes taken to summarize progress on obtaining new estimates for multilinear restriction, potentially using the methods of Wang and Wu."}}