{"index":{"slug":"index","filePath":"index.md","title":"Multilinear Restriction","links":[],"tags":[],"content":"These are some quick notes taken to summarize progress on obtaining new estimates for multilinear restriction, potentially using the methods of Wang and Wu."},"Multilinear-Restriction-Project/An-Induction-On-Scales-Approach-To-Mixed-Norm-Bounds-Exploiting-Transversality":{"slug":"Multilinear-Restriction-Project/An-Induction-On-Scales-Approach-To-Mixed-Norm-Bounds-Exploiting-Transversality","filePath":"Multilinear Restriction Project/An Induction On Scales Approach To Mixed Norm Bounds Exploiting Transversality.md","title":"An Induction On Scales Approach To Mixed Norm Bounds Exploiting Transversality","links":[],"tags":[],"content":"Setup\nWe use the variables x, y, z, and u to denote points in \\mathbb{R}^n, \\mathbb{R}^k, \\mathbb{R}^{n-k}, and \\mathbb{R}^{k-1} respectively, and use the variables \\xi, \\eta, \\zeta, and \\upsilon to denote the dual variables in these spaces.\nFor each j, let \\pi_j: \\mathbb{R}^n \\to \\mathbb{R}^{n-1} be the projection operator given by forgetting the jth coordinate of a vector. Then consider hyper surfaces \\Sigma_1, \\dots, \\Sigma_k in \\mathbb{R}^n given by the equation \\zeta_j = \\phi_j(\\pi_j(\\zeta)), where \\phi_j: \\mathbb{R}^{n-1} \\to \\mathbb{R} is a smooth function with \\phi_j(0) = 0 and \\nabla \\phi_j(0) = 0. Then define the parameterization \\Sigma_j: \\mathbb{R}^{n-1} \\to \\mathbb{R}^n of \\Sigma_j given by the map\n\\Sigma_j(\\upsilon,\\eta) = (\\upsilon_1,\\dots,\\upsilon_{j-1}, \\phi_j(\\upsilon,\\eta), \\upsilon_j, \\dots, \\upsilon_{k-1}, \\eta).\nConsequently, we define the extension operators\n\\mathcal{E}_j f(z) = \\int_{\\mathbb{R}^{n-1}} e^{2 \\pi i [\\Sigma_j(\\upsilon,\\eta) \\cdot z]} a_j(\\upsilon,\\eta) f(\\upsilon,\\eta)\\; d\\upsilon\\; d\\eta.\nwhere the \\{ a_j \\} are functions that are smooth and compactly supported.\nA Mixed Norm Estimate\nLet p = \\tfrac{2k}{k-1}, and define I_R = [-R,R]^k. We will prove that\n\\left\\| \\prod\\nolimits_j | \\mathcal{E}_j f_j |^{1/k} \\right\\|_{L^p_x(I_R) L^2_y(\\mathbb{R}^{n-k})} \\lesssim_\\varepsilon R^\\varepsilon \\prod\\nolimits_j \\| f_j \\|_{L^2(\\mathbb{R}^{n-1})}^{1/k}\nActually, we can prove a slightly stronger identity where we bring the 1/k outside of the y integral, i.e. we can prove\n\\left\\| \\prod\\nolimits_j \\| \\mathcal{E}_j f_j \\|_{L^2_y(\\mathbb{R}^{n-k})}^{1/k} \\right\\|_{L^p_x(I_R)} \\lesssim_\\varepsilon R^\\varepsilon \\prod\\nolimits_j \\| f_j \\|_{L^2(\\mathbb{R}^{n-1})}^{1/k}\nBy a translation and localization argument, given any \\varepsilon &gt; 0, it suffices to prove without loss of generality that the functions \\{ a_j \\} which define the extension operators are smooth and adapted to an arbitrarily small ball around the origin. In particular, we will assume that for each j, the inequality |\\nabla \\phi_j| \\leq \\delta holds on the support of a_j, for some fixed, very small constant \\delta, which we will eventually choose depending on \\varepsilon. In particular, we can do this by assuming a_j is supported on a ball of radius O(\\delta), where the implicit constant depends on the second derivatives of the functions \\{ \\phi_j \\}.\nTo prove the identity under this small support assumption, we use an induction on scales argument. Let C(R) be the best possible constant such that\n\\left\\| \\prod\\nolimits_j \\| \\mathcal{E}_j f_j \\|_{L^2_y(\\mathbb{R}^{n-k})}^{1/k} \\right\\|_{L^p_x(I_R)} \\leq C(R) \\prod\\nolimits_j \\| f_j \\|_{L^2(\\mathbb{R}^{n-1})}^{1/k}\nWe will show that C(R) \\lesssim_\\varepsilon R^\\varepsilon for all \\varepsilon &gt; 0. We will assume without loss of generality that the functions \\{ f_j \\} to which we are applying the inequality have support contained in the support of the functions \\{ a_j \\}.\nThe Base Case of the Induction\nCauchy-Schwartz implies that\n\\left\\| \\prod\\nolimits_j \\| \\mathcal{E}_j f_j \\|_{L^2_y(\\mathbb{R}^{n-k})}^{1/k} \\right\\|_{L^p_x(I_R)} \\lesssim R^{n/p} \\left\\| \\prod\\nolimits_j | \\mathcal{E}_j f_j | \\right\\|^{1/k}_{L^\\infty_x L^2_y([-R,R]^k \\times \\mathbb{R}^{n-k})}\nFor each fixed x, define\ng_{j,x}(\\eta) = \\int e^{2 \\pi i [ \\upsilon \\cdot \\pi_j(x) + \\phi_j(\\upsilon,\\eta) x_j ]} a_j(\\upsilon,\\eta) f_j(\\upsilon,\\eta)\\; d\\upsilon.\nThen\n\\begin{align*}\n\\mathcal{E}_j f_j(x,y) &amp;= \\int e^{2 \\pi i \\eta \\cdot y} g_{j,x,\\overline{\\xi}}(\\eta)\\; d\\eta = \\check{g}_{j,x}(y).\n\\end{align*}\nBy Minkowski’s integral inequality and Parseval’s identity, we conclude that\n\\| \\mathcal{E}_j f_j(x,\\cdot) \\|_{L^2_y(\\mathbb{R}^{n-k})} = \\| \\widehat{g}_{j,x} \\|_{L^2_y} = \\| g_{j,x} \\|_{L^2_\\eta} \\leq \\int \\| a_j(\\upsilon,\\cdot) f_j(\\upsilon,\\cdot) \\|_{L^2_\\eta}\\; d\\upsilon.\nApplying Cauchy-Schwartz in the \\upsilon variable, exploiting the compact support of a_j in that variable, we conclude\n\\| \\mathcal{E}_j f_j(x,\\cdot) \\|_{L^2_y(\\mathbb{R}^{n-k})} \\lesssim \\| f_j \\|_{L^2(\\mathbb{R}^{n-1})}.\nThus by Hölder’s inequality, we find that\n\\left\\| \\prod\\nolimits_j \\| \\mathcal{E}_j f_j \\|_{L^2_y(\\mathbb{R}^{n-k})}^{1/k} \\right\\|_{L^p_x(I_R)} \\lesssim R^{n/p} \\prod\\nolimits_j \\| f_j \\|_{L^2(\\mathbb{R}^{n-1})}^{1/k}.\nWe conclude that C(R) \\lesssim R^{n/p} holds for all R &gt; 0. In particular, this means that C(R) \\lesssim 1 for R \\leq 100.\nThe Inductive Case: Large Values of R\nFor R \\geq 100, we cover [-R,R]^k by a family \\mathcal{Q} essentially disjoint cubes of sidelength \\delta R. We can then write\n\\int_{[-R,R]^k} \\left\\| \\prod\\nolimits_j | \\mathcal{E}_j f_j(x,\\cdot) | \\right\\|_{L^2_y(\\mathbb{R}^{n-k})}^{1/k}\\; dx = \\sum\\nolimits_Q \\int_Q \\left\\| \\prod\\nolimits_j | \\mathcal{E}_j f_j(x,\\cdot) | \\right\\|_{L^2_y(\\mathbb{R}^{n-k})}^{1/k}\\; dx\nFor each cube Q, we apply the uncertainty principle to localize the supports of the functions \\{ f_j \\} on each cube Q, modulo a rapidly decay error, apply an induction on scales to bound the behavior of the extension operators for these localized functions, and then recombine estimates using the Loomis-Whitney inequality.\nLet \\chi_Q be a function which is smooth, adapted to 10 Q, and equal to one on 5Q. Then consider the operator P_Q on \\mathbb{R}^{n-1}, defined by setting\n(P_Q f)(\\upsilon,\\eta) = \\int \\chi_Q(-u) e^{2 \\pi i (\\upsilon - \\upsilon&#039;) \\cdot u} f(\\upsilon&#039;, \\eta)\\; d\\upsilon&#039;\\; du.\nIf we write \\chi_{Q^c} = 1 - \\chi_Q, then\n(I - P_Q) \\{ f \\}(\\upsilon,\\eta) = \\int \\chi_{Q^c}(-u) e^{2 \\pi i (\\upsilon - \\upsilon&#039;) \\cdot u} f(\\upsilon&#039;, \\eta)\\; d\\upsilon&#039;\\; du.\nWe calculate that the integral kernel K_j of \\mathcal{E}_j \\circ (I - P_Q) is given by the oscillatory integral\nK_j(x,y,\\upsilon, \\eta) = \\int \\chi_{Q^c}(-u) a_j(\\upsilon&#039;, \\eta) e^{2 \\pi i [ \\upsilon&#039; \\cdot \\pi_j(x) + \\phi_j(\\upsilon&#039;,\\eta) x_j  + (\\upsilon - \\upsilon&#039;) \\cdot u]} e^{2 \\pi i \\eta \\cdot y}\\; d\\upsilon&#039;\\; du\nThus if we define\ng_{j,x}(\\eta) = \\int \\chi_{Q^c}(-u) a_j(\\upsilon&#039;, \\eta) e^{2 \\pi i [ \\upsilon&#039; \\cdot \\pi_j(x) + \\phi_j(\\upsilon&#039;,\\eta) x_j  + (\\upsilon - \\upsilon&#039;) \\cdot u]} f(\\upsilon, \\eta)\\; d\\upsilon&#039;\\; du\\; d\\upsilon\\; d\\eta,\nthen\n\\mathcal{E}_j \\circ (I - P_Q) \\{ f \\}(x,y) = \\int K_j(x,y,\\upsilon, \\eta) f(\\upsilon, \\eta)\\; d\\upsilon\\; d\\eta = \\int g_{j,x}(\\eta) e^{2 \\pi i \\eta \\cdot y}\\; d\\eta = \\check{g}_{j,x}(y).\nThus by Parseval’s identity, applying the compact support of g_{j,x} we conclude that\n\\| \\mathcal{E}_j \\circ (I - P_Q) \\{ f \\}(x,\\cdot) \\|_{L^2_y(\\mathbb{R}^{n-k})} = \\| g_{j,x} \\|_{L^2_\\eta(\\mathbb{R}^{n-k})} \\lesssim \\| g_{j,x} \\|_{L^\\infty_\\eta(\\mathbb{R}^{n-k})}.\nIn the oscillatory integral defining g_{j,x}, we may profitably integrate by parts in the \\upsilon&#039; and u variables because the amplitude of the oscillatory integral is smooth in these variables. Let\n\\phi_{j,x}(\\upsilon&#039;, \\upsilon, u) = \\upsilon&#039; \\cdot \\pi_j(x) + \\phi_j(\\upsilon&#039;,\\eta) x_j  + (\\upsilon - \\upsilon&#039;) \\cdot u\nbe the phase defining g_{j,x} as an oscillatory integral. Then \\nabla_{\\upsilon&#039;} \\phi_{j,x} = \\pi_j(x) + (\\nabla_\\upsilon \\phi_j)(\\upsilon&#039;, \\eta) x_j + u. On the support of the oscillatory integral, |(\\nabla_\\nu \\phi_j)(\\nu&#039;,\\eta)| \\leq \\delta, |x_j| \\leq R, and since -u is not in 5Q since u is in the support of \\chi_{Q^c}, we find that |\\pi_j(x) + u| \\geq 4 \\delta R. Thus |\\nabla_{\\nu&#039;} \\phi_{j,x}| \\geq \\delta R. We may thus integrate by parts in the \\nu&#039; variable, noting that |\\partial_{\\nu&#039;}^\\alpha a_j| \\lesssim_\\alpha \\delta^{-|\\alpha|} for all multi-indices \\alpha, then apply Minkowski’s inequality in the u variable, and finally Cauchy-Schwartz in the \\nu and \\eta variables, to conclude that \\| g_{j,x} \\|_{L^\\infty_y(\\mathbb{R}^{n-k})} \\lesssim_N \\delta R^{-N} \\| f \\|_{L^2_y(\\mathbb{R}^{n-k})}. Thus\n\\| \\mathcal{E}_j \\circ (I - P_Q) \\{ f \\}(x,\\cdot) \\|_{L^2_y(\\mathbb{R}^{n-k})} \\lesssim_N \\delta R^{-N} \\| f \\|_{L^2_y(\\mathbb{R}^{n-1})}.\nFor each cube Q, we can write\n\\int_Q \\left\\| \\prod\\nolimits_j | \\mathcal{E}_j f_j(x,\\cdot) | \\right\\|_{L^2_y(\\mathbb{R}^{n-k})}^{1/k}\\; dx \\leq \\int_Q \\left\\| \\prod\\nolimits_j | (\\mathcal{E}_j \\circ P_Q) f_j(x,\\cdot) | \\right\\|_{L^2_y(\\mathbb{R}^{n-k})}^{1/k}\\; dx + \\sum\\nolimits_\\sigma A_\\sigma(Q),\nwhere the sum of A_\\sigma(Q) ranges over all \\sigma \\in \\{ -,+ \\}^k except for the tuple (+,\\cdots,+), where\nA_\\sigma = \\int_Q \\left\\| \\prod\\nolimits_j | \\tilde{\\mathcal{E}}_{j,\\sigma_j} f_j(x,\\cdot) | \\right\\|_{L^2_y(\\mathbb{R}^{n-k})}^{1/k}\\; dx,\nand where \\tilde{\\mathcal{E}}_{j,+} = \\mathcal{E}_j \\circ P_Q and \\tilde{\\mathcal{E}}_{j,-} = \\mathcal{E}_j \\circ (I - P_Q). The sum over the terms A_\\sigma range over 2^k - 1 = O(1) terms, and so if we apply the trivial estimate\n\\| \\tilde{\\mathcal{E}}_{j,+} f_j(x,\\cdot) \\|_{L^2_y(\\mathbb{R}^{n-k})} \\lesssim \\| f_j \\|_{L^2(\\mathbb{R}^{n-1})}\ncombined with\n\\| \\tilde{\\mathcal{E}}_{j,-} f_j(x,\\cdot) \\|_{L^2_y(\\mathbb{R}^{n-k})} \\lesssim_N \\delta R^{-N} \\| f_j \\|_{L^2_y(\\mathbb{R}^{n-1})}\nThen using Hölder’s inequality to trivially unlink the multilinear product gives that \\sum_Q \\sum_\\sigma A_\\sigma \\lesssim_N (\\delta R)^{-k} (\\delta R^{-N}) \\prod_j \\| f_j \\|_{L^2_y(\\mathbb{R}^{n-1})}^{1/k}. Picking N \\geq k, we conclude that \\sum_Q \\sum_\\sigma A_\\sigma \\lesssim \\delta^{1-k} \\prod_j \\| f_j \\|_{L^2(\\mathbb{R}^{n-1})}^{1/k}\nNow by induction,\n\\int_Q \\left[ \\left\\| \\prod\\nolimits_j | \\mathcal{E}_j \\{ P_Q f_j \\}(x,\\cdot) | \\right\\|_{L^2_y(\\mathbb{R}^{n-k})}^{1/k} \\right]^p\\; dx \\lesssim C(\\delta R)\\; \\left\\| \\prod\\nolimits_j |P_Q f_j|^{1/k} \\right\\|_{L^2(\\mathbb{R}^{n-1})}^p\nThe Loomis-Whitney inequality implies that\n\\begin{align*}\n\\sum\\nolimits_Q \\int \\left\\| \\prod\\nolimits_j |P_Q f_j|^{1/k} \\right\\|_{L^2}^p &amp;\\leq \\sum\\nolimits_Q \\int_Q \\prod\\nolimits_j \\| \\chi_Q \\widehat{f}_j \\|_{L^2_y(\\mathbb{R}^{n-1})}^{\\frac{2}{k-1}}\\\\\n&amp;\\leq \\prod\\nolimits_j \\left[ \\sum\\nolimits_Q \\| \\chi_Q \\widehat{f}_j \\|_{ L^2_y(\\mathbb{R}^{n-1})}^2 \\right]^{\\frac{1}{k-1}}\\\\\n&amp;\\lesssim \\prod\\nolimits_j \\| \\widehat{f}_j \\|_{L^2_y(\\mathbb{R}^{n-1})}^{\\frac{2}{k-1}}\\\\\n&amp;\\lesssim \\prod\\nolimits_j \\| f_j \\|_{L^2_y(\\mathbb{R}^{n-1})}^{\\frac{2}{k-1}}\n\\end{align*}\nPutting together inequalities, we conclude that there is a constants A and B so that for all R \\geq 100,\nC(R) \\leq A\\; C(\\delta R) + B\\; \\delta^{1-k}.\nIf we know that C(\\delta R) \\leq C_1 (\\delta R)^\\varepsilon, then the above inequality guarantees that we obtain that C(R) \\leq C_1 R^\\varepsilon provided that both A C_1 (\\delta R)^\\varepsilon \\leq 0.5 C_1 R^\\varepsilon and B \\delta^{1-k} \\leq 0.5 C_1 R^\\varepsilon. The former inequality holds if we pick \\delta \\leq (2A)^{-1/\\varepsilon}. This fixes \\delta, in a way that depends only on \\varepsilon. Once \\delta is fixed, we find that the latter inequality holds, assuming R \\geq 1, if we pick C_1 \\geq 2 B \\delta^{1-k}. Since \\delta depends only on \\varepsilon, we can then pick C_1 depending only on \\varepsilon. Thus the induction closes."},"Multilinear-Restriction-Project/Calculations-With-The-Shape-Operator-II":{"slug":"Multilinear-Restriction-Project/Calculations-With-The-Shape-Operator-II","filePath":"Multilinear Restriction Project/Calculations With The Shape Operator II.md","title":"Calculations With The Shape Operator II","links":[],"tags":[],"content":"Let \\pi_j: \\mathbb{R}^n \\to \\mathbb{R}^{n-1} denote the map \\pi_j(\\zeta) = (\\zeta_1,\\dots,\\zeta_{i-1},\\zeta_{i+1},\\dots,\\zeta_n). Consider hypersurfaces \\Sigma_1,\\dots,\\Sigma_k in \\mathbb{R}^n given by\n\\Sigma_i = \\{ \\zeta: \\zeta_j = \\phi_j(\\pi_j(\\zeta)) \\},\nwhere \\phi_j(0) = 0 and \\nabla \\phi_j(0) = 0. We write \\zeta = (\\xi,\\eta), with \\xi \\in \\mathbb{R}^k and \\eta \\in \\mathbb{R}^{n-k}. We consider the parameterization\n\\Sigma_i(\\upsilon,\\eta) = ( \\upsilon_1,\\dots,\\upsilon_{i-1}, \\phi_i(\\upsilon,\\eta), \\upsilon_{i+1},\\dots,\\upsilon_{k-1}, \\eta ).\nIn this note we prove an equivalence between the following two conditions:\n\nBejenaru’s Condition: If W = \\text{span}(e_{i+1},\\dots,e_n), then \\pi_W \\circ S_0 \\circ i_W is invertible, where S_0: T_0 \\Sigma_i \\to T_0 \\Sigma_i is the shape operator of M_i at 0, i_W: W \\to T_0 \\Sigma_i is the inclusion map, and \\pi_W: T_0 \\Sigma_i \\to W is the projection map.\nTacy’s Condition: The Hessian of \\phi_i in the \\eta variable is invertible at 0.\n\nTo see this equivalence, we begin by computing the shape operator in an appropriate coordinate system. For j \\in \\{ 1, \\dots, n-k \\}, we let \\partial_j(\\eta) = (\\partial_{\\eta_j} \\phi_i(0,\\eta) e_i, e_j). Then \\{ \\partial_1(\\eta), \\dots, \\partial_{n-k}(\\eta) \\} form a basis for the tangent space of \\Sigma_i at the point \\Sigma_i(\\xi,\\eta). Now\nn(\\eta) = r(\\eta) ( e_i, - \\nabla_\\xi \\phi_i(0,\\eta) )\nis the normal vector to \\Sigma_i at \\Sigma_i(0,\\eta), where r(\\eta) = \\sqrt{1 + |\\nabla_\\xi \\phi_i(0,\\eta)|^2}.\nThus differentiating in the \\xi_j variable, we see that there exists a constant c_j so that\nS_0(\\partial_j) = r(\\eta)^{-1} ( 0, - (\\text{Hess}_\\eta \\phi_i)(0) e_k ) + c_j n(\\eta)\nSo if H = \\text{Hess}_\\eta \\phi_i(0), then\nS_0\\left(\\sum a_j \\partial_j \\right) \\cdot \\left(\\sum b_k \\partial_k \\right) = r(\\eta)^{-1} (b^T H a)\nBejenaru’s condition fails precisely when \\pi_W(S_0(\\sum a_j \\partial_j)) = 0 for some nonzero vector a. The calculation above shows this is equivalent to b^T H a = 0 for all vectors b, and thus to Ha = 0. Thus we see immediately that Bejenaru’s condition fails at the origin precisely when H fails to be invertible. Conversely, Bejenaru’s condition holds precisely when H is invertible."},"Multilinear-Restriction-Project/Calculations-With-The-Shape-Operator":{"slug":"Multilinear-Restriction-Project/Calculations-With-The-Shape-Operator","filePath":"Multilinear Restriction Project/Calculations With The Shape Operator.md","title":"Calculations With The Shape Operator","links":[],"tags":[],"content":"Let \\Sigma be an orientable surface in \\mathbb{R}^d. Then we can consider a normal vector field n: \\Sigma \\to S^{d-1} to \\Sigma. The derivative of n at a point p \\in \\Sigma gives rise to a linear map from T_p \\Sigma to T_{n(p)} S^{d-1}. But both tangent spaces T_p \\Sigma and T_{n(p)} S^{d-1} correspond to the same subspace of \\mathbb{R}^d, and so the two can be naturally identified. Thus the derivative of n at a point p \\in \\Sigma gives rise to a linear operator S_p on T_p \\Sigma, self-adjoint with respect to the inner product on T_p \\Sigma given by the dot product. The operator S_p is called the shape operator.\nIntuitively, S_p describes how the normal vectors to \\Sigma vary up to first order around the point p. A vector v is an eigenvector of S_p if and only if the normal vector, to first order, only varies in the direction of v as we travel along a curve on \\Sigma tangent to v at p.\nWe would like to work with the operator S_p in coordinates. Let d = n+1, and consider a coordinate chart \\alpha: \\Sigma \\to \\mathbb{R}^n for \\Sigma. Then at each p \\in \\Sigma, we obtain a basis \\partial_1,\\dots,\\partial_n for T_p \\Sigma given by the columns of the derivative of \\alpha^{-1}, viewed as a map from \\mathbb{R}^n to \\mathbb{R}^d. For v \\in T_p \\Sigma, we let v^\\alpha \\in \\mathbb{R}^n denote the components of v, i.e. the vector such that v = \\sum v^\\alpha_i \\partial_i.\nWe would like to work out the matrix representation of the operator S_p in this coordinate system, i.e. finding the n \\times n matrix A so that for any two vectors v,w \\in T_p \\Sigma, S_p v = w holds if and only if Av^\\alpha = w^\\alpha. It is often easier to work with the second fundamental form in coordinates rather than the shape operator, i.e. the bilinear map \\text{II}_p: T_p \\Sigma \\times T_p \\Sigma \\to \\mathbb{R} given by \\text{II}_p(v,w) = (S_p v) \\cdot w. Thus we also hope to find the matrix B so that for v,w \\in T_p \\Sigma, \\text{II}_p(v,w) = ({v^\\alpha})^T B w^\\alpha. The matrices A and B can be related using the metric on \\Sigma in coordinates. Namely, if we consider the matrix G so that v \\cdot w = (v^\\alpha)^T G w^\\alpha, then B = A^T G.\nComputing the Operator on Hyperbolic Surfaces\nWe now write n = n_1 + n_2, and work with the shape operator on the special case of a hyperbolic surface of the form\n\\Sigma = \\left\\{ (x,y,z) : z = \\frac{|x|^2 - |y|^2}{2} \\right\\}.\nwhere x \\in \\mathbb{R}^{n_1} and y \\in \\mathbb{R}^{n_2}. We will work in the coordinate chart \\alpha given by projection onto the (x,y) axis. At a point p = (x,y,z) on \\Sigma, let us write the resulting basis of T_p \\Sigma from the coordinate chart as \\partial_1^x, \\dots, \\partial_{n_1}^x, \\partial_1^y, \\dots, \\partial_{n_2}^y. We let e^z, e_1^x, \\dots, e_{n_1}^x, e_1^y, \\dots, e^y_{n_2} denote the standard basis for \\mathbb{R}^d.\nComputing the Second Fundamental Form\nDifferentiating \\alpha^{-1}(x,y) = \\left(x,y,\\frac{|x|^2 - |y|^2}{2} \\right), we see that\n\\partial_i^x = e_i^x + x_i e^z \\quad\\text{and}\\quad \\partial_j^y = e_j^y - y_j e^z.\nWe also calculate that the unit normal vector n_p \\in \\mathbb{R}^d to \\Sigma at p is equal to\nn_p = (1/r) (x \\cdot e^x - y \\cdot e^x - e^z),\nwhere r = \\sqrt{1 + |x|^2 + |y|^2}.\nSince we have an expression for n_p involving the (x,y) coordinates, it is simple to compute the directional derivative of n_p in the directions \\partial_i^x and \\partial_i^y by differentiating the expression above in x and y. We thus find by the product rule that there exists constants c_i^x and c_i^y so that\nS_p(\\partial^x_i) = (1/r) e^x_i + c^x_i n_p\nand\nS_p(\\partial_j^y) = (-1/r) e^y_j + c^y_j n_p.\nSince n_p is orthogonal to all elements of T_p \\Sigma, we immediately conclude from this calculation that the matrix B representing the second fundamental form II_p is given by\nB = (1/r) \\begin{pmatrix} + I_{n_1 \\times n_1} &amp; 0_{n_1 \\times n_2} \\\\ 0_{n_2 \\times n_1} &amp; - I_{n_2 \\times n_2} \\end{pmatrix}\nThe Metric in Coordinates\nFrom the expressions of \\partial^x_i and \\partial^y_j in the standard basis vectors on \\mathbb{R}^d, we can immediately compute the matrix G representing the metric. It takes the form\nG = I_{n \\times n} + \\begin{pmatrix} x x^T &amp; - xy^T \\\\ - yx^T &amp;  yy^T \\end{pmatrix}\nInverting this expression gives that\nG^{-1} = I_{n \\times n} - \\frac{1}{1 + |x|^2 + |y|^2} \\begin{pmatrix} xx^T &amp; - xy^T \\\\ - yx^T &amp; yy^T \\end{pmatrix}\nAs can be verified by a simple direct computation. Alternatively, we see that G has x e^x - y e^y as an eigenvector, with eigenvalue 1 + |x|^2 + |y|^2, and G acts as the identity on the orthogonal complement to the line generated by this eigenvector. Conversely, G^{-1} has xe^x - ye^y as an eigenvector, with eigenvalue (1 + |x|^2 + |y|^2)^{-1}, and acts as the identity on the orthogonal complement to the line generated by this eigenvector.\nWe thus conclude from the identity B = A^TG that A = G^{-1} B. Thus we find that\n\\begin{align}\nA &amp;= (1/r) \\begin{pmatrix} I &amp; 0 \\\\ 0 &amp; -I \\end{pmatrix} - (1/r^3) \\begin{pmatrix} xx^T &amp; -xy^T \\\\ -yx^T &amp; yy^T \\end{pmatrix} \\begin{pmatrix} I &amp; 0 \\\\ 0 &amp; -I \\end{pmatrix}\\\\\n&amp;= (1/r) \\begin{pmatrix} I &amp; 0 \\\\ 0 &amp; -I \\end{pmatrix} - (1/r^3) \\begin{pmatrix} xx^T &amp; xy^T \\\\ -yx^T &amp; -yy^T \\end{pmatrix}.\n\\end{align}\nWe note that, even though S_p is self-adjoint with respect to the inner product on T_p \\Sigma, the matrix A need not be symmetric since it is not defined with respect to an orthogonal basis. And indeed, this is the case. But A is self-adjoint with respect to a certain inner product, and thus diagonalizable.\nClearly vectors with components (a,0) with a \\cdot x = 0 are eigenvectors of A with eigenvalue 1/r. Similarly, vectors with components (0,b) with b \\cdot y = 0 are eigenvectors with eigenvalue -1/r. If (x,y) = 0, then this describes all eigenvectors of A. If x = 0 but y \\neq 0, then the only remaining eigenvector is (0,y), with eigenvalue -1 / r^3. If x \\neq 0 but y = 0, then the only remaining eigenvector is (x,0) with eigenvalue 1/r^3. Finally, if x \\neq 0 and y \\neq 0, then we have two remaining eigenvectors. In the basis x \\cdot e^x and y \\cdot e^y for the invariant subspace of A given by the span of the two remaining eigenvectors, the matrix A has the representation as the 2 \\times 2 matrix\nM = (1/r) \\begin{pmatrix} 1 &amp; 0 \\\\ 0 &amp; -1 \\end{pmatrix} - (1/r^3) \\begin{pmatrix} |x|^2 &amp; |y|^2 \\\\ -|x|^2 &amp; -|y|^2 \\end{pmatrix}\nNow \\text{tr}(M) = -z/r^3 and \\text{det}(M) = -1/r^4. From this, we compute that the two eigenvalues of M, which are the two remaining eigenvalues \\lambda_+ and \\lambda_- of A, given by\n\\lambda_{\\pm} = \\frac{-z \\pm \\sqrt{ z^2 + 4r^2 }}{2r^3}\nAn eigenvector v_+ of M corresponding to \\lambda_+ is\n\\begin{pmatrix} 2|y|^2 \\\\ 2 + 2|y|^2 - (-z + \\sqrt{z^2 + 4r^2}) \\end{pmatrix} = \\begin{pmatrix} r^2 - z^2 - 1 \\\\ 1 + r^2 - \\sqrt{z^2 + 4r^2} \\end{pmatrix}.\nAn eigenvector v_- of M corresponding to \\lambda_- is\n\\begin{pmatrix}\n2|y|^2 \\\\ 2 + 2|y|^2 - (-z - \\sqrt{z^2 + 4r^2})\n\\end{pmatrix} = \\begin{pmatrix}\nr^2 - z^2 - 1 \\\\ 1 + r^2 + \\sqrt{z^2 + 4r^2}\n\\end{pmatrix}\nwhich can then be converted into the two remaining eigenvectors of A.\nNote that when z = 0, we get \\lambda_{\\pm} = \\pm r^{-2},\nv_+ = \\begin{pmatrix} r+1 \\\\ r-1 \\end{pmatrix} \\quad\\text{and}\\quad v_- = \\begin{pmatrix} r-1 \\\\ r+1 \\end{pmatrix},\nFor large r these vectors look like almost multiples of one another, but not with respect to the metric G.\nWedge Products of Normals With The Shape Operator\nNow consider two points p, and q_1,\\dots,q_k. The curvature condition of Bejanaru states that for unit normal vectors \\{ n_p, n_{q_1}, \\dots, n_{q_k} \\} to caps, if we define V = \\text{span}(n_p, n_{q_1}, \\dots, n_{q_k} ), then the linear operator \\pi_{V^\\perp} \\circ S_p|_{V^\\perp} is invertible, where \\pi_{V^\\perp} is the orthogonal projection onto V^\\perp.\nThis condition fails precisely when there exists a unit vector v in T_p \\Sigma orthogonal to \\{ n_p, n_{q_1}, \\dots, n_{q_k} \\}, with the property that S_pv is in the span of the unit normal vectors \\{ n_p, n_{q_1}, \\dots, n_{q_k} \\}. This would imply that S_p v \\cdot v = 0 since v is orthogonal to the unit normal vectors. Thus v lies in the cone \\Gamma = \\{ a \\cdot \\partial^x + b \\cdot \\partial^y : |a| = |b| \\}, which is precisely the family of vectors such that S_p v \\cdot v = 0, because if v = a \\cdot \\partial_\\alpha + b \\cdot \\partial_\\beta then S_p v \\cdot v = |a|^2 - |b|^2. In particular, we see that the curvature condition fails for a family of normal vectors V = \\{ n_p, n_{q_1}, \\dots, n_{q_k} \\} whenever V^\\perp contains a vector v \\in \\Gamma such that S_p v \\in V.\nBarron’s Condition on Curvature\nConversely, Barron’s condition fails for two points p and q with coordinates (\\alpha_1,\\beta_1) and (\\alpha_2,\\beta_2) whenever (\\alpha_1 - \\alpha_2) \\cdot \\partial_\\alpha + (\\beta_1 - \\beta_2) \\partial_\\beta \\in \\Gamma. We claim this condition is, in the bilinear case, entirely equivalent to Bejenaru’s condition. In the bilinear case, using the notation of Bejenaru’s condition above, V^\\perp \\cap T_p \\Sigma is a line spanned by the orthogonal projection \\pi_p(n_q) of n_q onto T_p \\Sigma. Since S_p is invertible, it follows that Bejanaru’s condition reduces to observing when S_p^{-1}(\\pi_p(n_q)) \\in B. The following proposition thus shows that Barron and Bejenaru’s conditions are equivalent.\nProposition: Fix p,q \\in \\Sigma. Then S_p^{-1}(\\pi_p(n_q)) is a constant multiple of (\\alpha_1 - \\alpha_2) \\cdot \\partial_\\alpha + (\\beta_1 - \\beta_2) \\partial_\\beta.\nProof: The proposition is invariant under linear transformations of the coordinates (\\alpha,\\beta) that preserve |\\alpha|^2 - |\\beta|^2. The action of these transformations is transitive on the level sets of the function |\\alpha|^2 - |\\beta|^2. It therefore suffices to prove the proposition when \\alpha = te_1 and \\beta = 0, for some t \\in \\mathbb{R}, or when \\alpha = 0 and \\beta = te_1, for some t \\in \\mathbb{R}. We will only focus on the first case (though the second can likely be reduced to the first by applying reflection symmetries).\nWrite \\alpha = (\\lambda,\\gamma). Then the metric of \\Sigma at p is given by\ng_p = (1 + 4t^2) d\\lambda^2 + d\\gamma^2 + d\\beta^2\nIt thus follows from our formula for \\text{II}^p that\nS_p( a \\partial_{\\lambda} + b \\cdot \\partial_{\\gamma} + c \\cdot \\partial_\\beta ) = \\left( \\frac{a}{1 + 4t^2} \\right) \\partial_{\\lambda} + b \\cdot \\partial_{\\gamma} - c \\cdot \\partial_\\beta\nRecalling that q has coordinates (\\alpha_2,\\beta_2) = (\\lambda_2,\\gamma_2,\\beta_2), one can verify that the orthogonal projection of n_q onto T_p\\Sigma is given by a constant multiple of\n\\left( \\frac{\\lambda_2 - t}{1 + 4t^2} \\right) \\partial_\\lambda + \\gamma_2 \\cdot \\partial_\\gamma - \\beta_2 \\cdot \\partial_\\beta.\nApplying S_p^{-1} to this vector, we obtain the vector\n\\left( \\lambda_2 - t \\right) \\partial_\\lambda + \\gamma_2 \\cdot \\partial_\\gamma - \\beta_2 \\cdot \\partial_\\beta.\nThis vector is negation of (\\alpha_1 - \\alpha_2) \\cdot \\partial_\\alpha + (\\beta_1 - \\beta_2) \\partial_\\beta.  □\nConfigurations of Bad Caps\nFor a family of caps, Bejenaru’s condition fails for a family of normal vectors \\{ n_p, n_{q_1}, \\dots, n_{q_k} \\} whenever there span V has the property that V^\\perp contains a vector v such that S_p v \\in V. It is thus natural to consider the Grassmannian \\text{Gr}_k(T_p \\Sigma), the space of k-dimensional subspaces of T_p \\Sigma, and to consider the Grassmannian variety\n\\mathcal{Z} = \\{ V \\in \\text{Gr}_k(T_p \\Sigma) : \\text{there exists $v \\in V^\\perp - \\{ 0 \\}$ such that $S_p v \\in V$} \\}\nIndeed, normal vectors \\{ n_p, n_{q_1}, \\dots, n_{q_k} \\} fail Bejenaru’s condition whenever the projection of the vectors \\{ n_{q_1}, \\dots, n_{q_k} \\} onto T_p \\Sigma span an element of \\mathcal{Z}.\nLet us simplify our analysis by starting with the assumption that p = 0. Then T_p \\Sigma is just the (x,y) plane, and the matrix A representing S_p is given by\n\\begin{pmatrix} +I_{n_1 \\times n_1} &amp; 0_{n_1 \\times n_2} \\\\ 0_{n_2 \\times n_1} &amp; -I_{n_2 \\times n_2} \\end{pmatrix}\nTo determine the structure of \\mathcal{Z}, we apply a system of coordinates to \\text{Gr}_k(T_p \\Sigma). Let us assume for simplicity that k \\leq n_1. Let x = (x^\\alpha,x^\\beta), where x^\\alpha \\in \\mathbb{R}^k and x^\\beta \\in \\mathbb{R}^{n_1 - k}. Then all elements V of \\text{Gr}_k(T_p \\Sigma) which intersect the x^\\alpha axis transversally (which holds generically) can be written uniquely as \\{ (x^\\alpha,Mx^\\alpha,Nx^\\alpha) \\}, for a (n_1 - k) \\times k matrix M and a n_2 \\times k matrix N. We view the pair of matrices M and N as coordinates parameterizing an element of \\text{Gr}_k(T_p \\Sigma). We will call them systems of Grassmann coordinates, though I don’t think this term is standard.\nGiven V parameterized by M and N, a vector (v^\\alpha, v^\\beta, v^y) is in V^\\perp when for all x^\\alpha,\nv^\\alpha \\cdot x^\\alpha + v^\\beta \\cdot M x^\\alpha + v^y \\cdot Nx^\\alpha = 0,\ni.e. when v^\\alpha + M^T v^\\beta + N^T v^y = 0. Conversely, S_p(v^\\alpha ,v^\\beta, v^y) = (v^\\alpha, v^\\beta, -v^y) is in V when there exists some x^\\alpha with v^\\alpha = x^\\alpha, v^\\beta = Mx^\\alpha, and v^y = - Nx^\\alpha. Combining these equations, we find that it must be true that (I + M^T M - N^T N) x^\\alpha = 0, and this condition implies the converse; that is, we conclude that V lies in \\mathcal{Z} if and only if I + M^T M - N^T N is not invertible. This corresponds to a quadratic equation \\det(I + M^T M - N^T N) = 0 in the Grassmann coordinates M and N for V. Thus we see that \\mathcal{Z} is a quadratic surface in this coordinate system.\nExperimentally, it seems that \\mathcal{Z} is a non-degenerate quadratic in all cases but when n = 2, n_1 = n_2 = 1, and k = 1. In this case, M does not really factor into the parameterization since it is a 0 \\times 1 matrix, N is a 1 \\times 1 matrix with a single component b, and\n\\det( I + M^T M - N^T N ) = -(b -1)(b + 1)\nThus in this case we thus see that \\mathcal{Z} consists of two points. This corresponds to the fact that Bejenaru’s condition fails in bilinear analysis fails for \\{ n_p, n_q \\} when the projections of n_q onto n_p lies along one of two different lines.\nIf we next consider the case n = 4, n_1 = n_2 = 2, and k = 1, then M is a 1 \\times 1 matrix with some entry a, and N a 2 \\times 1 matrix with entries b_1 and b_2. In this case\n\\det(I + M^T M - N^T N) = 1 + a^2 - b_1^2 - b_2^2.\nThis defines an irreducible quadratic in the variables a, b_1, and b_2. In particular, this means that \\mathcal{Z} is infinite in this case, and so Bejenaru’s condition can fail for \\{ n_p, n_q \\} if the projection of n_q onto n_p lie along one of an 2 dimensional family of ‘forbidden’ lines, which generate a cone.\nThings become worse when k &gt; 1. If n = 4, n_1 = n_2 = 2, and k = 2, then M is a 0 \\times 2 matrix, N is a 2 \\times 2 matrix with entries \\{ b_{ij} \\}, and then\n\\det(I + M^TM - N^TN) = 1 - b_{11}^2 - b_{12}^2 - b_{21}^2 + b_{12}^2 b_{21}^2 - 2 b_{11} b_{12} b_{21} b_{22} - b_{22}^2 + b_{11}^2 b_{22}^2\nMathematica does not believe that this quantity factors, and graphing the solution set gives what looks to be an irreducible variety. A consequence of this is that Bejenaru’s condition can fail for \\{ n_p, n_{q_1}, n_{q_2} \\} when the projection of n_{q_1} and n_{q_2} onto T_p \\Sigma generate a plane which is contained in one of a 3 dimensional family of ‘forbidden’ planes.\nIf n_{q_1} is fixed, can we find an equation for n_{q_2} that determine when the span of the projections of n_{q_1} and n_{q_2} generate such a forbidden plane? To begin with, if v and w are given, we must convert V = \\text{span}(v,w) into coordinates on the Grassmannian. Then any vector in V can be written as (av^+ + bw^+, av^- + bw^-), so that we see V = \\{ (v^+, Nv^+) \\} where\nN = \\begin{pmatrix} v^- &amp; w^- \\end{pmatrix} \\begin{pmatrix} v^+ &amp; w^+ \\end{pmatrix}^{-1}.\nWe can simplify, writing\n\\begin{aligned}\n N &amp;= \\frac{1}{v^+_1 w^+_2 - v^+_2 w^+_1} \\begin{pmatrix} v^-_1 &amp; w^-_1 \\\\ v_2^- &amp; w_2^- \\end{pmatrix} \\begin{pmatrix} w^+_2 &amp; -w^+_1 \\\\ -v^+_2 &amp; v^+_1 \\end{pmatrix}\n\\end{aligned}\ni.e. so that if N = \\left( \\begin{smallmatrix} b_{11} &amp; b_{12} \\\\ b_{21} &amp; b_{22} \\end{smallmatrix} \\right), where\n\\begin{split}\nb_{11} &amp;= \\frac{v^-_1 w_2^+ - w^-_1 v^+_2}{v_1^+ w_2^+ - v_2^+ w_1^+}\\\\\nb_{12} &amp;= \\frac{- v_1^- w^+_1 + w_1^- v_1^+}{v_1^+ w_2^+ - v_2^+ w_1^+}\\\\\nb_{21} &amp;= \\frac{v^-_2 w_2^+ - w_2^- v^+_2}{v_1^+ w_2^+ - v_2^+ w_1^+}\\\\\nb_{22} &amp;= \\frac{- v_2^- w^+_1 + w_2^- v_1^+}{v_1^+ w_2^+ - v_2^+ w_1^+}\n\\end{split}\nWe can then substitute these parameters into the equation for \\det(I + M^TM - N^TN) above to determine an equation in v and w determining when Bejenaru’s condition fails. This condition becomes equivalent to the vanishing of an irreducible bi-homogeneous polynomial of degree two in each of the variables of v and w (thus a degree four homogeneous polynomial jointly). Thus for a generic choice of v, the set of forbidden choices of w lie on an irreducible quadratic in T_p \\Sigma.\nTo determine the centers of the caps that are forbidden, if the center of a cap q has coordinates (x,y), then when p = 0, the projection of n_q onto T_p \\Sigma has (x,y) coordinates (x/r, -y/r). Since the polynomials that define the forbidden regions are homogeneous, we can forget about the r parameter. Thus the cap centered q is forbidden when the vector w = (x,-y) is forbidden. On Desmos, this seems to be a cone for many values of v, but some of the conics seem different for some values, and I don’t see to understand when such values occur (talk to Jianghao and Jonathan about this).\nHow does the case n = 3, n_1 = 2, n_2 = 1, k = 2 look? Here M is a 0 \\times 2 matrix and and N is a  1 \\times 2 matrix with entries b_1 and b_2, and Bejanaru’s condition in coordinates on the Grassmanian is that\n1 + b_1^2 - b_2^2 = 0.\nGiven two vectors (v^+,v^-) and (w^+,w^-) in T_p \\Sigma, we have\n\\begin{split}\n\\begin{pmatrix} b_1 &amp; b_2 \\end{pmatrix} &amp;= \\begin{pmatrix} v^- &amp; w^- \\end{pmatrix} \\begin{pmatrix} v^+ &amp; w^+ \\end{pmatrix}^{-1}\\\\\n&amp;= \\frac{1}{v^+_1 w^+_2 - v^+_2 w^+_1} \\begin{pmatrix} v^- &amp; w^- \\end{pmatrix} \\begin{pmatrix} w^+_2 &amp; - w^+_1 \\\\ - v^+_2 &amp; v^+_1 \\end{pmatrix}.\n\\end{split}\nThus we have\n\\begin{split}\nb_1 &amp;= \\frac{1}{v^+_1 w^+_2 - v^+_2 w^+_1} \\begin{pmatrix} v^- w^+_2 - w^- v_2^+ \\end{pmatrix}\\\\\nb_2 &amp;= \\frac{1}{v^+_1 w^+_2 - v^+_2 w^+_1} \\begin{pmatrix} -v^- w^+_1 + w^- v_1^+ \\end{pmatrix}\n\\end{split}\nPlugging in the vector w = (x,-y) and observing the output on Desmos, we see that the cap is bad when it lies on one of two flat planes. So we can apply our analysis in this situation.\nHow does the case n = 4, n_1 = 3, n_2 = 1, k = 3 look? Here M is a 0 \\times 3 matrix and N is a 1 \\times 3 matrix. If we write the entries of N as b_1,b_2, and b_3, then the equation for Bejenaru’s condition to fail becomes\n1 - b_1^2 - b_2^2 - b_3^2 = 0\nGiven three vectors v = (v^+,v^-), w = (w^+,w^-), and u = (u^+, u^-), the Grassmann coordinates of the vector space spanned by v and w are given by\n\\begin{pmatrix} b_1 &amp; b_2 &amp; b_3 \\end{pmatrix} = \\begin{pmatrix} v^- &amp; w^- &amp; u^- \\end{pmatrix} \\begin{pmatrix} v^+ &amp; w^+ &amp; u^+ \\end{pmatrix}^{-1}\nComputing this inverse and viewing the caps on desmos, we see that for each v and w, the set of u that are forbidden forms a cone.\nA Possible Line of Attack\nOne option that may help us is to consider whether the multilinear restriction theorem holds, under a weaker range of p, under weaker curvature assumptions on the linear operator \\pi_{V^\\perp} \\circ S_p|_{V^\\perp}, i.e. that it has rank at least l for some fixed l \\leq n-k. Since Tacy’s argument only requires Stein-Tomas L^2 estimates interpolated with transversality estimates, it may be possible to adapt her argument to this more general situation. This may possibly cut down the number of ‘bad caps’ to consider, which may result in better numerology when considering the relevant induction on scales."},"Multilinear-Restriction-Project/Keel-Tao-Estimates-on-Subset-of-Variables":{"slug":"Multilinear-Restriction-Project/Keel-Tao-Estimates-on-Subset-of-Variables","filePath":"Multilinear Restriction Project/Keel-Tao Estimates on Subset of Variables.md","title":"Keel-Tao Estimates on Subset of Variables","links":[],"tags":[],"content":"Consider the Schrödinger operator e^{i t \\Delta} on \\mathbb{R}^d = \\mathbb{R}^n_x \\oplus \\mathbb{R}^m_y, where n + m = d. Then we want to prove that if p = 2m/(m-2), and if \\widehat{f} is supported on the unit ball, then\n\\| e^{it \\Delta} f \\|_{L^2_x(\\mathbb{R}^n) L^p_y(\\mathbb{R}^m)} \\lesssim \\langle t \\rangle^{-1} \\| f \\|_{L^2_x(\\mathbb{R}^n) L^{p&#039;}_y(\\mathbb{R}^m)}.\nThen a Young’s inequality argument in the t variable establishes that the extension operator \\mathcal{E} for the paraboloid \\{ \\tau = |\\xi|^2 + |\\eta|^2 \\} satisfies\n\\| (\\mathcal{E} \\circ \\mathcal{E}^*) f \\|_{L^2_t(I_R) L^2_x(\\mathbb{R}^n) L^p_y(\\mathbb{R}^m)} \\lessapprox \\| f \\|_{L^2_t(I_R) L^2_x(\\mathbb{R}^n) L^{p&#039;}_y(\\mathbb{R}^m)}\nwhich by the TT^* method is sufficient to conclude that \\mathcal{E} is bounded from L^2_\\xi(\\mathbb{R}^n) L^2_\\eta(\\mathbb{R}^m) to L^2_t(\\mathbb{R}^n) L^2_x(\\mathbb{R}^n) L^p_y(\\mathbb{R}^m), which is Proposition 2.2 of Tacy’s paper.\nTo prove the estimate above, we write e^{it \\Delta} = e^{it \\Delta_x} \\circ e^{it \\Delta_y}. Let us assume that\n\\| e^{it \\Delta_x} f \\|_{L^2_x L^1_y} \\lesssim \\| f \\|_{L^2_x L^1_y}.\nApplying the usual dispersive estimates for \\Delta_y, one can conclude that\n\\| e^{it \\Delta_y} f \\|_{L^2_x L^\\infty_y} \\lesssim \\langle t \\rangle^{-m/2} \\| f \\|_{L^2_x L^1_y}.\nCombining the above two bounds, we obtain that\n\\| e^{it \\Delta} f \\|_{L^2_x L^\\infty_y} \\lesssim \\langle t \\rangle^{-m/2} \\| f \\|_{L^2_x L^1_y}.\nOn the other hand, purely by energy conservation we obtain that\n\\| e^{it \\Delta} f \\|_{L^2_x L^2_y} \\lesssim \\| f \\|_{L^2_x L^2_y}.\nInterpolation then yields that \\| e^{it \\Delta} f \\|_{L^2_x L^p_y} \\lesssim |t|^{-1} \\| f \\|_{L^2_x L^{p&#039;}_y}, as was required.\nAttempt to Find Counterexample\nWe try and use a bush example to find a counterexample to the inequality \\| e^{it \\Delta_x} f \\|_{L^2_x L^1_y} \\lesssim \\| f \\|_{L^2_x L^1_y}. Let m = 1. For 1 \\leq j \\lesssim N, with N \\sim R^{d/2}, consider a family of disjoint balls \\{ B_j \\} of radius R^{1/2} in the ball of radius R, with B_j has center x_j. Then consider a family of wave packets \\{ f_j \\}, with \\| f_j \\|_{L^2} = 1, with f_j supported on B_j, and where \\hat{f}_j is supported on an R^{-1/2} neighborhood of \\xi_j = - 2 t^{-1} x_j. Thus the average value of |f_j| is R^{-d/4} = N^{-1/2}. Then e^{it \\Delta_x} f_j is supported on an R^{1/2} neighborhood of the origin, and with Fourier transform supported on a R^{-1/2} neighborhood of \\xi_j. Now because the functions \\{ f_j \\} have disjoint spatial support, it follows that\n\\| f_j \\|_{L^2_x l^1_j} = \\| f_j \\|_{L^2_x} \\approx N^{1/2}.\nOn the other hand, the average value of \\sum |e^{it \\Delta_x} f_j| should be N R^{-d/4} \\sim R^{d/4}, concentrated on the ball of radius R^{1/2} of the origin, so\n\\| e^{it \\Delta_x} f_j \\|_{L^2_x l^1_j} \\approx R^{d/4 + d/4} = R^{d/2} = N.\nSo we obtain a contradiction to the stated bound. To replace the l^1_j norm with an L^1_x norm, we consider the function f with f(x,j+y) = f_j(x) for 0 \\leq y &lt; 1, and then \\| f \\|_{L^2_y L^1_x} = \\| f_j \\|_{L^2_x l^1_j} and \\| e^{it \\Delta_x} f \\|_{L^2_y L^1_x} = \\| e^{it \\Delta_x} f_j \\|_{L^2_y l^1_j}."},"Multilinear-Restriction-Project/Multilinear-Restriction-Using-Polynomial-Partitioning-and-Refined-Decoupling":{"slug":"Multilinear-Restriction-Project/Multilinear-Restriction-Using-Polynomial-Partitioning-and-Refined-Decoupling","filePath":"Multilinear Restriction Project/Multilinear Restriction Using Polynomial Partitioning and Refined Decoupling.md","title":"Multilinear Restriction Using Polynomial Partitioning and Refined Decoupling","links":["General-Zettels/Broad-Narrow-Analysis","2015---Guth---A-Restriction-Estimate-Using-Polynomial-Partioning"],"tags":[],"content":"Setup\nGiven f = (f^1,\\dots,f^k), define\nT(f) = |Ef^1|^{1/k} \\cdots |Ef^k|^{1/k}. \\tag{1}\nand E(f) = \\prod \\| E_if_i \\|_{L^2(\\mathbb{R}^d)}^{1/k}. Our goal is to prove (L^2)^k \\to L^q estimates for T for q &gt; 2(d+k)/(d+k-2), i.e. estimates of the form\n\\| T(f) \\|_{L^q(B_R)} \\lessapprox E(f).\t\\tag{2}\nIn the Broad Norm setting in order to carry out an induction on scales it is necessary to split the right hand side of (2) into an expression involving a decomposition of the functions \\{ f_i \\} into caps of sidelength K = O_\\varepsilon(1). I am not sure how necessary this is in the multilinear setting.\nBy Pigeonholing, we may assume in (2) that:\n\nThe L^2 norms of all of the wave packets \\{ f^i_T \\} are proportional.\nFor each i, and each R^{-1/2} cap \\theta on \\Sigma for which f^i_\\theta \\neq 0, the number \\mu(\\theta) = \\# \\{ T \\in \\mathbb{T}_\\theta \\} of tubes associated with \\theta are proportional to some common constant \\mu.\nBy homogeneity, we may assume that \\| f_\\theta \\|_{L^2} \\leq 1 for all \\theta.\n\nLet \\mathcal{C}(R,E) denote the family of all f = \\{ f^i \\} with E(f) \\leq R and with the property that for each i, and for all R^{-1/2} caps \\theta on \\Sigma_i, either f^i_\\theta = 0 or \\| f^i_\\theta \\|_{L^2(\\Sigma_i)} \\sim 1. Then let C(R,E) be the smallest constant so that (2) holds for all f \\in \\mathcal{C}(R,E) with implicit constant C(R,E).\nBy Hölder’s inequality, local constancy and L^2 bounds,\n\\begin{aligned}\n\\| T(f) \\|_{L^q(B_R)} &amp;\\leq \\prod \\| E f^i \\|_{L^q(B_R)}^{1/k} \\lesssim \\prod \\| Ef^i \\|_{L^2(B_R)}^{1/k} \\lesssim R E(f)\n\\end{aligned} \\tag{7}\nThus C(R,E) \\lesssim R. Conversely, if E \\lesssim 1, then \\mathcal{C}(R,E) contains only the zero function, since e.g. if f \\in \\mathcal{C}(R,E)$$ and we can find { \\theta_i }so thatf_{\\theta_i}^i \\neq 0$, then\n\\| f^i \\|_{L^2(\\Sigma_i)} \\geq \\| f^i_\\theta \\|_{L^2(\\Sigma_i)} \\sim 1,\nso E(f) \\gtrsim 1. Thus C(R,E) = 0 in this case.\nBreaking Up Into Cases\nOur goal will be use induction on scales to either solve the problem.\nFor a given R and E, Pick f \\in \\mathcal{C}(R,E) so that\n\\| T(f) \\|_{L^q(B_R)} \\approx C(R,E) E. \\tag{8}\nConsider a non-singular algebraic hypersurface Z of degree D which cuts \\mathbb{R}^n into \\Theta(D^n) cells, such that for any two cells O and O&#039;,\n\\| T(f) \\|_{L^q(O \\cap B_R)} \\sim \\| T(f) \\|_{L^q(O&#039; \\cap B_R)}. \\tag{9}\nLet W be the R^{1/2} neighborhood of Z, and define O^\\circ = O - W and let W_{O} = O - O^\\circ. We have\n\\| T(f) \\|_{L^q(B_R)} = \\left( \\sum \\| T(f) \\|_{L^q(O)}^q \\right)^{1/q} = \\left( \\sum \\| T(f) \\|_{L^q(O^\\circ)}^q + \\| T(f) \\|_{L^q(W_{O})}^q \\right)^{1/q}. \\tag{10}\nThe Cellular Case\nWe say we are in the cellular case if\n\\sum \\| Tf \\|_{L^q(O^\\circ)}^q \\geq \\sum \\| Tf \\|_{L^q(W_{O})}^q. \\tag{11}\nThen\n\\| Tf \\|_{L^q(B_R)} \\leq 2^{1/q} \\left( \\sum \\| T(f) \\|_{L^q(O^\\circ)}^q \\right)^{1/q}. \\tag{12} \nSuppose there are N cells, and let A = \\| T(f) \\|_{L^q(B_R)}. Then \\| T(f) \\|_{L^q(O)} \\sim A N^{-1/q} for each cell O. If we suppose \\| T(f) \\|_{L^q(O)} \\leq 2 A N^{-1/q} for each cell, and we let B be the number of cells O such that \\| T(f) \\|_{L^q(O^\\circ)} \\leq (1/10) AN^{-1/q}, then we conclude that\n\\begin{aligned}\nA &amp;\\leq 2^{1/q} \\left( \\sum \\| Tf \\|_{L^q(O^\\circ)}^q \\right)^{1/q}\\\\\n&amp;\\leq 2^{1/q} \\left( B (1/10) A^q N^{-1} + 2 (N - B) A^q N^{-1} \\right)^{1/q}\\\\\n&amp;= 2^{1/q} A N^{-1/q}( 2N - 1.9B )^{1/q}\n\\end{aligned} \\tag{13}\nRearranging gives 2N - 1.9B \\geq N/2, or B \\leq 0.8N.\nSince there are \\Theta(D^n) cells, we can find a subfamily \\mathcal{O} with \\#(\\mathcal{O}) \\sim D^n and for O \\in \\mathcal{O},\n\\| Tf \\|_{L^q(O^\\circ)} \\geq (1/10) AN^{-1/q}.\nIt thus follows that for each O \\in \\mathcal{O},\n\\| Tf \\|_{L^q(B_R)} \\lesssim D^{n/q} \\| Tf \\|_{L^q(\\mathcal{O}^\\circ)}. \\tag{14}\nFor each cell O \\in \\mathcal{O}, define f_O = ( f_O^i) to be the sum of wave packets over tubes that pass through O^\\circ Since a tube can only pass through the interior of D + 1 cells, it follows that\n\\sum\\nolimits_{O} E(f_{O}) \\lesssim D E(f). \\tag{15}\nSince \\mathcal{O} contains \\Theta(D^n) cells, it follows by the pigeonhole principle that there is some O with\nE(f_{O}) \\lesssim D^{1-n} E(f). \\tag{16}\nThus the energy in this cell is much smaller than the energy associated with f if we choose D to be large. So it makes sense to apply induction, i.e. concluding that\n\\begin{aligned} \\| Tf \\|_{L^q(B_R)} &amp;\\lesssim D^{n/q} \\| Tf \\|_{L^q(\\mathcal{O}^\\circ)}\\\\\n&amp;=  D^{n/q} \\| Tf_O \\|_{L^q(\\mathcal{O}^\\circ)}\\\\\n&amp;\\leq D^{n/q} R^{-1/2} C(R,D^{1-n} E) E(f_O)\\\\\n&amp;\\lesssim D^{n/q + 1 -n} R^{-1/2} C(R,D^{1-n} E) E(f).\\end{aligned} \\tag{17}\nSince \\| Tf \\|_{L^q(B_R)} \\sim C(R,E) Ef, we can rearrange this inequality to read that\nC(R,E) \\lesssim D^{n/q + 1 - n} C(R, D^{1-n} Ef). \\tag{18}\nProvided that n/q + 1 - n &lt; 0, i.e. q &gt; n/(n-1), this is likely strong enough to obtain the required inequality if we pick D \\gg 1 to kill any of the implicit constants arising from iterating induction on scales. It turns out that choosing D = R^\\varepsilon will suffice for some \\varepsilon &gt; 0 will suffice.\nThe Algebraic Case\nIf we are not in the tangential case, then it follows that\n\\| Tf \\|_{L^q(O \\cap W \\cap B_R)} \\geq (1/2) \\| Tf \\|_{L^q(O \\cap B_R)}. \\tag{19}\nWe call this the algebraic case. The case where the behavior of f and g on W are both dominated by transverse intersections and tangential intersections is likely simple to deal with using the method of Guth, so we focus now on the case that the L^q behavior of Tf on W is dominated by the behaviour when l functions are transverse, and k - l are tangent.\nThe Transverse-Tangential Case: The Bilinear Case\nLet us focus first on the bilinear case. To simplify notation, let f^1 = f and g^1 = g.Suppose we are in the situation where f consists only of transverse tubes to the wall W, and g only contains tangential tubes to the wall W. For simplicity, assume that the wall behaves like a hyperplane in most respects aside from those relating to the degree of the surface.\nBy pigeonholing, we may assume that all of the tubes in f make an angle \\sim R^{\\alpha - 1/2} with the wall for some 0 &lt; \\alpha \\leq 1/2. It then follows that all the wave packets in f^1 are concentrated in a ball of radius R^{\\alpha - 1/2}. and thus f is locally constant at a scale R^{1/2 - \\alpha}. Moreover, the intersections of the tubes in f are tubes of dimension R^{1/2} \\times R^{1-\\alpha}. If \\alpha \\sim 1/2, then the tubes in f intersect the wall in cubes. On the other hand, if \\alpha \\ll 1/2, then the projections of the tubes in f onto the wall remain transverse with the tubes in the decomposition of g.\nSince all tubes in the decomposition of g are tangent, all the wave packets of g are concentrated in a ball of radius R^{-1/2}, so g is locally constant at a scale R^{1/2}, the thickness of the wall W.\nThe more transverse the tubes of f are, the less transverse equidistribution holds, but the more shortening occurs. The less transverse, the more transverse equidistribution holds, but the less shortening occurs. Hopefully we can make some tradeoff between shortening and equidistribution to obtain an efficient bound in all cases.\nIt is likely true that we do not want to reduce to analysis on some translate of Z, since the exponents in the refined decoupling are better the higher the dimension we are working in. So perhaps there is a way to exploit transverse equidistribution without having to work in the lower dimensional variety Z.\nBecause the intersection of the tubes in the decomposition of f with the wall are R^{1/2} \\times R^{1 - \\alpha} tubes we obtain that\n\\| Ef_T \\|_{L^2(W)} \\lesssim R^{\\frac{1 - \\alpha}{2}} \\| f_T \\|_{L^2(\\Sigma)}.\nBecause the tubes \\{ f_T \\} are orthogonal on R^{1/2} discretized sets, we obtain that\n\\| Ef \\|_{L^2(W)} \\lesssim R^{\\frac{1 - \\alpha}{2}} \\| f_T \\|_{L^2(\\Sigma)}.\nSince we have\n\\| Eg \\|_{L^2(W)} \\lesssim R^{1/2} \\| g \\|_{L^2(\\Sigma&#039;)}\nwe obtain via Hölder’s inequality that\n\\| T(f,g) \\|_{L^2(W)} \\lesssim R^{1 - \\alpha/2} \\| f \\|_{L^2(\\Sigma)} \\| g \\|_{L^2(\\Sigma)}.\nIf we are instead consider a \\lambda_1-shading X of the tubes in f, and a \\lambda_2-shading of the intersection of the tubes in g with W, such that the shading X is contained in the wall W, then a similar argument to the one above shows that\n\\| T(f,g) \\|_{L^2(X)} \\lesssim (\\lambda_1 \\lambda_2)^{1/2} R^{1 - \\alpha/2} \\| f \\|_{L^2(\\Sigma)} \\| g \\|_{L^2(\\Sigma)}.\nPerhaps using Tomas Stein here rather than just L^2 bounds might be more efficient?\nWe hope to interpolate this with a more efficient L^{q_D} bound where q_D = 2 + 4/(n-1) is the dual Stein-Tomas exponent / decoupling exponent in \\mathbb{R}^d. We note that\n(2 + 4/n)^{-1} = \\frac{\\theta}{2} + \\frac{1 - \\theta}{q_D}\nwhere \\theta = 1/(n+2). In order to obtain efficient bounds in L^q for q &gt; 2 + 4/n, we need to obtain a bound of the form\n\\| T(f,g) \\|_{L^{q_D}(X)} \\lesssim (\\lambda_1 \\lambda_2)^{-\\frac{1}{2(n+1)}} R^{-\\beta} \\| f \\|_{L^2(\\Sigma)} \\| g \\|_{L^2(\\Sigma)},\nwhere\n\\beta = \\frac{1 - \\alpha/2}{n+1}.\nTo obtain these bounds, we hope to apply the multilinear Kakeya inequality.\nThe Completely Transverse Case\nTo simplify a first hash at the analysis, let us assume that \\alpha \\sim 1/2, i.e. where tubes intersect completely transversally. Then the only \\lambda_1 shading of the tubes of f in Z can occur when \\lambda_1 \\sim 1, since the shading is R^{1/2} discretized. So we can assume \\lambda_1 in what follows. We might as well assume that X is equal to the support of the intersection of the tubes of f with W. Can we then guarantee good bounds on\n\\| Ef \\|_{L^{q_D}(X)} = \\| Ef \\|_{L^{q_D}(W)}.\nI am not quite sure how to obtain a good bound for this quantity, however.\nOn the other hand, if we thin the tubes in the decomposition of g so that there are m tubes in each direction, and if we thin X so that the multiplicity of g-tubes on X is \\sim m, then the refined decoupling theorem implies that\n\\| Eg \\|_{L^{q_D}(X)} \\lesssim R^{\\frac{-(n-1)}{2(n+1)}} (M/m)^{\\frac{1}{n+1}} \\| f \\|_{L^{q_D}(\\Sigma)}.\nThe Maximal Kakeya conjecture then implies that M \\lesssim m \\lambda_2^{1-n}. This seems to be good enough numerology which is surprising in light of the need for a two ends condition in the linear restriction method of Wang and Wu. If we apply local constancy at a scale R, so that \\| f \\|_{L^{q_D}(\\Sigma)} \\lesssim R^{\\frac{n-1}{n+1}} \\| f \\|_{L^2(\\Sigma)}, we obtain that\n\\| Eg \\|_{L^{q_D}(X)} \\lesssim R^{\\frac{n-1}{2(n+1)}} (M/m)^{\\frac{1}{n+1}} \\| f \\|_{L^2(\\Sigma)}.\nThe growth in R here seems pretty problematic.\nFurthermore, the \\lambda_2-shading of the tubes in g may as well be contained in the set of tubes formed from the intersections of f. The problem then turns into a problem purely about the extension of g, restricted to the surface Z. Namely, we must obtain a bound of the form\n\\| Eg \\|_{L^{q_D}(X)} \\lesssim \\lambda_2^{- \\frac{1}{n+1}} R^{- \\frac{1}{n+1}} \\| g \\|_{L^2(\\Sigma)}\nMaybe this isn’t quite right because we’re working in a lower dimensional set, but it probably is true with an extra loss in R by transverse equidistribution and we should instead get that\n\\| Eg \\|_{L^{q_D}(X)} \\lesssim R^{\\frac{-3(n-1)}{4(n+1)}} (M/m)^{\\frac{1}{n+1}} \\| f \\|_{L^{q_D}(\\Sigma)} \\lesssim R^{\\frac{-3(n-1)}{4(n+1)}} R^{\\frac{n-1}{n+1}} (M/m)^{\\frac{1}{n+1}} \\| f \\|_{L^2(\\Sigma)}.\nSo provided we can show that M \\lesssim R^{(3n-5)/4} \\lambda_2^{-1} m the proof is complete. But this is true if the maximal Kakeya conjecture is true, because it implies .\nIn the transverse case, we are talking about R^{1/2} thickened point line incidences on the surface Z, so perhaps Szemerédi–Trotter type incidence bounds may help us here?\nThe Analysis When Less Transversality Is Present\nNow how about when \\alpha is much smaller than 1/2. Then we have to solve a problem involving incidences of tubes with shortened tubes. But let’s just try treating them as normal sized tubes and see how far we get.\nLet us assume that each cube Q in the intersection of tubes in f and g has product multiplicity \\mu. Then\n\\begin{align}\nR^{n/2} \\#(\\mathcal{Q})\\; \\mu &amp;= \\sum\\nolimits_Q |Q| \\mu \\leq \\int \\left( \\sum\\nolimits_{T \\in \\mathbb{T}} \\sum\\nolimits_{T&#039; \\in \\mathbb{T}&#039;} \\chi_T \\chi_{T&#039;} \\right).\n\\end{align}\nDilating space by R^{-1} and applying multi—linear Kakeya, we bound this quantity by\nR^{-n/2 - 1} \\#(\\mathbb{T}) \\#(\\mathbb{T}&#039;).\nRearranging, we find that\n\\mu \\lesssim \\#(\\mathbb{T}) \\#(\\mathbb{T}&#039;) \\#(\\mathcal{Q}) / R^{n+1}\nNow if the tubes in f have multiplicity \\mu_1 with X, and the tubes in g have multiplicity \\mu_2, then we find that \\mu_1 |X| \\sim \\lambda_1 R^{\\frac{n+1}{2}} \\# \\mathbb{T} and \\mu_2 |X| \\sim \\lambda_2 R^{\\frac{n+1}{2}} \\# \\mathbb{T}&#039; and \\#(\\mathcal{Q}) = R^{-n/2} |X| so we find that\n\\mu \\lesssim \\mu \\lambda_1^{-1} \\lambda_2^{-1} |X|^3 R^{-2.5n-2}\nThe multilinear Kakeya inequality (\\text{MLK}) implies that\n\\#(\\mathbb{A}) \\lesssim R^{- \\kappa n / 2} \\#(\\mathbb{T})^{(\\kappa/2) \\left( \\frac{n}{n-1} \\right)} \\#(\\mathbb{T}&#039;)^{(\\kappa/2) \\left( \\frac{n}{n-1} \\right)}.\nIf X is a union of M cubes from the set \\mathbb{A}, then the multilinear Kakeya inequality implies that at least half the cubes in X have multiplicity at most\n\\left( \\frac{\\#(\\mathbb{T})}{\\#(\\mathbb{A})} \\right)^{n-1} \\lambda^{1-n} R^{- \\frac{(n-1)^2}{2}} \\lesssim R^{n-1} \\lambda^{1-n}.\nIf we now consider a \\lambda-shading of the tubes of f and g, by linearity we conclude that a generic cube in X has multiplicity at most M \\leq m^{2 \\frac{n-1}{n}} R^{n-1} \\lambda^{1-n}, where m = m_1m_2.\n*The bound on M above doesn’t seem to be sharp enough to obtain the required bounds.\njust try using the Hölder’s inequality and seeing how far we get. We would hope to be able to prove that\n\\| Ef \\|_{L^{q_D}(X)} \\lesssim \\lambda_1^{-\\frac{1}{n+1}} R^{-\\beta} \\| f \\|_{L^2(\\Sigma)},\nand that\n\\| Eg \\|_{L^{q_D}(X)} \\lesssim \\lambda_2^{- \\frac{1}{n+1}} \\| g \\|_{L^2(\\Sigma)}.\nWe note that in this case, because the tubes are close to tangential, this means that, one a surface, the tubes must remain transverse when projected onto a surface.\nAn Alternate Inductive Setup\nWe might need to set\nE(f,g) = \\left( \\sum\\nolimits_{\\tau,\\tau&#039;} \\| T(f_\\tau, g_{\\tau&#039;}) \\|_{L^2(\\Sigma)}^4 \\right)^{1/4}. \\tag{3}\nOur goal would then be to show a bound of the form\n\\| T(f,g) \\|_{L^q(B_{R})} \\lessapprox R^{-1/2} E(f,g) \\tag{4}\nHölder’s inequality and L^2 bounds then imply bilinear restriction. But for now, let’s set\nE(f,g) = \\| f \\|_{L^2(\\Sigma)} \\| g \\|_{L^2(\\Sigma)}, \\tag{5}\nand try and prove\n\\| T(f,g) \\|_{L^q(B_{R})} \\lessapprox E(f,g), \\tag{6}\nwhich is precisely the multilinear bound we hope to obtain.\nFit Somewhere\nAssume f and g have \\sim m_1 and \\sim m_2 tubes in each of their directions. Let’s suppose that we have an inequality of the form\n\\left\\| \\left( \\sum \\chi_T \\chi_{T&#039;} \\right)^{1/2} \\right\\|_{L^{\\frac{n}{n-1}}(\\mathbb{R}^n)} \\lessapprox R^{(1 - \\kappa) \\frac{n-1}{2}} \\#(\\mathbb{T})^{\\kappa/2} \\#(\\mathbb{T}&#039;)^{\\kappa/2}. \\tag{MLK}\nfor direction separated families of transverse tubes. If, for a R^{1/2} ball Q, we define M(Q) to be the number of pairs of tubes T and T&#039; such that T \\cap T&#039; contain Q, then the Markov inequality\n\\# \\{ Q : M(Q) \\geq M_0 \\} \\lesssim R^{- (\\kappa/2) n} \\#(\\mathbb{T})^{(\\kappa/2) \\left( \\frac{n}{n-1} \\right)} \\#(\\mathbb{T}&#039;)^{(\\kappa/2) \\left( \\frac{n}{n-1} \\right)} M_0^{- \\frac{1}{2} \\left( \\frac{n}{n-1} \\right)}\nholds.\nNow suppose X is a union of N cubes from the set \\mathbb{A}. If f has m_1 tubes in each direction, and g has m_2 tubes in each direction, and we set m = m_1m_2, then the Markov inequality above implies that a generic cube in X has multiplicity\nO \\left(  m^{2 \\left( \\frac{n-1}{n} \\right)} R^{- \\kappa (n-1)} \\#(\\mathbb{T})^{\\kappa} \\#(\\mathbb{T}&#039;)^{\\kappa} N^{-2 \\left( \\frac{n-1}{n} \\right)} \\right)\nGiven an R^{1/2} discretized subset X of the support of T(f,g), if we can prove that each ball in X intersects at most M_1 tubes in f, and at most M_2 tubes in g, where M_1 M_2 \\lesssim M, and that f has m_1 tubes in each direction, and g has m_2 tubes in each direction, where m_1m_2 \\sim m, then simply by Hölder’s inequality and refined we conclude that\n\\| T(f,g) \\|_{L^{q_D}(X)} \\lesssim (M/m)^{\\frac{1}{n+1}} R^{- \\frac{1}{2} \\frac{n-1}{n+1}} \\| f \\|_{L^{q_D}(\\Sigma)} \\| g \\|_{L^{q_D}(\\Sigma)}\nIf we could guarantee that M/m \\lesssim R^{\\frac{n+1}{2} - \\alpha}, then this would complete the argument. In particular\n\nIn the completely transverse case \\alpha \\sim 1/2, we must prove M/m \\lesssim R^{n/2}.\nIn the least transverse case \\alpha \\sim 0, we must prove that M/m \\lesssim R^{\\frac{n+1}{2}}.\n\nHowever, in the argument above, we only have M \\lesssim m^{2 \\left( \\frac{n-1}{n} \\right)} R^{- \\kappa (n-1)} \\#(\\mathbb{T})^{\\kappa} \\#(\\mathbb{T}&#039;)^{\\kappa} N^{-2 \\left( \\frac{n-1}{n} \\right)}, which doesn’t seem sufficient to obtain these bounds, e.g. if m \\sim R then\nM/m \\lesssim R^{1-2/n-\\kappa(n-1)}\nR^{- \\kappa (n-1)} \\#(\\mathbb{T})^{\\kappa} \\#(\\mathbb{T}&#039;)^{\\kappa} M^{-2 \\left( \\frac{n-1}{n} \\right)} \\lesssim M_0\nasdawdaw\nLet Z be a slice of the wall. Because the intersection of the tubes in the decomposition of f with the wall are R^{1/2} \\times R^{1 - \\alpha} tubes, we obtain a bound\n\\| Ef_T \\|_{L^2(Z)} \\lesssim R^{1/2 - \\alpha} \\| f_T \\|_{L^2(\\Sigma)},\nand so because the tubes are almost orthogonal on sets that are R^{1/2} discretized, we obtain that\n\\| Ef \\|_{L^2(Z)} \\lesssim R^{1/2 - \\alpha} \\| f \\|_{L^2(\\Sigma)}.\nWe also have that\n\\| Eg \\|_{L^2(Z)} \\lesssim R^{1/2} \\| g \\|_{L^2(\\Sigma)}.\nIf X is a \\lambda_1-shading of the tubes in f contained within the variety Z, then we similarly obtain that\n\\| Ef \\|_{L^2(X)} \\lesssim \\lambda_1^{1/2} R^{1/2 - \\alpha} \\| f \\|_{L^2(\\Sigma)} \nand if X is a \\lambda_2-shading of the tubes in g contained within the variety Z, we obtain that\n\\| Eg \\|_{L^2(X)} \\lesssim \\lambda_2^{1/2} R^{1/2} \\| f ||_{L^2(\\Sigma)}.\nWe can use Hölder’s inequality to conclude that if X is a \\lambda_1 shading of the tubes in f and a \\lambda_2 shading of the tubes in g, then\n\\| T(f,g) \\|_{L^2(X)} \\lesssim (\\lambda_1 \\lambda_2)^{1/2} R^{1 - \\alpha} \\| f \\|_{L^2(\\Sigma)} \\| g \\|_{L^2(\\Sigma&#039;)}."},"Multilinear-Restriction-Project/Switching-Variables-in-Mixed-Norm-Extension-Estimates":{"slug":"Multilinear-Restriction-Project/Switching-Variables-in-Mixed-Norm-Extension-Estimates","filePath":"Multilinear Restriction Project/Switching Variables in Mixed Norm Extension Estimates.md","title":"Switching Variables in Mixed Norm Extension Estimates","links":["General-Zettels/Important-Exponents-in-Restriction-Theory"],"tags":[],"content":"Let d = n + m + 1, and let p = 2m/(m-2) be the Keel-Tao Exponent in \\mathbb{R}^{m+1}.\nTheorem Let \\phi(\\xi,\\eta) be a smooth function from \\mathbb{R}^n \\times \\mathbb{R}^m to \\mathbb{R} such that for all (\\xi,\\eta) \\in \\Omega, the Hessian matrix \\text{Hess}_y \\phi is invertible. Then for any smooth function a compactly supported on \\Omega, the extension operator\n\\mathcal{E} f(t,x,y) = \\int a(\\xi,\\eta) e^{i [\\phi(\\xi,\\eta) t + \\xi \\cdot x + \\eta \\cdot y]} f(\\xi,\\eta)\\; d\\xi\\; d\\eta\nmaps L^2(\\mathbb{R}^n \\times \\mathbb{R}^m) to (L^2_t L^2_x L^p_y)(B_R) with operator norm O_\\varepsilon(R^\\varepsilon) for all \\varepsilon &gt; 0, where B_R is the unit ball in \\mathbb{R}^{d+1}.\nWe claim this theorem cannot hold, because it would imply certain maximal estimates for the Schrödinger equation which cannot be true. In this note, we employ a change of variables trick in order to introduce this maximal norm.\nTo begin with, consider the extension operator for the paraboloid, i.e. the operator\n\\mathcal{E} f(t,x,y) = \\int a(\\xi,\\eta) e^{i[ (|\\xi|^2 + |\\eta|^2) t + \\xi \\cdot x + \\eta \\cdot y ]} f(\\xi,\\eta)\\; d\\xi\\; d\\eta,\nwhere a is smooth and compactly supported. Write \\eta = (\\tilde{\\eta}, \\eta_m), where \\tilde{\\eta} \\in \\mathbb{R}^{m-1} and \\eta_m \\in \\mathbb{R}. Write \\phi(\\xi,\\eta) = (\\eta_m - |\\xi|^2 - |\\tilde{\\eta}|^2)^{1/2}, and consider the coordinate transformation (\\xi,\\eta) = F(\\xi,\\eta), where F: \\mathbb{R}^n \\times \\mathbb{R}^{m-1} \\times \\mathbb{R} \\to \\mathbb{R}^n \\times \\mathbb{R}^m is given by F(\\xi,\\eta) = (\\xi,\\tilde{\\eta}, \\phi(\\xi,\\eta)). The map F is a diffeomorphism away from the paraboloid \\eta_m = |\\xi|^2 + |\\tilde{\\eta}|^2 in \\mathbb{R}^{n+m}, i.e. away from F^{-1}(\\mathbb{R}^n,0).\nIf we write \\tilde{a}(\\xi,\\eta) = a(F(\\xi,\\eta)) \\det( (DF)(\\xi,\\eta)), \\tilde{f}(\\xi,\\eta) = f(F(\\xi,\\eta)), and we write y = (\\tilde{y},y_m), then\n\\mathcal{E} f(t,x,y) = \\int \\tilde{a}(\\xi,\\eta) e^{i [\\eta_m t + \\xi \\cdot x + \\tilde{\\eta} \\cdot \\tilde{y} + \\phi(\\xi,\\eta) y_m ]} \\tilde{f}(\\xi,\\eta)\\; d\\xi\\; d\\eta\nWe can rewrite this identity as\n\\mathcal{E} f(t,x,y) = \\tilde{\\mathcal{E}} \\tilde{f}(y_d,x,\\tilde{y},t)\nwhere \\tilde{\\mathcal{E}} is the operator\n\\tilde{\\mathcal{E}} f(t,x,y) = \\int \\tilde{a}(\\xi,\\eta) e^{i [ \\phi(\\xi,\\eta) t + \\xi \\cdot x + \\eta \\cdot y ]} f(\\xi,\\eta)\\; d\\xi\\; d\\eta.\nThen we claim that \\text{Hess}_\\eta \\phi has determinant 0.25 (-1/\\phi)^{m+2}. so that we may apply Theorem to \\tilde{\\mathcal{E}} provided \\tilde{a} is supported away from the paraboloid \\phi = 0, which is equivalent to a being supported away from the line \\eta_m = 0. We calculate this Hessian at the End of this note.\nSo provided that a is supported away from the line \\eta_m = 0, we can apply the Theorem to conclude that \\tilde{\\mathcal{E}} maps L^2(\\mathbb{R}^n \\times \\mathbb{R}^m) to (L^2_t L^2_x L^p_y)(B_R) with operator norm O_\\varepsilon(R^\\varepsilon) for all \\varepsilon &gt; 0. But applying the identity (1) above, noting that \\| \\tilde{f} \\|_{L^2} \\sim \\| f \\|_{L^2} for any f in L^2(\\mathbb{R}^n \\times \\mathbb{R}^m) with compact support, we conclude that \\mathcal{E} maps L^2(\\mathbb{R}^n \\times \\mathbb{R}^m) into (L^2_{y_m} L^2_x L^p_{\\tilde{y},t})(B_R) with operator norm O_\\varepsilon(R^\\varepsilon) for all \\varepsilon &gt; 0.\nIn particular, if m = 2 then we conclude that \\mathcal{E} maps L^2(\\mathbb{R}^n \\times \\mathbb{R}^m) to (L^2_{y_m} L^2_x L^\\infty_{\\tilde{y},t})(B_R), which implies that the operator T = \\mathcal{E} \\circ \\mathcal{E}^*, which is given by\nTf(t,x,y) = \\int e^{i(t-s) \\Delta} \\{ f(s) \\}(x,y)\\; ds\nis bounded from (L^2_{y_m} L^2_x L^1_{\\tilde{y},t})(B_R) to (L^2_{y_m} L^2_x L^\\infty_{\\tilde{y},t})(B_R).\nAppendix: Hessian Computation\nIn this appendix, we prove that \\text{Hess}_\\eta \\phi has determinant 0.25 (-1/\\phi)^{m+2}, where \\phi(\\xi,\\eta) = (\\eta_m - |\\xi|^2 - |\\tilde{\\eta}|^2). We calculate that\n\\nabla_\\eta \\phi(\\xi,\\eta) = 0.5 \\phi^{-1} ( - 2 \\tilde{\\eta}, 1 )\nand thus that\n\\text{Hess}_\\eta \\phi(\\xi,\\eta) = \\begin{pmatrix} - \\phi^{-3} \\tilde{\\eta} \\tilde{\\eta}^T - \\phi^{-1} I_{m-1} &amp; 0.5 \\phi^{-3} \\tilde{\\eta} \\\\ 0.5 \\phi^{-3} \\tilde{\\eta}^T &amp; - 0.25 \\phi^{-3} \\end{pmatrix} = \\begin{pmatrix} A &amp; B \\\\ C &amp; D \\end{pmatrix}\nThe determinant of this matrix is equal to D \\det(A - BD^{-1} C). We compute that\nBD^{-1} C = -4 \\phi^3 (BC) = - \\phi^{-3} \\tilde{\\eta} \\tilde{\\eta}^T\nso\nA - BD^{-1} C = - \\phi^{-1} I_{m-1}\nand thus\n\\det(A - BD^{-1}C) = (- \\phi^{-1})^{m-1}\nThus the determinant of \\text{Hess}_\\eta \\phi is equal to 0.25 (-1/\\phi)^{m+2}."},"2.-General-Zettels/Broad-Narrow-Analysis":{"slug":"2.-General-Zettels/Broad-Narrow-Analysis","filePath":"2. General Zettels/Broad-Narrow Analysis.md","title":"Broad-Narrow Analysis","links":["2015---Guth---A-Restriction-Estimate-Using-Polynomial-Partitioning","1998---Tao-Vargas-Vega---A-Bilinear-ApproachT-to-the-Restriction-and-Kakeya-Conjectures"],"tags":[],"content":"We aim to obtain a bound\n\\| Ef \\|_{L^p(B_R)} \\lessapprox \\| f \\|_{L^p(\\Sigma)}\nby using multilinear restriction estimates and decoupling estimates.\nFix K &gt; 0, and cover B_R by balls B of radius A, where K \\ll A \\leq K^{O(1)}. Similarly, decompose \\Sigma into a family \\Theta of caps \\theta of diameter 1/K. For each cap \\theta, we let n(\\theta) denote the normal vector to \\Sigma at the center of the cap. We will pick K \\lessapprox 1. In particular, it then follows that \\#(\\Theta) = K^{O(1)} \\lessapprox 1, so that we can analyze each ball B separately and then put estimates together using the triangle inequality.\nFor each ball B, let S(B) be the set of all \\theta \\in \\Theta so that\n\\| Ef_\\theta \\|_{L^p(B)} \\gg \\frac{\\| Ef \\|_{L^p(B)}}{\\#(\\Theta)}.\nThen\n\\| Ef \\|_{L^p(B)} \\sim \\left\\| \\sum\\nolimits_{\\theta \\in S(B)} Ef_\\theta \\right\\|_{L^p(B)}.\nIn fact, we have \\| Ef \\|_{L^p(B)} \\approx \\| Ef_\\theta \\|_{L^p(B)} for each \\theta \\in S(B).\nFix k \\in \\{ 2, \\dots, d \\}. We say a ball B is k-narrow if there exists a k-1 dimensional plane H in \\mathbb{R}^d so that the set of vectors \\{ n(\\theta): \\theta \\in S(B) \\} all make an angle at most 1/K with H. Otherwise, call the ball B a k-broad ball.\nIf B is a k-broad ball, then there exists k caps \\theta_1, \\dots, \\theta_k in S(B) so that\n|n(\\theta_1) \\wedge \\cdots \\wedge n(\\theta_k)| \\gtrsim 1/K.\nWe would like to obtain a bound of the form\n\\left\\| Ef \\right\\|_{L^p(B)} \\lessapprox \\left\\| \\prod\\nolimits_j |Ef_{\\theta_j}|^{1/k} \\right\\|_{L^p(B)}\nso that we can apply the multi-linear restriction theorem. The converse follows from Hölder’s inequality and that \\| Ef_{\\theta_j} \\|_{L^p(B)} \\sim \\| Ef \\|_{L^p(B)}, so we should think of this as a kind of reverse Hölder’s inequality.\nIf B were a ball of radius K, then by local constancy we could guarantee this reverse Hölder’s inequality, if we are willing to work with rapidly decaying cutoff functions around the balls B, rather than L^p norms on the balls themselves, i.e. proving a bound of the form\n\\left\\| Ef \\right\\|_{L^p(w_B)} \\lessapprox \\left\\| \\prod\\nolimits_j |Ef_{\\theta_j}|^{1/k} \\right\\|_{L^p(w_B)}\nLet us prove that\n\\left\\| Ef \\right\\|_{L^p(w_B)} \\lessapprox \\left\\| |Ef_{\\theta_1}|^t |Ef_{\\theta_2}|^{1-t} \\right\\|_{L^p(w_B)}\nUsing Bernstein’s inequality, we may assume without loss of generality that p \\geq 2/t, since the result for any particular 1 &lt; p &lt; \\infty implies the result for all p. Find a set S \\subset \\mathbb{R}^d so that \\| 1_S \\|_{L^1(w_B)} \\geq 0.999 \\| 1 \\|_{L^1(w_B)} and for x \\in S, |Ef_{\\theta_2}(x)| \\sim \\| Ef \\|_{L^p(w_B)} K^{-d/p}. Then applying the general reverse Hölder’s inequality for L^p spaces, we have\n\\begin{align}\n\\left\\| |Ef_{\\theta_1}|^t |Ef_{\\theta_2}|^{1-t} 1_S \\right\\|_{L^p(w_B)} &amp;= \\| |Ef_{\\theta_1}|^{tp} |Ef_{\\theta_2}|^{p(1-t)} 1_S \\|_{L^1(w_B)}^{1/p}\\\\\n&amp;\\geq \\| |Ef_{\\theta_1}|^{tp} \\|_{L^{1/2}(w_B)}^{1/p} \\| |Ef_{\\theta_2}|^{p(1-t)} 1_S \\|_{L^{-1}(w_B)}^{1-t}\\\\\n&amp;= \\| Ef_{\\theta_1} \\|_{L^{tp/2}(w_B)}^t \\| Ef_{\\theta_2} 1_S \\|_{L^{-p(1-t)}(w_B)}^{1-t}\\\\\n&amp;\\sim \\left[ K^{(d/p)(2/t - 1)} \\| Ef \\|_{L^p(w_B)} \\right]^t \\left[ \\| Ef \\|_{L^p(w_B)} K^{-d/p} K^{\\frac{-d}{p(1-t)}} \\right]^{1-t}\\\\\n&amp;\\sim \\| Ef \\|_{L^p(w_B)}\n\\end{align}\nWe used the Sobolev embedding term to bound the first term in the second last line. But. now the general result follows by induction, since \\prod_j Ef_{\\theta_j} also satisfies the local constancy property.\nFor larger balls, this argument clearly cannot be generalized, but we instead use a random translation argument as a substitute. For each j, we can find a ball B_j of radius K so that \\| Ef_{\\theta_j} \\|_{L^p(w_{B_j})} \\geq (A/K)^d \\| Ef \\|_{L^p(w_B)}. If we consider vectors \\nu_1,\\dots,\\nu_k chosen uniformly at random from B^*, then with probability \\Omega((A/K)^{k-1}), the set S = \\text{Trans}_{\\nu_1} S_1 \\cap \\cdots \\cap \\text{Trans}_{\\nu_k} S_k contains a ball B_0 of radius \\Omega(K). Then by local constancy, \\| Ef_{\\theta_j} \\|_{L^p(w_{B_0})} \\gtrapprox (A/K)^d \\| Ef \\|_{L^p(w_B)} for each j, and so by the reverse Hölder’s inequality we proved above, we conclude that\n(A/K)^d \\left\\| Ef \\right\\|_{L^p(w_{B_0})} \\lessapprox \\left\\| \\prod\\nolimits_j |\\text{Trans}_{\\nu_j} Ef_{\\theta_j}|^{1/k} \\right\\|_{L^p(B_0)}\nThus we find that\n\\| Ef \\|_{L^p(w_{B_0})} \\lessapprox \\mathbb{E}_\\nu \\left\\| \\prod\\nolimits_j |\\text{Trans}_{\\nu_j} Ef_{\\theta_j}|^{1/k} \\right\\|_{L^p(B_0)}.\nStudying \\text{Trans}_{\\nu_j} Ef_{\\theta_j} is no more difficult than studying Ef_{\\theta_j} because we can write the translation into modulation of f_{\\theta_j}, i.e. \\text{Trans}_{\\nu_j} Ef_{\\theta_j} = E \\{ e_{\\nu_j} f_{\\theta_j} \\} where e_{\\nu_j}(x) = e^{-2 \\pi i \\nu_j \\cdot x}. We can then apply the multilinear inequality to each of the translations and thus obtain appropriate bounds.\nThe functions Ef_\\theta are locally constant on balls of radius K, so the reverse would follow if A = K from local constancy. But for A \\gg K the two quantities could be completely incomparable, since the functions |Ef_{\\theta_j}| could be large where the other |Ef_{\\theta_k}| are very small.\nThe fix for this is that, if we translate the functions Ef_{\\theta_j} at random, then by local constancy there is probability O(K^{-O(1)}) that the regions where the functions are large all align. More precisely, by local constancy we can find a ball B_j \\subset B of radius K upon which \\| Ef_{\\theta_j} \\|_{L^p(B_j)} \\gtrapprox \\| Ef_{\\theta_j} \\|_{L^p(B)}. Then by local constancy (Bernstein’s inequality), \\| Ef_{\\theta_j} \\|_{L^p(B_j)} \\sim K^d \\| Ef_{\\theta_j} \\|_{L^\\infty(B_j)}\nThen if \\nu_1,\\dots,\\nu_k are vectors chosen uniformly at random from the ball of radius A, then with probability O(K^{-O(1)}), the set U = \\bigcap_j \\text{Trans}_{\\nu_j} B_j satisfies U \\gtrsim K.\nThen for some \\{ \\nu_j \\}, by local constancy,\n\\left\\| \\prod\\nolimits_j \\text{Trans}_{\\nu_j} Ef_{\\theta_j} \\right\\|_{L^p(U)}\nIf we define \\text{Trans}_\\nu Ef_{\\theta_j}\nlocal constancy only gives that\n\\| Ef \\|_{L^p(B)} \\sim \\left( \\sum \\| Ef \\|_{L^p(B_k)}^p \\right)^{1/p} \\sim \\prod \\| Ef_\\theta \\|_{L^p(B)}^{1/k} \\lesssim A^d \\prod \\| Ef_\\theta \\|_{L^\\infty(B)}^{1/k}\nif l &gt; 1 then the converse doesn’t quite work. The trick is to consider random translations\nIt then follows from a translation trick, Tacy’s theorem (we likely have to make another assumption on the caps so they don’t lie in a non-curved subspace), and a wave packet decomposition of each E f_{\\theta_j} into tubes T_j that\n\\| Ef \\|_{L^p(B)} \\leq K^{O(1)} \\left( \\prod\\nolimits_j \\left\\| \\sum\\nolimits_{\\nu_j \\in S(B,\\theta_j)} f_{\\theta_j,\\nu_j} \\right\\|_{L^2(\\Sigma)} \\right)^{1/k} \\leq K^{O(1)} \\max\\nolimits_j \\left\\| \\sum\\nolimits_{\\nu_j \\in S(B,\\theta_j)} f_{\\theta_j,\\nu_j} \\right\\|_{L^2(\\Sigma)}.\nSince each \\nu_j is in S(B,\\theta_j) for at most K^{O(1)} different balls B, L^2 orthogonality of tubes implies that\n\\| Ef \\|_{L^p(\\text{Broad})} \\leq K^{O(1)} \\| f \\|_{L^2(\\Sigma)} \\leq K^{O(1)} \\| f \\|_{L^p(\\Sigma)}.\nNow we deal with the narrow case. Suppose that B is a k-narrow ball. Then there exists\nusing decoupling inequalities. Suppose that B is a narrow ball, and S(B) is such that we have a decoupling inequality\n\\| Ef \\|_{L^p(B)} \\lesssim K^{O(1)} \\left( \\sum \\| Ef_\\theta \\|_{L^p(B)}^2 \\right)^{1/2}.\nSumming over all narrow balls B using the finite overlap property, we obtain that\n\\| Ef \\|_{L^p(\\text{Narrow})} \\lesssim K^{O(1)} \\left( \\sum \\| Ef_\\theta \\|_{L^p(B_R)}^2 \\right)^{1/2}.\nWe now bound each term \\| Ef_\\theta \\|_{L^p(B_R)} using induction on scales. Namely, we can find a function g_\\theta on \\Sigma for each \\theta so that \\| g \\|_{L^p(\\Sigma)} = K^{\\frac{d-1}{p}} \\| f_\\theta \\|_{L^p(\\Sigma)} and \\| Ef_\\tau \\|_{L^p(B_R)} \\lesssim K^{\\frac{d+1}{p} - (d-1)} \\| Eg \\|_{L^p(B_{R/K})}. Applying induction on scales, letting C(R) be the best constant in the extension inequality on B_R, we find that\n\\| Ef \\|_{L^p(\\text{Narrow})} \\lesssim K^{\\frac{2d}{p} - (d-1)} C(R/K).\nPutting together the analysis of the broad and narrow cases, we find that\nC(R) \\lesssim K^{O(1)} + C K^{\\frac{2d}{p} - (d-1)} C(R/K).\nSince p &gt; 2d(d-1), for all \\varepsilon &gt; 0, if we choose K = R^\\delta for \\delta sufficiently small, depending on \\varepsilon, we conclude that C(R) \\lesssim_\\varepsilon R^\\varepsilon.\nWe likely can use decoupling in the right range provided that the k-1 dimensional hypersurface on which the caps are concentrated is appropriately curved. The amount of curvature required is not completely apparent I need to ask Jonathan what the range of decoupling estimates are known in the case that we have degenerate hyper-surfaces.\nGuth Polynomial Partitioning Broad Narrow Argument\nFix K &gt; 0, and divide a hypersurface \\Sigma in \\mathbb{R}^d into caps \\tau of diameter O(K^{-1}). Given a function f on \\Sigma, let g = Ef. Then a point x \\in \\mathbb{R}^d is \\alpha broad if \\max |Ef_\\tau(x)| \\leq \\alpha |Ef(x)|. If a point is not \\alpha broad, then it is \\alpha narrow, which means there is some \\tau_0 with |Ef(x)| \\leq \\alpha^{-1} |Ef_{\\tau_0}(x)|. This gives a smaller scale which can bound the current scale of analysis, so induction on scales often allows us to bound the behavior of the extension operator at narrow points, and we may thus restrict our attention to the behavior at broad points.\nMore precisely, if we define \\text{Br}_\\alpha(g) to be equal to g at broad points, and equal to zero at narrow points, then we have a pointwise bound\n |g| \\leq |\\text{Br}_\\alpha(g)| + \\alpha^{-1} \\max\\nolimits_{\\tau_0} |Ef_{\\tau_0}|\nInduction on scales bounds |Ef_{\\tau_0}| uniformly, so it suffices to estimate |\\text{Br}_\\alpha(g)|. The advantage of reducing to the broad case is that one can often reduce to multilinear estimates, given that the caps \\{ \\tau_0 \\} are suitably transverse to one another.\nIn more sophisticated contexts, it is useful to be more quantitative, especially when considering estimates closer to k-linear analysis. We define a measure \\mu = \\mu_a^p, locally constant at a scale K^2, so that for a  ball of radius K^2,\n \\mu^p(f,B) = \\min\\nolimits_{V_1,\\dots,V_a} \\max\\nolimits_{\\tau \\in \\text{Tr}(V_1,\\dots,V_a)} \\int_B |Ef_\\tau|^p\nwhere V_1,\\dots,V_a are k-dimensional subspaces, and \\text{Tr}(V_1,\\dots,V_A) is the set of caps transverse to all V_1,\\dots,V_a, more precisely, making an angle greater than 1/K with each subspace. We then define, for a set U constant at a scale K^2,\n \\| Ef \\|_{\\text{BL}_{k,a}^p(U)} = \\left( \\sum\\nolimits_{B \\subset U} \\mu^p(f,B) \\right)^{1/p}\nThe need to choose a &gt; 1 is required so that the broad norm is semi-additive and satisfies the Holder inequality. We often choose a \\sim 1. On a particular ball of radius K^2, we are only bounding those \\| Ef_{\\tau_0} \\|_{L^p(B)} for which there exists \\tau_1,\\dots,\\tau_{k-1} with \\tau_0 \\wedge \\cdots \\wedge \\tau_{k-1} \\gtrsim 1 and \\| Ef_{\\tau_i} \\|_{L^p(B)} \\gtrsim \\| Ef_\\tau \\|_{L^p(B)}. The most useful property of the broad norm is that if we are only studying tubes that are tangent to a k-1 dimensional variety, then the broad norm of Ef is essentially zero (for whenever the tubes intersect, they do so in a way that is not k transverse).\nIn the multilinear case, what gets thrown out?\n\nGuth uses the method to prove his L^\\infty(\\Sigma) \\to L^p(\\mathbb{R}^3) restriction estimate for p &gt; 3.25.\nGuth states that his broad narrow analysis is similar to the bilinear restriction methods of Tao, Vargas, and Vega, but I have not looked into this paper.\n"},"2.-General-Zettels/Enemies-in-Multilinear-Restriction":{"slug":"2.-General-Zettels/Enemies-in-Multilinear-Restriction","filePath":"2. General Zettels/Enemies in Multilinear Restriction.md","title":"Enemies in Multilinear Restriction","links":["2.-General-Zettels/The-Wave-Packet-Decomposition-For-Extension-Operators"],"tags":[],"content":"A regulus S is a degree 2 algebraic surface in \\mathbb{R}^3 which is doubly ruled, i.e. there are two families of lines, which we might call horizontal and vertical, and each point lies in a horizontal line and a vertical line.\n\nPlanar Examples:\nReguli: Consider Wave Packets f = \\sum f_T, where the sum is restricted to R^{1/2} \\times R tubes taking from the ruling of S \\cap B_R, with each wave packet having the same L^2 norm. This example is sharp for some bilinear restriction estimates.\n"},"2.-General-Zettels/Important-Exponents-in-Restriction-Theory":{"slug":"2.-General-Zettels/Important-Exponents-in-Restriction-Theory","filePath":"2. General Zettels/Important Exponents in Restriction Theory.md","title":"Important Exponents in Restriction Theory","links":["Problems/The-Multilinear-Restriction-Conjecture"],"tags":[],"content":"Here we are working with restriction operators for curved hypersurfaces of dimension n in \\mathbb{R}^d. We also look at the value of |1/p - 1/2|, which we call the Distance to 1/2.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nExponentValueDistance to 1/2Restriction Exponent\\frac{2d}{d-1}\\frac{1}{2d}Stein-Tomas Exponent\\frac{2(d+1)}{d+3}\\frac{1}{d+1}Dual Stein-Tomas ExponentDecoupling Exponent\\frac{2(d+1)}{d-1}\\frac{1}{d+1}Keel-Tao ExponentDual Heo-Nazarov-Seeger Exponent\\frac{2(d-1)}{d-3}\\frac{1}{d-1}Heo-Nazarov-Seeger Exponent\\frac{2(d-1)}{d+1}\\frac{1}{d-1}Multilinear Restriction (k-linear)\\frac{2(d+k)}{d+k-2}\\frac{1}{d+k}"},"2.-General-Zettels/Induction-on-Scales":{"slug":"2.-General-Zettels/Induction-on-Scales","filePath":"2. General Zettels/Induction on Scales.md","title":"Induction on Scales","links":["2006---Bennett-Carbery-Tao---On-The-Multilinear-Restriction-And-Kakeya-Conjectures","1998---Tao-Vargas-Vega---A-Bilinear-Approach-to-the-Restriction-and-Kakeya-Conjectures"],"tags":[],"content":"Suppose C(R) is a finite quantity chosen for each integer R &gt; 0, such that, by some (hopefully trivial) argument, we can justify C(R) = R^{O(1)}. The goal of induction on scales is, by bounding C(R) in terms of C(R&#039;) for a small R&#039;, to obtain a bound C(R) \\lesssim_\\varepsilon R^\\varepsilon for all \\varepsilon &gt; 0. We write A \\lessapprox B if A \\lesssim_\\varepsilon R^\\varepsilon B for all \\varepsilon &gt; 0.\n\nIf C(R) \\lessapprox C(R^\\alpha) for some 0 &lt; \\alpha &lt; 1 and all \\varepsilon &gt; 0, and we know that C(R) \\lesssim R^{O(1)}, then induction on scales can guarantee that C(R) \\lessapprox 1. This is used, for instance in the Bennett Carbery Tao Multilinear Restriction Theorem.\nIf C(R) \\lessapprox C(R^{1 - \\delta}) + R^{O(\\delta)} for all \\delta &gt; 0, then C(R) \\lessapprox 1. This is used, for instance, in Tao Vargas Vega.\nIf C(R) \\lesssim_\\varepsilon (1 + \\varepsilon) C(R/10) then we obtain that C(R) \\lessapprox 1.\n"},"2.-General-Zettels/Local-Constancy-Heuristics-and-the-Uncertainty-Principle":{"slug":"2.-General-Zettels/Local-Constancy-Heuristics-and-the-Uncertainty-Principle","filePath":"2. General Zettels/Local Constancy Heuristics and the Uncertainty Principle.md","title":"Local Constancy Heuristics and the Uncertainty Principle","links":[],"tags":[],"content":"Let f be a function whose Fourier transform is supported on the ball \\{ \\xi : |\\xi| \\leq R \\}. The local constancy heuristic, or the uncertainty principle, says that f is ‘locally constant’ at a scale 1/R. There are several ways of making this precise:\nBernstein’s Inequality\nIf a function f was locally constant at a scale 1/R, then on each ball B of radius 1/R, we might expect the function f as having a certain ‘height’ H. It would then follow that \\| f \\|_{L^p(B)} \\sim H R^{-d/p}. In particular, this would imply that R^{d/p} \\| f \\|_{L^p(B)} \\sim R^{d/q} \\| f \\|_{L^q(B)} for all 1 \\leq p \\leq q \\leq \\infty. This is, heuristically speaking, the case, if we replace local integrals on B with pseudo-local integrals. One direction of this inequality follows immediately from Hölder’s inequality. The other requires slightly more work.\nFirst, Bernstein’s inequality says that\n\\| f \\|_{L^{p,s}(\\mathbb{R}^d)} \\lesssim R^s \\| f \\|_{L^p(\\mathbb{R}^d)}.\nBut this equation can also be localized. Fix r &gt; s, which can be arbitrarily large. For each B, let w_B = \\left\\langle  \\frac{d(x,B)}{\\text{Rad}(B)} \\right\\rangle^{-r}, and let \\tilde{w}_B = \\left\\langle  \\frac{d(x,B)}{\\text{Rad}(B)} \\right\\rangle^{-t} for t \\leq s-r. Then Bernstein’s inequality says that\n\\| f \\|_{L^{p,s}(w_B)} \\lesssim R^s \\| f \\|_{L^p(\\tilde{w}_B)}.\nTo prove this result, we may assume by rescaling symmetries that R = 1. We then find a Schwartz function \\chi with |\\chi(x)| \\geq 1 for |x| \\leq 1, but with \\widehat{\\chi}(\\xi) supported on |\\xi| \\lesssim 1. Applying the usual Bernstein inequality, if we let \\chi_l(x) = \\chi(x / 2^l), then we have\n\\| f \\|_{L^{p,s}(w_B)} \\lesssim \\sum\\nolimits_{l \\geq 0} 2^{-lr} \\| \\chi_l f \\|_{L^{p,s}(\\mathbb{R}^d)} \\lesssim \\sum\\nolimits_{l \\geq 0} 2^{l(s-r)} \\| \\chi_l f \\|_{L^p(\\mathbb{R}^d)} \\lesssim \\| f \\|_{L^p(\\tilde{w}_B)}\nA similar argument using the Sobolev embedding theorem shows that the L^p improving inequality \\| f \\|_{L^q(w_B)} \\lesssim R^{d(1/p - 1/q)} \\| f \\|_{L^p(\\tilde{w}_B)} holds for p \\leq q &lt; \\infty, where w_B and \\tilde{w}_B are defined above, and where s = d(1/p - 1/q). In particular, since in this case s is always bounded by d. Customarily, one uses r &gt; d so that the inequality holds also when q = \\infty.\nPointwise Bounds\nIt follows from Bernstein’s inequality that if r &gt; d, then for each ball B, and for 1 \\leq p \\leq q \\leq \\infty,\n\\| f \\|_{L^q(B)} \\lesssim R^{d(1/p - 1/q)} \\| f \\|_{L^p(w_B)}\nLet us suppose that \\| f \\|_{L^p(w_B)} \\lesssim \\| f \\|_{L^p(B)}. This is often the case in practical considerations whe analyzing balls B which are significant to the L^p norm of the entire function f, i.e. if \\| f \\|_{L^q(B)} \\geq C^{-1} \\| f \\|_{L^q(\\mathbb{R}^d)} for some fixed constant C. Then we have the inequality\n\\| f \\|_{L^q(B)} \\lesssim R^{d(1/p - 1/q)} \\| f \\|_{L^p(B)}.\nIn particular, f is bounded by H_B = R^{d/p} \\| f \\|_{L^p(B)} on B. But this implies that for any \\varepsilon &gt; 0, there exists \\delta &gt; 0, depending only on the implicit constants, such that all but a fraction \\varepsilon of the points in B satisfy\n\\delta H_B \\leq |f(x)| \\lesssim H_B.\nThus we can think of f as having height H_B on almost all points of B, which is a kind of locally constant heuristic.\nMore generally, a version from this result follows if \\| f \\|_{L^p(w_B)} \\sim \\| f \\|_{L^p(\\tilde{w}_B)}, i.e. so that the L^p mass of f is not concentrated too far away from the ball B. We then conclude that for all \\varepsilon &gt; 0, there exists \\delta &gt; 0 so that for all but a fraction \\varepsilon of the points in \\mathbb{R}^d (with the fraction measured with respect to the weight w_B) satisfy \\delta H_B \\leq |f(x)| \\lesssim H_B."},"2.-General-Zettels/Polynomial-Partitioning":{"slug":"2.-General-Zettels/Polynomial-Partitioning","filePath":"2. General Zettels/Polynomial Partitioning.md","title":"Polynomial Partitioning","links":["2015---Guth-Katz---On-The-Erdos-Distinct-Distances-Problem-in-the-Plane","2008---Dvir---On-the-Size-of-Kakeya-Sets-in-Finite-Fields","1990---Clarkson-Edelsbrunner-Guibas-Sharir-Welzl---Combinatorial-Complexity-Bounds-for-Arrangements-of-Curves-and-Spheres"],"tags":[],"content":"The idea of polynomial partitioning, introduced by Guth and Katz in their 2015 Paper on the Erdos distinct distances problem, is to combine the polynomial incidence geometric methods of Dvir with the divide and conquer approaches of divide and conquer partitioning approach introduced by CEGSW in incidence geometry.\nGiven a set X \\subset \\mathbb{R}^d of N points, the polynomial method allows us to find a polynomial of degree O(N^{1/d}) vanishing on X. In polynomial partitioning, for any D, we can choose a polynomial of degree D defining a hypersurface Z, such that \\mathbb{R}^d - Z is divided into O(D^d) cells, each containing O(N/D^d) points from X. The surface Z is called the cell wall, and the connected components of \\mathbb{R}^d - Z are called the cells. The problem then breaks down into two regimes:\n\nIf X contains few points in the cell wall, it must be evenly divided into each of the cells, so methods akin to  CEGSW apply.\nIf X contains many points in the cell wall, then we obtain structural information akin to Dvir’s Method.\n\nThe problem can also be applied to continuous problems. If f is a function on \\mathbb{R}^d, then for any D we can find a hypersurface Z defined by a polynomial of degree D so that the L^1 norm of f on each cell cut out by the surface Z is the same. However, to fully exploit the polynomial structure in the continuous setting we must often thicken the cell wall, so that e.g. any ‘transverse’ tube passes through the surface Z at most D times, and thus enters at most D + 1 cells. If the tubes we are considering have thickness \\delta, then we should let the \\delta neighborhood Z_\\delta of Z be the cell wall, and let the cells be the connected components of \\mathbb{R}^d - Z_\\delta. This is because it then follows that if a tube passes through a cell of \\mathbb{R}^d - Z_\\delta, then it’s central line passes through the corresponding cell in \\mathbb{R}^d - Z, and can only do this at most D + 1 times."},"2.-General-Zettels/Random-Rotations-Trick":{"slug":"2.-General-Zettels/Random-Rotations-Trick","filePath":"2. General Zettels/Random Rotations Trick.md","title":"Random Rotations Trick","links":[],"tags":[],"content":""},"2.-General-Zettels/Rapidly-Decaying-Wave-Packet-Weights":{"slug":"2.-General-Zettels/Rapidly-Decaying-Wave-Packet-Weights","filePath":"2. General Zettels/Rapidly Decaying Wave Packet Weights.md","title":"Rapidly Decaying Wave Packet Weights","links":[],"tags":[],"content":"TODO\nUsing translation invariance, can go from local estimates to weighted estimates, so that the inequalities can be composed."},"2.-General-Zettels/Reverse-Hölder's-Inequality-For-Fourier-Localized-Functions":{"slug":"2.-General-Zettels/Reverse-Hölder's-Inequality-For-Fourier-Localized-Functions","filePath":"2. General Zettels/Reverse Hölder's Inequality For Fourier Localized Functions.md","title":"Reverse Hölder's Inequality For Fourier Localized Functions","links":["2.-General-Zettels/Local-Constancy-Heuristics-and-the-Uncertainty-Principle"],"tags":[],"content":"Suppose g_1,\\dots,g_k are functions with Fourier transform supported on balls of radius R. Suppose also that w_B and \\tilde{w}_B are weight functions, where w_B decays at a rate d times faster than \\tilde{w}_B, then for any ball B of radius 1/R,\nR^{d/p} \\prod\\nolimits_j \\| g_j \\|_{L^p(\\tilde{w}_B)}^{1/k} \\lesssim \\left\\| \\prod\\nolimits_j |g_j|^{1/k} \\right\\|_{L^p(w_B)}\nIn particular,\nR^{d/p} \\prod\\nolimits_j \\| g_j \\|_{L^p(B)}^{1/k} \\lesssim \\left\\| \\prod\\nolimits_j |g_j|^{1/k} \\right\\|_{L^p(w_B)}.\nThis is called a reverse Hölder’s Inequality because if we flip the inequality and forget about weights, then the inequality is a special case of Hölder’s inequality.\nRescaling, we may assume R = 1. The result follows by applying the Pointwise Locally Constant Property, together with a union bound, to conclude that 99% of all points in \\mathbb{R}^d, with respect to the weight \\tilde{w}_B, satisfy |g_j(x)| \\gtrsim R^{d/p} \\| g_j \\|_{L^p(w_B)}^{1/k} for each j, and for such points, we thus have \\prod_j |g_j|^{1/k} \\sim R^{d/p} \\prod_j \\| g_j \\|_{L^p(w_B)}^{1/k}. Integrating over this region, the inequality immediately follows.\nAn Alternate Approach\nThis method may have technical problems. The result would follow if we could prove the bilinear result\n\\left\\| f_1 \\right\\|_{L^p(\\tilde{w}_B)} \\| f_2 \\|_{L^p(\\tilde{w}_B)} \\lessapprox \\left\\| |f_1|^t |f_2|^{1-t} \\right\\|_{L^p(\\tilde{w}_B)},\nsince we could then apply induction. Using Bernstein’s inequality, we may assume without loss of generality that p \\geq 2/t, since the result for any particular 1 &lt; p &lt; \\infty implies the result for all p. Find a set S \\subset \\mathbb{R}^d so that \\| 1_S \\|_{L^1(w_B)} \\geq 0.999 \\| 1 \\|_{L^1(w_B)} and for x \\in S, |Ef_{\\theta_2}(x)| \\sim \\| Ef \\|_{L^p(w_B)} K^{-d/p}. Then applying the general reverse Hölder’s inequality for L^p spaces, we have\n\\begin{split}\n\\left\\| |Ef_{\\theta_1}|^t |Ef_{\\theta_2}|^{1-t} 1_S \\right\\|_{L^p(w_B)} &amp;= \\| |Ef_{\\theta_1}|^{tp} |Ef_{\\theta_2}|^{p(1-t)} 1_S \\|_{L^1(w_B)}^{1/p}\\\\\n&amp;\\geq \\| |Ef_{\\theta_1}|^{tp} \\|_{L^{1/2}(w_B)}^{1/p} \\| |Ef_{\\theta_2}|^{p(1-t)} 1_S \\|_{L^{-1}(w_B)}^{1-t}\\\\\n&amp;= \\| Ef_{\\theta_1} \\|_{L^{tp/2}(w_B)}^t \\| Ef_{\\theta_2} 1_S \\|_{L^{-p(1-t)}(w_B)}^{1-t}\\\\\n&amp;\\sim \\left[ K^{(d/p)(2/t - 1)} \\| Ef \\|_{L^p(w_B)} \\right]^t \\left[ \\| Ef \\|_{L^p(w_B)} K^{-d/p} K^{\\frac{-d}{p(1-t)}} \\right]^{1-t}\\\\\n&amp;\\sim \\| Ef \\|_{L^p(w_B)}\n\\end{split}\nWe used the Sobolev embedding term to bound the first term in the second last line. But. now the general result follows by induction, since \\prod_j Ef_{\\theta_j} also satisfies the local constancy property."},"2.-General-Zettels/Shadings":{"slug":"2.-General-Zettels/Shadings","filePath":"2. General Zettels/Shadings.md","title":"Shadings","links":["2.-General-Zettels/We-Can-Remove-Exceptional-Sets-From-Lp-Estimates","2.-General-Zettels/Random-Rotations-Trick","Problems/The-Kakeya-Maximal-Inequality"],"tags":[],"content":"Suppose we have a family of subsets \\mathbb{A} in \\mathbb{R}^n, with |A| \\sim V for each A \\in \\mathbb{A}. Suppose we are trying to prove an inequality\n\\left\\| \\sum\\nolimits_{A \\in \\mathbb{A}} 1_A \\right\\|_{L^p(\\mathbb{R}^n)} \\lesssim C. \\tag{1}\nBy real interpolation, (1) is roughly equivalent to a restricted bound of the form\n\\sum |A \\cap X| \\leq C |X|^{1/d}, \\tag{2}\nwhere d = p&#039;. By dyadic pigeonholing, we may find \\mathbb{A}&#039; \\subset \\mathbb{A} and \\lambda \\in (0,1) so that |A \\cap X| \\sim \\lambda |A| for each A \\in \\mathbb{A}&#039;, and such that \\sum_{A \\in \\mathbb{A}} |A \\cap X| \\approx \\sum_{A \\in \\mathbb{A}&#039;} |A \\cap X|. Normally we have \\# \\mathbb{A} \\lesssim V^{-1}, so that M = (\\# (\\mathbb{A}&#039;) V)^{-1} is large. Then, rearranging, we find (2) is equivalent to\n|X| \\gtrapprox \\left( \\lambda / CM \\right)^d. \\tag{3}\nWe can state this process in the language of shadings. For each A \\in \\mathbb{A}, we pick X(A) \\subset A so that X(A) \\sim \\lambda |A| for each A. Such a choice is called a \\lambda-shading. The L^p inequality we wished to prove above is equivalent to proving that for any subset \\mathbb{A}&#039; of \\mathbb{A}, and any \\lambda-shading of \\mathbb{A}&#039;, the set X = \\bigcup X(A) satisfies |X| \\gtrapprox (\\lambda / CM)^d. Thus we see that upper bounds on L^p sum of indicator functions are roughly equivalent to lower bounding the size of shadings, which is a Kakeya type problem.\nThe Generic Multiplicity of Shadings\nSuppose that each set in \\mathbb{A} is \\delta-discretized (roughly speaking, a union of \\delta balls). For each \\delta ball Q, let M(Q) denote the number of sets in \\mathbb{A} containing Q. Then Markov’s inequality, applied to (1), implies that\n\\# \\{ Q : M(Q) \\geq M_0 \\} \\leq \\delta^{-n} C^p / M_0^p. \\tag{4}\nIf X is a \\delta-discretized \\lambda-shading of \\mathbb{A}&#039;, then (3) implies that X contains at least \\delta^{-n} (\\lambda / CM)^d balls of radius \\lambda. So (3) and (4) together imply that at least half the cubes in X have multiplicity at most O( C^d (M/\\lambda)^{d - 1} ). Conversely, if (3) and (4) hold, then we can obtain inequalities of the form (1) because We Can Remove Exceptional Sets From Lp Estimates.\nThe Special Case of Tubes\nIn the special case where we are studying the Kakeya inequality, \\mathbb{A} is a family of direction separated \\delta-tubes, V = \\delta^{1-n}, and C = \\delta^{1 - n/d}, The Random Rotations Trick allows us to assume that M \\sim 1, so the The Kakeya Maximal Inequality is roughly equivalent to prove that for any family \\mathbb{T} of \\sim \\delta^{1-n} direction separated \\delta tubes, and any \\lambda-shading X of \\mathbb{T}, |X| \\gtrapprox \\lambda^d \\delta^{n-d}. In particular, at least half the cubes in any \\lambda-shading of \\mathbb{T} must have multiplicity at most O(\\delta^{d - n} \\lambda^{1-d}).\nGeometric Means\nSuppose we have proved\n\\left\\| \\left( \\sum\\nolimits_{A_1 \\in \\mathbb{A}, \\dots, A_k \\in \\mathbb{A}_k} 1_{A_1} \\cdots 1_{A_k} \\right)^{1/k} \\right\\|_{L^p(\\mathbb{R}^n)} \\lesssim C. \\tag{1}\nwhere \\mathbb{A}_1,\\dots, \\mathbb{A}_k are families of \\delta discretized sets. The analogous weak bound is that if we let M_i(Q) denote the number of elements of \\mathbb{A}_i which contain a \\delta ball Q, then for any \\delta discretized set X,\n\\sum\\nolimits_{Q \\subset X} [M_1(Q) \\cdots M_k(Q)]^{1/k} \\lesssim C.\nPigeonholing, we may assume that X is a \\lambda-shading of the set of intersections\n\\mathbb{A} = \\{ A_1 \\cap \\cdots \\cap A_k : A_1 \\in \\mathbb{A}_1, \\dots, A_k \\in \\mathbb{A}_k \\}."},"2.-General-Zettels/Simultaneous-Saturation":{"slug":"2.-General-Zettels/Simultaneous-Saturation","filePath":"2. General Zettels/Simultaneous Saturation.md","title":"Simultaneous Saturation","links":[],"tags":[],"content":"Suppose that T_1,\\dots,T_M are operators, with T_i mapping elements of a Hilbert space H_i to functions on a set X, where \\| T_i \\|_{H_i \\to L^2(X)} \\lesssim B. For each x, we consider the linear functional T_i(x) on H_i given by T_i(x) \\{ v \\} = (T_i v)(x). We identify T_i(x) with the corresponding vector in H_i which gives the linear functional via the inner product. Also fix a parameter \\lambda &gt; 0.\nLet us assume (a) that there is a relationship C_i on X for each i such that if C_i(x,y) does not hold, then \\langle T_i(x), T_i(y) \\rangle \\leq R(\\lambda), and (b) for each m \\leq M, the only \\{ x_1,\\dots,x_m \\} such that C_i(x_i,x_{i+1}) for each i are the trivial solution where x_1 = \\cdots = x_m. (TODO NOT SURE ABOUT DEGENERACY).\nLet N be the largest integer for which there exists N distinct points x_1,\\dots,x_N so that\n\\left| \\prod\\nolimits_{i = 1}^M (T_i v_i)(x_j) \\right|^{1/M} \\geq L \\left( \\prod\\nolimits_{i = 1}^M \\| v_i \\|_{H_i} \\right)^{1/M} \\quad\\text{for each $j \\in \\{ 1, \\dots, N \\}$}.\nSuppose we a priori know some upper bound N \\leq R(\\lambda)^{-\\varepsilon/M^2}, for some \\varepsilon &gt; 0. Then there exists C independent of B, L, and \\lambda so that\nN \\leq \\left( C (B/L)^{2 \\left( \\frac{M}{M-1} \\right)} \\right)^{\\frac{1}{1 - \\varepsilon}}.\nProof: Consider the linear map T from H_N = (\\prod_i H_i)^N to functions on X^{MN} given by\nTv(x) = \\prod\\nolimits_{i = 1}^M \\prod\\nolimits_{j = 1}^N (T_i v_{ij})(x_{ij})\nLet v \\in (\\prod_i H_i)^N be the vector with v_{ij} = f_i for each j \\in \\{ 1, \\dots, N \\}, and let x \\in X^{MN} be the set of all points with x_{ij} = x_j for each i \\in \\{ 1, \\dots, M \\}. Let S_N be the permutation group on N elements. For any \\sigma \\in S_N^M, let x^\\sigma_{ij} = x_{i \\sigma(j)}. Then Tv(x^\\sigma) = Tv(x) for each \\sigma. Each permutation gives rise to a distinct point since the points x_1, \\dots, x_N are distinct. Let S be the set of all x^\\sigma.\nWe give S the uniform probability measure, so that we can consider the Hilbert space L^2(S). We note then that if 1_S \\in L^2(S) is the constant function, then\nL^{MN} \\leq |\\langle Tv, 1_S \\rangle| = |\\langle v ,  T^* 1_S \\rangle| \\leq \\| T^* 1_S \\|_{H_N} = \\langle TT^* 1_S, 1_S \\rangle^{1/2}.\nOne may calculate that\n(TT^* f)(x) = \\sum U(x,y) f(y)\nwhere U(x,y) = \\prod \\langle T_i(x_{ij}), T_i(y_{ij}) \\rangle.\nLemma: 1_S is an eigenfunction of TT^*.\nProof: This follows because \\sum U(x,y) = \\sum U(x^\\sigma, y) for each \\sigma \\in S_N^M, as the two sums are just permutations of one another.\nIf TT^* 1_S = \\Lambda 1_S, then we conclude that L^{MN} \\leq \\Lambda."},"2.-General-Zettels/The-Polynomial-Wolff-Axioms":{"slug":"2.-General-Zettels/The-Polynomial-Wolff-Axioms","filePath":"2. General Zettels/The Polynomial Wolff Axioms.md","title":"The Polynomial Wolff Axioms","links":["2024-12-HongWangShukunWu-RestrictionEstimatesUsingDecouplingTheoremsAndTwoEndsFurstenbergInequalities.pdf"],"tags":[],"content":"A set of \\delta-tubes \\mathbb{T} satisfy the Polynomial Wolff axioms if, for any semi-algebraic set S,\n\\# \\{ T \\in \\mathbb{T}: |T \\cap S| \\geq \\lambda |T| \\} \\lesssim |S| \\delta^{1-n} \\lambda^{-n} \\tag{1}\nwhere the implicit constants depend only on the complexity of the semi-algebraic set S. Guth, Zahl, Katz, and Rogers proved that a family of tubes pointing in a \\delta-separated family of directions satisfy the Polynomial Wolff Axioms.\nLet us say a tube T is tangent to a \\delta neighborhood S of an algebraic surface \\Sigma if |T \\cap S| \\geq 0.1 |T|. Since |S|  \\lesssim \\delta the Polynomial Wolff Axioms tell us that at most O(\\delta^{2-n}) tubes in \\mathbb{T} are tangent to the surface. If \\mathbb{T} are \\delta separated, we can have \\#(\\mathbb{T}) \\sim \\delta^{1-n}, and so the Polynomial Wolff Axioms tell us most of the tubes in \\mathbb{T} are not tangent to S.\nSuppose \\mathbb{T} contains at most m tubes in each direction. A natural question is to understand how (1) may be quantified in terms of m - this may have applications to restriction theory, e.g. to the methods of Wang and Wu."},"2.-General-Zettels/The-Refined-Decoupling-Theorem":{"slug":"2.-General-Zettels/The-Refined-Decoupling-Theorem","filePath":"2. General Zettels/The Refined Decoupling Theorem.md","title":"The Refined Decoupling Theorem","links":[],"tags":[],"content":"Suppose p &gt; 2(d+1)/(d-1).\nLet S be a strictly convex, C^2 hypersurface in \\mathbb{R}^d with Gaussian curvature \\sim 1, and consider f: S \\to \\mathbb{C} that can be expanded in a wave-packet decomposition of the form f = \\sum_{T \\in \\mathbb{T}} f_T, where \\mathbb{T} is a family of R-tubes, so that f_T is supported in a radius R^{-1} neighborhood of S, and E_S f_T is essentially supported on T. Assume that the w_R norms of the functions \\{ E_S f_T: T \\in \\mathbb{T} \\} are all comparable (Equivalently, we may assume the norms of the \\{ f_T : T \\in \\mathbb{T} \\} are all comparable). Suppose X \\subset B_R is a union of a family of radius R^{1/2} balls, so that each such ball Q in the union has multiplicity m(Q) = \\# \\{ T \\in \\mathbb{T}: Q \\cap T \\neq \\emptyset \\} at most M. Then\n\\| E_S f \\|_{L^p(X)} \\lessapprox M^{\\frac{2}{n-1}} \\sum\\nolimits_{T \\in \\mathbb{T}} \\| E_S f_T \\|_{L^p(w_R)}^2."},"2.-General-Zettels/The-Wave-Packet-Decomposition-For-Extension-Operators":{"slug":"2.-General-Zettels/The-Wave-Packet-Decomposition-For-Extension-Operators","filePath":"2. General Zettels/The Wave Packet Decomposition For Extension Operators.md","title":"The Wave Packet Decomposition For Extension Operators","links":["1991---Bourgain---Besicovitch-Type-Multiplier-Operators-And-Applications-To-Fourier-Analysis","1969---Fefferman---Inequalities-For-Strongly-Singular-Convolution-Operators","1982---Cordoba---Geometric-Fourier-Analysis","1991---Seeger-Sogge-Stein---Regularity-Properties-of-Fourier-Integral-Operators"],"tags":[],"content":"Given any function f supported on a compact neighborhood of a curved hypersurface \\Sigma, and each R &gt; 0, we can break \\Sigma down finitely overlapping caps \\Theta, each having dimensions R^{-1/2} tangent to \\Sigma, and dimension R^{-1} in the normal direction to \\Sigma. If, for each \\theta \\in \\Theta, we consider a family of tubes \\mathbb{T}(\\theta) pointing in the normal direction to the cap, with dimensions R^{1/2} by R, and then write \\mathbb{T} = \\bigcup \\mathbb{T}(\\theta), then we have an orthogonal decomposition f = \\sum f_T, where for T \\in \\mathbb{T}(\\theta) the following is true:\n\nf_T is supported on \\theta.\nFor x \\in B_R, E_\\Sigma f_T(x) \\approx a_T \\chi_T e^{2 \\pi i \\omega_\\theta x}, where \\omega_\\theta is the center of \\theta, |a_T| \\sim R^{-1/2} \\| f_T \\|_{L^2(\\Sigma)}., and \\chi_T is smooth and adapted to T. In particular, \\| E_\\Sigma f_T \\|_{L^2(B_R)} \\sim R^{1/2} \\| f_T \\|_{L^2(\\Sigma)}.\nThe functions E f_T are locally orthogonal on balls of radius R^{1/2}. That is, for any ball B of radius at least R^{1/2}, \\| Ef \\|_{L^2(B)} \\approx \\sum \\| Ef_T \\|_{L^2(B)}^2.\n\nThe method was widely brought to the attention by Bourgain’s use of the result in a 1991 paper (some claim he introduced the method, though it is also in use by Fefferman and Cordoba in their work on the restriction problem), and is highly similar to the second dyadic decomposition introduced in 1991 by Seeger, Sogge and Stein to analyze Fourier Integral Operators."},"2.-General-Zettels/Wang-Wu-Restricted-Decoupling-+-Kakeya-Implies-Restriction":{"slug":"2.-General-Zettels/Wang-Wu-Restricted-Decoupling-+-Kakeya-Implies-Restriction","filePath":"2. General Zettels/Wang-Wu Restricted Decoupling + Kakeya Implies Restriction.md","title":"Wang-Wu Restricted Decoupling + Kakeya Implies Restriction","links":["2.-General-Zettels/The-Refined-Decoupling-Theorem"],"tags":[],"content":"Recall the The Refined Decoupling Theorem. In this note we discuss how to use this theorem, together with Kakeya type bounds, to prove Restriction Theorems. To begin with, we note that the refined decoupling theorem implies the following bound.\nTheorem: Suppose a family of tubes \\mathbb{T} can be divided into families of tubes \\mathbb{T}_\\theta which are R^{-1/2} direction separated, and \\#(\\mathbb{T}_\\theta) \\leq m for each \\theta. Then if X is a union of R^{1/2} balls, so that m(Q) \\leq M for each Q \\subset X, then\n\\| E_S f \\|_{L^p(X)} \\lessapprox R^{\\frac{n}{p} - \\frac{n-1}{2}} M^{\\frac{1}{p} \\frac{2}{n-1}} m^{1/p - 1/2} \\| f \\|_{L^p(M)}.\nProof: Applying the The Refined Decoupling Theorem, we find that\n\\| E_S f \\|_{L^p(X)}^p \\lessapprox M^{\\frac{2}{n-1}} \\sum\\nolimits_{T \\in \\mathbb{T}} \\| E_S f_T \\|_{L^p(w_R)}^p.\nNow \\| E_S f_T \\|_{L^p(w_R)}^p \\sim R^{ \\frac{p - p_{ST}}{2 - p_{ST}} } \\| f_T \\|_{L^2(M)}^p for each T \\in \\mathbb{T}, so\n\\sum\\nolimits_{T \\in \\mathbb{T}} \\| E_S f_T \\|_{L^p(w_R)}^p \\sim R^{\\frac{p - p_{ST}}{2 - p_{ST}}} \\sum\\nolimits_{T \\in \\mathbb{T}} \\| f_T \\|_{L^2(M)}^p.\nSince all the norms \\| f_T \\|_{L^2(M)} are all comparable, we have that for each \\theta,\n\\sum\\nolimits_{T \\in \\mathbb{T}_\\theta} \\| f_T \\|_{L^2(M)}^p \\sim m^{1 - p/2} \\left( \\sum\\nolimits_{T \\in \\mathbb{T}_\\theta} \\| f_T \\|_{L^2(M)}^2 \\right)^{p/2} \\sim m^{1 - p/2} \\| f_\\theta \\|_{L^2(M)}^p.\nBy H”{o}lder’s inequality, since f_\\theta is supported on a R^{-1/2} cap, we have\n\\| f_\\theta \\|_{L^2(M)}^p \\lesssim R^{- \\left( \\frac{n-1}{2} \\right) (p/2 - 1)} \\| f_\\theta \\|_{L^p(M)}^p.\nCombining these bounds gives that\n\\begin{split}\n    \\| E_S f \\|_{L^p(X)}^p &amp;\\lessapprox M^{\\frac{2}{n-1}} m^{1 - p/2} R^{\\frac{p - p_{ST}}{2 - p_{ST}} - \\left( \\frac{n-1}{2} \\right) (p/2 - 1) } \\| f \\|_{L^p(M)}^p\\\\\n    &amp;= R^{n - \\left( \\frac{n-1}{2} \\right) p} M^{\\frac{2}{n-1}} m^{1 - p/2} \\| f \\|_{L^p(M)}^p.\n\\end{split}\nSo, if we can show a potential counterexample to a restriction bound is concentrated on a set X upon which M^{\\frac{2}{n-1}} m^{1 - p/2} \\lessapprox R^{ \\left( \\frac{n-1}{2} \\right) p - n }, then we will have obtained a contradiction, thus proving the restriction bound. □\nIn particular, if p = p_{ST} then the bound becomes\n \\| E_S f \\|_{L^{p_{ST}}(X)} \\lesssim R^{-1/p_{ST}} (M/m)^{\\frac{1}{n+1}} \\| f \\|_{L^p(M)},\nwhich will be important in a later calculation.\nFor a given family of tubes \\mathbb{T}, controlling M and m simultaneously is a Kakeya type problem. If we consider a set X formed from the union of R^{1/2} tubes, such that |X \\cap T| \\sim \\lambda |T| for each T \\in \\mathbb{T}, then the full Kakeya maximal conjecture implies the multiplicity of a generic \\delta-cube in X is O(m \\lambda^{1-n}). So given a set X, after thinning X appropriately we can set M \\lesssim m \\lambda^{1-n} in the result above.\nLet us try and use this technique to obtain an extension bound. Assume that \\| f \\|_{L^p(M)} = 1. Consider a wave packet decomposition f = \\sum f_{\\theta,\\nu} at a scale R^{-1/2}, and thus E_S f = \\sum_{T \\in \\mathbb{T}} g_T, where T = \\{ T_{\\theta,\\nu}: f_{\\theta,\\nu} \\neq 0 \\}. By pigeonholing, we may assume that there is B &gt; 0 so that \\| f_{\\theta,\\nu} \\|_{L^\\infty(M)} \\sim B for all T \\in \\mathbb{T}. Let X be a set, which we may assume to be R^{1/2} discretized, we try and find X_0 \\subset X with |X_0| \\geq |X|/10 so that \\| E_S f \\|_{L^p(X_0)} \\lesssim 1. We may assume X is R^{1/2} discretized, and by dyadic pigeonholing, we may find a dyadic scale \\lambda so that X(T) = X \\cap T satisfies |X(T)| \\sim \\lambda |T| for some \\lambda \\in [0,1] and all T \\in \\mathbb{T}. Because the functions \\{ g_T \\} are orthogonal on R^{1/2} cubes, they are also orthogonal on X, so\n\\| E_S f \\|_{L^2(X)} \\lesssim \\left( \\sum \\| g_T \\|_{L^2(X)}^2 \\right)^{1/2} \\sim (\\lambda R)^{1/2} \\left( \\sum \\| f_{\\theta,\\nu} \\|_{L^2(M)}^2 \\right)^{1/2} = (\\lambda R)^{1/2} \\| f \\|_{L^2(M)}.\nOn the other hand, if p_{ST} is the Stein-Tomas exponent, we can find a set X_0 \\subset X with |X_0| \\geq |X|/10 so that M \\lesssim m \\lambda^{-(n-1)}. If we could somehow improve this bound so we could assume M \\lesssim m \\lambda^{- \\frac{n-1}{2}}, then\n\\begin{split}\n    \\| E_S f \\|_{L^{p_{ST}}(X_0)} &amp;\\lessapprox (M/m)^{ \\frac{1}{n+1}} R^{-\\frac{n-1}{2(n+1)}} \\| f \\|_{L^{p_{ST}}(X_0)}\\\\\n    &amp;\\lessapprox (\\lambda R)^{- 1/p_{ST}} \\| f \\|_{L^{p_{ST}}(X_0)}\n\\end{split}\nInterpolating, we obtain that at the critical exponent for the restriction conjecture, i.e. for p = 2n/(n-1),\n\\| E_S f \\|_{L^p(X_0)} \\lesssim \\| f \\|_{L^p(X_0)}.\nThis is sufficient to completely prove the restriction conjecture.\nIn general, we will be able to obtain square root cancellation in \\lambda by forcing X to satisfy a two-ends condition, and we can then use this to obtain restriction estimates. Given a set X satisfying the two-ends condition, with |X \\cap T| \\sim \\lambda |T| for each T \\in \\mathbb{T}, the bush argument of Bourgain gives that |X| \\gtrapprox R^{\\frac{3n+1}{4}} \\lambda, and so the average multiplicity of a cube Q in X is M \\lesssim m \\lambda^{- \\frac{n-1}{n+1}} R^{-\\frac{(n-1)^2}{4(n+1)}} \\lambda^{-\\frac{n-1}{n+1}}, which gives\n\\| E_S f \\|_{L^{p_{ST}}(X_0)} \\lessapprox R^{-\\frac{(n-1)[3n+1]}{4(n+1)^2}} \\lambda^{- \\frac{n-1}{(n+1)^2}} \\| f \\|_{L^{p_{ST}}}\nInterpolation between the L^2 estimate gives a result of the form\n\\| E_S f \\|_{L^p(X_0)} \\lessapprox \\| f \\|_{L^p(X_0)}\nfor p = \\frac{2 + 2n(5n + 2)}{(n-1)(5n + 3)}. In particular, for n = 3 this gives p = 26/9 \\approx 2.89."},"2.-General-Zettels/We-Can-Remove-Exceptional-Sets-From-Lp-Estimates":{"slug":"2.-General-Zettels/We-Can-Remove-Exceptional-Sets-From-Lp-Estimates","filePath":"2. General Zettels/We Can Remove Exceptional Sets From Lp Estimates.md","title":"We Can Remove Exceptional Sets From Lp Estimates","links":[],"tags":[],"content":"Suppose X_0 has finite measure, and we have to prove an inequality of the form\n\\| f \\|_{L^p(X_0)} \\lesssim C. \\tag{1}\nEquation (1) is almost equivalent to proving that for any subset X of X_0, there exists E \\subset X with |E \\cap X| \\leq 1/2 so that\n\\| f \\|_{L^p(X - E)} \\lesssim C |X|^{1/p&#039;}. \\tag{2}\nCertainly (1) implies (2) by Hölder’s inequality. Conversely, if (2) holds, then we may find E_1 so that if X_1 = X - E_1, then\n\\| f \\|_{L^p(X_1)} \\lesssim C |X|^{1/p&#039;}. \\tag{3}\nIterating, for each n \\geq 1, we can apply (2) with X = X_n to find E_n \\subset X_n so that if X_{n+1} = X_n - E_n,\n\\| f \\|_{L^p(X_{n+1})} \\lesssim C |X_n|^{1/p} \\lesssim 2^{-n/p} C |X|^{1/p&#039;}. \\tag{4}\nApplying the triangle inequality, since X - \\bigcup X_n is measure zero, we find\n\\| f \\|_{L^p(X)} \\leq \\sum\\nolimits_n \\| f \\|_{L^p(X_n)} \\lesssim \\sum 2^{-n/p} C |X|^{1/p&#039;} \\lesssim C |X|^{1/p&#039;}. \\tag{5}"},"1.-Problems/Generalization-of-Decoupling-and-Restricted-Decoupling":{"slug":"1.-Problems/Generalization-of-Decoupling-and-Restricted-Decoupling","filePath":"1. Problems/Generalization of Decoupling and Restricted Decoupling.md","title":"Generalization of Decoupling and Restricted Decoupling","links":[],"tags":[],"content":"During a talk, Tony Carbery proposed the following result, which generalizes decoupling and restricted decoupling. It states that\n\\int_{B_R} |Eg|^2 w \\lessapprox \\sum\\nolimits_\\nu \\sum\\nolimits_{T \\perp S_\\nu} \\| g_T \\|_{L^2}^2 w_T^\\nu,\nwhere w_T^\\nu = w^{\\frac{n+1}{2}}(T)^{\\frac{2}{n+1}}."},"1.-Problems/The-Kakeya-Maximal-Inequality":{"slug":"1.-Problems/The-Kakeya-Maximal-Inequality","filePath":"1. Problems/The Kakeya Maximal Inequality.md","title":"The Kakeya Maximal Inequality","links":[],"tags":[],"content":"The Kakeya maximal conjecture states that for a family \\mathbb{T} of \\delta-tubes in \\mathbb{R}^n, which are direction separated, and for 0 \\leq d \\leq n,\n\\left\\| \\sum 1_T \\right\\|_{L^{\\frac{d}{d-1}}(\\mathbb{R}^n)} \\lessapprox \\delta^{1-n/d}.\nSuch a bound implies that all Kakeya sets must have Hausdorff dimension d."},"1.-Problems/The-Multilinear-Restriction-Conjecture":{"slug":"1.-Problems/The-Multilinear-Restriction-Conjecture","filePath":"1. Problems/The Multilinear Restriction Conjecture.md","title":"The Multilinear Restriction Conjecture","links":["2003---Tao---A-Sharp-Bilinear-Restriction-Estimate-for-Paraboloids-1","2006-BennettCarberyTao-OnTheMultilinearRestrictionAndKakeyaConjectures","Harmonic-Analysis/Multilinear-Methods-in-Restriction-Theory/2022---Bejenaru---The-Almost-Optimal-Multilinear-Restriction-Estimate-For-Hypersurfaces-With-Curvature","2011---Bourgain-Guth---Bounds-on-Oscillatory-Integrals-Using-Multilinear-Estimates","Harmonic-Analysis/Polynomial-Methods-in-Restriction-Theory/2018---Guth---Restriction-Estimates-Using-Polynomial-Partitioning-2","2006---Bennett-Carbery-Tao---On-The-Multilinear-Restriction-And-Kakeya-Conjectures"],"tags":[],"content":"The restriction conjecture states that for 2d/(d-1) &lt; q &lt; \\infty and  1 - \\left( \\frac{d+1}{d-1} \\right) (1/q) \\geq 1/p,\n\\| Ef \\|_{L^q(\\mathbb{R}^d)} \\lesssim \\| f \\|_{L^p(\\Sigma)}.\nThe multilinear restriction conjectures says that for 2 \\leq k \\leq n, if f_1,\\dots,f_k are restricted to transverse subsets of \\Sigma, then for q &gt; 2(d+k)/(d+k-2),\n\\left\\| \\prod\\nolimits_j |Ef_j|^{1/k} \\right\\|_{L^q(B_R)} \\lessapprox \\prod\\nolimits_j \\| f_j \\|_{L^2(\\Sigma)}^{1/k}.\n\nThe case k = 1 is essentially the Stein-Tomas theorem.\nThe conjecture has been proved for k = 2 by Tao.\nThe conjecture has been proved for k = n by Bennett, Carbery, and Tao.\nThe conjecture has been proved for k = n-1 by Bejenaru.\n\nThe methods of Bourgain and Guth show that multilinear estimates for the restriction conjecture imply some restriction estimates. In particular, if the multilinear restriction conjecture was established, then it would imply the results of Guth, who was able to get around using multilinear estimates by using the broad norms.\n\nApparently, the methods of Bennett, Carbery, and Tao imply the result is true for p &gt; 2/(k-1).\nJennifer Duncan has claimed in talks to prove the result for p &gt; 2(k+1)/k.\n"}}