{"Problems/Generalization-of-Decoupling-and-Restricted-Decoupling":{"slug":"Problems/Generalization-of-Decoupling-and-Restricted-Decoupling","filePath":"Problems/Generalization of Decoupling and Restricted Decoupling.md","title":"Generalization of Decoupling and Restricted Decoupling","links":[],"tags":[],"content":"During a talk, Tony Carbery proposed the following result, which generalizes decoupling and restricted decoupling. It states that\n\\int_{B_R} |Eg|^2 w \\lessapprox \\sum\\nolimits_\\nu \\sum\\nolimits_{T \\perp S_\\nu} \\| g_T \\|_{L^2}^2 w_T^\\nu,\nwhere w_T^\\nu = w^{\\frac{n+1}{2}}(T)^{\\frac{2}{n+1}}."},"Problems/The-Kakeya-Maximal-Inequality":{"slug":"Problems/The-Kakeya-Maximal-Inequality","filePath":"Problems/The Kakeya Maximal Inequality.md","title":"The Kakeya Maximal Inequality","links":[],"tags":[],"content":"The Kakeya maximal conjecture states that for a family \\mathbb{T} of \\delta-tubes which are direction separated, then for 0 \\leq d \\leq n,\n \\left\\| \\sum 1_T \\right\\|_{L^{\\frac{d}{d-1}}(\\mathbb{R}^n)} \\lessapprox \\delta^{1-n/d}."},"Problems/The-Multilinear-Restriction-Conjecture":{"slug":"Problems/The-Multilinear-Restriction-Conjecture","filePath":"Problems/The Multilinear Restriction Conjecture.md","title":"The Multilinear Restriction Conjecture","links":["2003---Tao---A-Sharp-Bilinear-Restriction-Estimate-for-Paraboloids-1","2006-BennettCarberyTao-OnTheMultilinearRestrictionAndKakeyaConjectures","Harmonic-Analysis/Multilinear-Methods-in-Restriction-Theory/2022---Bejenaru---The-Almost-Optimal-Multilinear-Restriction-Estimate-For-Hypersurfaces-With-Curvature","2011---Bourgain-Guth---Bounds-on-Oscillatory-Integrals-Using-Multilinear-Estimates","Harmonic-Analysis/Polynomial-Methods-in-Restriction-Theory/2018---Guth---Restriction-Estimates-Using-Polynomial-Partitioning-2","2006---Bennett-Carbery-Tao---On-The-Multilinear-Restriction-And-Kakeya-Conjectures"],"tags":[],"content":"The restriction conjecture states that for 2d/(d-1) &lt; q &lt; \\infty and  1 - \\left( \\frac{d+1}{d-1} \\right) (1/q) \\geq 1/p,\n\\| Ef \\|_{L^q(\\mathbb{R}^d)} \\lesssim \\| f \\|_{L^p(\\Sigma)}.\nThe multilinear restriction conjectures says that for 2 \\leq k \\leq n, if f_1,\\dots,f_k are restricted to transverse subsets of \\Sigma, then for q &gt; 2(d+k)/(d+k-2),\n\\left\\| \\prod\\nolimits_j |Ef_j|^{1/k} \\right\\|_{L^q(B_R)} \\lessapprox \\prod\\nolimits_j \\| f_j \\|_{L^2(\\Sigma)}.\n\nThe case k = 1 is essentially the Stein-Tomas theorem.\nThe conjecture has been proved for k = 2 by Tao.\nThe conjecture has been proved for k = n by Bennett, Carbery, and Tao.\nThe conjecture has been proved for k = n-1 by Bejenaru.\n\nThe methods of Bourgain and Guth show that multilinear estimates for the restriction conjecture imply some restriction estimates. In particular, if the multilinear restriction conjecture was established, then it would imply the results of Guth, who was able to get around using multilinear estimates by using the broad norms.\n\nApparently, the methods of Bennett, Carbery, and Tao imply the result is true for p &gt; 2/(k-1).\nJennifer Duncan has claimed in talks to prove the result for p &gt; 2(k+1)/k.\n"},"Quick-Notes/Broad-Narrow-Analysis":{"slug":"Quick-Notes/Broad-Narrow-Analysis","filePath":"Quick Notes/Broad-Narrow Analysis.md","title":"Broad-Narrow Analysis","links":[],"tags":[],"content":"We aim to obtain a bound\n\\| Ef \\|_{L^p(B_R)} \\lessapprox \\| f \\|_{L^p(\\Sigma)}\nby using multilinear restriction estimates and decoupling estimates.\nFix K &gt; 0, and cover B_R by balls B of radius A, where K \\ll A \\leq K^{O(1)}. Similarly, decompose \\Sigma into a family \\Theta of caps \\theta of diameter 1/K. For each cap \\theta, we let n(\\theta) denote the normal vector to \\Sigma at the center of the cap. We will pick K \\lessapprox 1. In particular, it then follows that \\#(\\Theta) = K^{O(1)} \\lessapprox 1, so that we can analyze each ball B separately and then put estimates together using the triangle inequality.\nFor each ball B, let S(B) be the set of all \\theta \\in \\Theta so that\n\\| Ef_\\theta \\|_{L^p(B)} \\gg \\frac{\\| Ef \\|_{L^p(B)}}{\\#(\\Theta)}.\nThen\n\\| Ef \\|_{L^p(B)} \\sim \\left\\| \\sum\\nolimits_{\\theta \\in S(B)} Ef_\\theta \\right\\|_{L^p(B)}. \nIn fact, we have \\| Ef \\|_{L^p(B)} \\approx \\| Ef_\\theta \\|_{L^p(B)} for each \\theta \\in S(B).\nFix k \\in \\{ 2, \\dots, d \\}. We say a ball B is k-narrow if there exists a k-1 dimensional plane H in \\mathbb{R}^d so that the set of vectors \\{ n(\\theta): \\theta \\in S(B) \\} all make an angle at most 1/K with H. Otherwise, call the ball B a k-broad ball.\nIf B is a k-broad ball, then there exists k caps \\theta_1, \\dots, \\theta_k in S(B) so that\n|n(\\theta_1) \\wedge \\cdots \\wedge n(\\theta_k)| \\gtrsim 1/K.\nWe would like to obtain a bound of the form\n\\left\\| Ef \\right\\|_{L^p(B)} \\lessapprox \\left\\| \\prod\\nolimits_j |Ef_{\\theta_j}|^{1/k} \\right\\|_{L^p(B)}\nso that we can apply the multi-linear restriction theorem. The converse follows from Hölder’s inequality and that \\| Ef_{\\theta_j} \\|_{L^p(B)} \\sim \\| Ef \\|_{L^p(B)}, so we should think of this as a kind of reverse Hölder’s inequality.\nIf B were a ball of radius K, then by local constancy we could guarantee this reverse Hölder’s inequality, if we are willing to work with rapidly decaying cutoff functions around the balls B, rather than L^p norms on the balls themselves, i.e. proving a bound of the form\n\\left\\| Ef \\right\\|_{L^p(w_B)} \\lessapprox \\left\\| \\prod\\nolimits_j |Ef_{\\theta_j}|^{1/k} \\right\\|_{L^p(w_B)}\nLet us prove that\n\\left\\| Ef \\right\\|_{L^p(w_B)} \\lessapprox \\left\\| |Ef_{\\theta_1}|^t |Ef_{\\theta_2}|^{1-t} \\right\\|_{L^p(w_B)}\nUsing Bernstein’s inequality, we may assume without loss of generality that p \\geq 2/t, since the result for any particular 1 &lt; p &lt; \\infty implies the result for all p. Find a set S \\subset \\mathbb{R}^d so that \\| 1_S \\|_{L^1(w_B)} \\geq 0.999 \\| 1 \\|_{L^1(w_B)} and for x \\in S, |Ef_{\\theta_2}(x)| \\sim \\| Ef \\|_{L^p(w_B)} K^{-d/p}. Then applying the general reverse Hölder’s inequality for L^p spaces, we have\n\\left\\| |Ef_{\\theta_1}|^t |Ef_{\\theta_2}|^{1-t} 1_S \\right\\|_{L^p(w_B)} &amp;= \\| |Ef_{\\theta_1}|^{tp} |Ef_{\\theta_2}|^{p(1-t)} 1_S \\|_{L^1(w_B)}^{1/p}\\\\\n&amp;\\geq \\| |Ef_{\\theta_1}|^{tp} \\|_{L^{1/2}(w_B)}^{1/p} \\| |Ef_{\\theta_2}|^{p(1-t)} 1_S \\|_{L^{-1}(w_B)}^{1-t}\\\\\n&amp;= \\| Ef_{\\theta_1} \\|_{L^{tp/2}(w_B)}^t \\| Ef_{\\theta_2} 1_S \\|_{L^{-p(1-t)}(w_B)}^{1-t}\\\\\n&amp;\\sim \\left[ K^{(d/p)(2/t - 1)} \\| Ef \\|_{L^p(w_B)} \\right]^t \\left[ \\| Ef \\|_{L^p(w_B)} K^{-d/p} K^{\\frac{-d}{p(1-t)}} \\right]^{1-t}\\\\\n&amp;\\sim \\| Ef \\|_{L^p(w_B)}\n\\end{aligned}$$\n\nWe used the Sobolev embedding term to bound the first term in the second last line. But. now the general result follows by induction, since $\\prod_j Ef_{\\theta_j}$ also satisfies the local constancy property.\n\nFor larger balls, this argument clearly cannot be generalized, but we instead use a *random translation argument* as a substitute. For each $j$, we can find a ball $B_j$ of radius $K$ so that $\\| Ef_{\\theta_j} \\|_{L^p(w_{B_j})} \\geq (A/K)^d \\| Ef \\|_{L^p(w_B)}$. If we consider vectors $\\nu_1,\\dots,\\nu_k$ chosen uniformly at random from $B^*$, then with probability $\\Omega((A/K)^{k-1})$, the set $S = \\text{Trans}_{\\nu_1} S_1 \\cap \\cdots \\cap \\text{Trans}_{\\nu_k} S_k$ contains a ball $B_0$ of radius $\\Omega(K)$. Then by local constancy, $\\| Ef_{\\theta_j} \\|_{L^p(w_{B_0})} \\gtrapprox (A/K)^d \\| Ef \\|_{L^p(w_B)}$ for each $j$, and so by the reverse Hölder&#039;s inequality we proved above, we conclude that\n\n(A/K)^d \\left| Ef \\right|{L^p(w{B_0})} \\lessapprox \\left| \\prod\\nolimits_j |\\text{Trans}{\\nu_j} Ef{\\theta_j}|^{1/k} \\right|_{L^p(B_0)}\n\nThus we find that\n\n| Ef |{L^p(w{B_0})} \\lessapprox \\mathbb{E}\\nu \\left| \\prod\\nolimits_j |\\text{Trans}{\\nu_j} Ef_{\\theta_j}|^{1/k} \\right|_{L^p(B_0)}.\n\nStudying $\\text{Trans}_{\\nu_j} Ef_{\\theta_j}$ is no more difficult than studying $Ef_{\\theta_j}$ because we can write the translation into modulation of $f_{\\theta_j}$, i.e. $\\text{Trans}_{\\nu_j} Ef_{\\theta_j} = E \\{ e_{\\nu_j} f_{\\theta_j} \\}$ where $e_{\\nu_j}(x) = e^{-2 \\pi i \\nu_j \\cdot x}$. We can then apply the multilinear inequality to each of the translations and thus obtain appropriate bounds.\n\nThe functions $Ef_\\theta$ are locally constant on balls of radius $K$, so the reverse would follow if $A = K$ from local constancy. But for $A \\gg K$ the two quantities could be completely incomparable, since the functions $|Ef_{\\theta_j}|$ could be large where the other $|Ef_{\\theta_k}|$ are very small.\n\nThe fix for this is that, if we translate the functions $Ef_{\\theta_j}$ at random, then by local constancy there is probability $O(K^{-O(1)})$ that the regions where the functions are large all align. More precisely, by local constancy we can find a ball $B_j \\subset B$ of radius $K$ upon which $\\| Ef_{\\theta_j} \\|_{L^p(B_j)} \\gtrapprox \\| Ef_{\\theta_j} \\|_{L^p(B)}$. Then by local constancy (Bernstein&#039;s inequality), $\\| Ef_{\\theta_j} \\|_{L^p(B_j)} \\sim K^d \\| Ef_{\\theta_j} \\|_{L^\\infty(B_j)}$\n\nThen if $\\nu_1,\\dots,\\nu_k$ are vectors chosen uniformly at random from the ball of radius $A$, then with probability $O(K^{-O(1)})$, the set $U = \\bigcap_j \\text{Trans}_{\\nu_j} B_j$ satisfies $U \\gtrsim K$. \n\nThen for some $\\{ \\nu_j \\}$, by local constancy,\n\n\\left| \\prod\\nolimits_j \\text{Trans}{\\nu_j} Ef{\\theta_j} \\right|_{L^p(U)}\n\nIf we define $\\text{Trans}_\\nu Ef_{\\theta_j}$\n\nlocal constancy only gives that\n\n| Ef |{L^p(B)} \\sim \\left( \\sum | Ef |{L^p(B_k)}^p \\right)^{1/p} \\sim \\prod | Ef_\\theta |{L^p(B)}^{1/k} \\lesssim A^d \\prod | Ef\\theta |_{L^\\infty(B)}^{1/k}\n\nif $l &gt; 1$ then the converse doesn&#039;t quite work. The trick is to consider *random translations*\n\nIt then follows from a translation trick, Tacy&#039;s theorem (*we likely have to make another assumption on the caps so they don&#039;t lie in a non-curved subspace*), and a wave packet decomposition of each $E f_{\\theta_j}$ into tubes $T_j$ that\n\n$$ \\| Ef \\|_{L^p(B)} \\leq K^{O(1)} \\left( \\prod\\nolimits_j \\left\\| \\sum\\nolimits_{\\nu_j \\in S(B,\\theta_j)} f_{\\theta_j,\\nu_j} \\right\\|_{L^2(\\Sigma)} \\right)^{1/k} \\leq K^{O(1)} \\max\\nolimits_j \\left\\| \\sum\\nolimits_{\\nu_j \\in S(B,\\theta_j)} f_{\\theta_j,\\nu_j} \\right\\|_{L^2(\\Sigma)}. $$\n\nSince each $\\nu_j$ is in $S(B,\\theta_j)$ for at most $K^{O(1)}$ different balls $B$, $L^2$ orthogonality of tubes implies that\n\n| Ef |{L^p(\\text{Broad})} \\leq K^{O(1)} | f |{L^2(\\Sigma)} \\leq K^{O(1)} | f |_{L^p(\\Sigma)}.\n\nNow we deal with the narrow case. Suppose that $B$ is a $k$-narrow ball. Then there exists \n\nusing decoupling inequalities. Suppose that $B$ is a narrow ball, and $S(B)$ is such that we have a decoupling inequality\n\n$$ \\| Ef \\|_{L^p(B)} \\lesssim K^{O(1)} \\left( \\sum \\| Ef_\\theta \\|_{L^p(B)}^2 \\right)^{1/2}. $$\n\nSumming over all narrow balls $B$ using the finite overlap property, we obtain that\n\n$$ \\| Ef \\|_{L^p(\\text{Narrow})} \\lesssim K^{O(1)} \\left( \\sum \\| Ef_\\theta \\|_{L^p(B_R)}^2 \\right)^{1/2}. $$\nWe now bound each term $\\| Ef_\\theta \\|_{L^p(B_R)}$ using induction on scales. Namely, we can find a function $g_\\theta$ on $\\Sigma$ for each $\\theta$ so that $\\| g \\|_{L^p(\\Sigma)} = K^{\\frac{d-1}{p}} \\| f_\\theta \\|_{L^p(\\Sigma)}$ and $\\| Ef_\\tau \\|_{L^p(B_R)} \\lesssim K^{\\frac{d+1}{p} - (d-1)} \\| Eg \\|_{L^p(B_{R/K})}$. Applying induction on scales, letting $C(R)$ be the best constant in the extension inequality on $B_R$, we find that\n\n$$ \\| Ef \\|_{L^p(\\text{Narrow})} \\lesssim K^{\\frac{2d}{p} - (d-1)} C(R/K). $$\n\nPutting together the analysis of the broad and narrow cases, we find that\n\n$$ C(R) \\lesssim K^{O(1)} + C K^{\\frac{2d}{p} - (d-1)} C(R/K). $$\n\nSince $p &gt; 2d(d-1)$, for all $\\varepsilon &gt; 0$, if we choose $K = R^\\delta$ for $\\delta$ sufficiently small, depending on $\\varepsilon$, we conclude that $C(R) \\lesssim_\\varepsilon R^\\varepsilon$.\n\n*We likely can use decoupling in the right range provided that the $k-1$ dimensional hypersurface on which the caps are concentrated is appropriately curved. The amount of curvature required is not completely apparent I need to ask Jonathan what the range of decoupling estimates are known in the case that we have degenerate hyper-surfaces.*\n\n\n\n\n\n\n\n\n\n\n### Guth Polynomial Partitioning Broad Narrow Argument\nFix $K &gt; 0$, and divide a hypersurface $\\Sigma$ in $\\mathbb{R}^d$ into caps $\\tau$ of diameter $O(K^{-1})$. Given a function $f$ on $\\Sigma$, let $g = Ef$. Then a point $x \\in \\mathbb{R}^d$ is $\\alpha$ broad if $\\max |Ef_\\tau(x)| \\leq \\alpha |Ef(x)|$. If a point is not $\\alpha$ broad, then it is $\\alpha$ narrow, which means there is some $\\tau_0$ with $|Ef(x)| \\leq \\alpha^{-1} |Ef_{\\tau_0}(x)|$. This gives a smaller scale which can bound the current scale of analysis, so induction on scales often allows us to bound the behavior of the extension operator at narrow points, and we may thus restrict our attention to the behavior at broad points.\n\nMore precisely, if we define $\\text{Br}_\\alpha(g)$ to be equal to $g$ at broad points, and equal to zero at narrow points, then we have a pointwise bound\n$$ |g| \\leq |\\text{Br}_\\alpha(g)| + \\alpha^{-1} \\max\\nolimits_{\\tau_0} |Ef_{\\tau_0}|$$\nInduction on scales bounds $|Ef_{\\tau_0}|$ uniformly, so it suffices to estimate $|\\text{Br}_\\alpha(g)|$. The advantage of reducing to the broad case is that one can often reduce to multilinear estimates, given that the caps $\\{ \\tau_0 \\}$ are suitably transverse to one another. \n\nIn more sophisticated contexts, it is useful to be more quantitative, especially when considering estimates closer to $k$-linear analysis. We define a measure $\\mu = \\mu_a^p$, locally constant at a scale $K^2$, so that for a  ball of radius $K^2$,\n$$ \\mu^p(f,B) = \\min\\nolimits_{V_1,\\dots,V_a} \\max\\nolimits_{\\tau \\in \\text{Tr}(V_1,\\dots,V_a)} \\int_B |Ef_\\tau|^p$$\nwhere $V_1,\\dots,V_a$ are $k$-dimensional subspaces, and $\\text{Tr}(V_1,\\dots,V_A)$ is the set of caps transverse to all $V_1,\\dots,V_a$, more precisely, making an angle greater than $1/K$ with each subspace. We then define, for a set $U$ constant at a scale $K^2$,\n$$ \\| Ef \\|_{\\text{BL}_{k,a}^p(U)} = \\left( \\sum\\nolimits_{B \\subset U} \\mu^p(f,B) \\right)^{1/p}$$\nThe need to choose $a &gt; 1$ is required so that the broad norm is semi-additive and satisfies the Holder inequality. We often choose $a \\sim 1$. On a particular ball of radius $K^2$, we are only bounding those $\\| Ef_{\\tau_0} \\|_{L^p(B)}$ for which there exists $\\tau_1,\\dots,\\tau_{k-1}$ with $\\tau_0 \\wedge \\cdots \\wedge \\tau_{k-1} \\gtrsim 1$ and $\\| Ef_{\\tau_i} \\|_{L^p(B)} \\gtrsim \\| Ef_\\tau \\|_{L^p(B)}$. The most useful property of the broad norm is that if we are only studying tubes that are tangent to a $k-1$ dimensional variety, then the broad norm of $Ef$ is essentially zero (for whenever the tubes intersect, they do so in a way that is not $k$ transverse).\n\nWhen estimating the broad norm rather than the usual $L^p$ norm, tubes that are concentrated on $k-1$ dimensional varieties are\n\nIn the multilinear case, what gets thrown out?\n\n- [[2015 - Guth - A Restriction Estimate Using Polynomial Partitioning|Guth]] uses the method to prove his $L^\\infty(\\Sigma) \\to L^p(\\mathbb{R}^3)$ restriction estimate for $p &gt; 3.25$.\n- [[2015 - Guth - A Restriction Estimate Using Polynomial Partitioning|Guth]] states that his broad narrow analysis is similar to the bilinear restriction methods of [[1998 - Tao Vargas Vega - A Bilinear ApproachT to the Restriction and Kakeya Conjectures|Tao, Vargas, and Vega]], but I have not looked into this paper."},"Quick-Notes/Calculations-With-The-Shape-Operator-II":{"slug":"Quick-Notes/Calculations-With-The-Shape-Operator-II","filePath":"Quick Notes/Calculations With The Shape Operator II.md","title":"Calculations With The Shape Operator II","links":[],"tags":[],"content":"Let \\pi_j: \\mathbb{R}^n \\to \\mathbb{R}^{n-1} denote the map \\pi_j(\\zeta) = (\\zeta_1,\\dots,\\zeta_{i-1},\\zeta_{i+1},\\dots,\\zeta_n). Consider hypersurfaces \\Sigma_1,\\dots,\\Sigma_k in \\mathbb{R}^n given by\n\\Sigma_i = \\{ \\zeta: \\zeta_j = \\phi_j(\\pi_j(\\zeta)) \\},\nwhere \\phi_j(0) = 0 and \\nabla \\phi_j(0) = 0. We write \\zeta = (\\xi,\\eta), with \\xi \\in \\mathbb{R}^k and \\eta \\in \\mathbb{R}^{n-k}. We consider the parameterization\n\\Sigma_i(\\upsilon,\\eta) = ( \\upsilon_1,\\dots,\\upsilon_{i-1}, \\phi_i(\\upsilon,\\eta), \\upsilon_{i+1},\\dots,\\upsilon_{k-1}, \\eta ).\nIn this note we prove an equivalence between the following two conditions:\n\nBejenaru’s Condition: If W = \\text{span}(e_{i+1},\\dots,e_n), then \\pi_W \\circ S_0 \\circ i_W is invertible, where S_0: T_0 \\Sigma_i \\to T_0 \\Sigma_i is the shape operator of M_i at 0, i_W: W \\to T_0 \\Sigma_i is the inclusion map, and \\pi_W: T_0 \\Sigma_i \\to W is the projection map.\nTacy’s Condition: The Hessian of \\phi_i in the \\eta variable is invertible at 0.\n\nTo see this equivalence, we begin by computing the shape operator in an appropriate coordinate system. For j \\in \\{ 1, \\dots, n-k \\}, we let \\partial_j(\\eta) = (\\partial_{\\eta_j} \\phi_i(0,\\eta) e_i, e_j). Then \\{ \\partial_1(\\eta), \\dots, \\partial_{n-k}(\\eta) \\} form a basis for the tangent space of \\Sigma_i at the point \\Sigma_i(\\xi,\\eta). Now\nn(\\eta) = r(\\eta) ( e_i, - \\nabla_\\xi \\phi_i(0,\\eta) )\nis the normal vector to \\Sigma_i at \\Sigma_i(0,\\eta), where r(\\eta) = \\sqrt{1 + |\\nabla_\\xi \\phi_i(0,\\eta)|^2}.\nThus differentiating in the \\xi_j variable, we see that there exists a constant c_j so that\nS_0(\\partial_j) = r(\\eta)^{-1} ( 0, - (\\text{Hess}_\\eta \\phi_i)(0) e_k ) + c_j n(\\eta)\nSo if H = \\text{Hess}_\\eta \\phi_i(0), then\nS_0\\left(\\sum a_j \\partial_j \\right) \\cdot \\left(\\sum b_k \\partial_k \\right) = r(\\eta)^{-1} (b^T H a)\nBejenaru’s condition fails precisely when \\pi_W(S_0(\\sum a_j \\partial_j)) = 0 for some nonzero vector a. The calculation above shows this is equivalent to b^T H a = 0 for all vectors b, and thus to Ha = 0. Thus we see immediately that Bejenaru’s condition fails at the origin precisely when H fails to be invertible. Conversely, Bejenaru’s condition holds precisely when H is invertible."},"Quick-Notes/Calculations-With-The-Shape-Operator":{"slug":"Quick-Notes/Calculations-With-The-Shape-Operator","filePath":"Quick Notes/Calculations With The Shape Operator.md","title":"Calculations With The Shape Operator","links":[],"tags":[],"content":"Let \\Sigma be an orientable surface in \\mathbb{R}^d. Then we can consider a normal vector field n: \\Sigma \\to S^{d-1} to \\Sigma. The derivative of n at a point p \\in \\Sigma gives rise to a linear map from T_p \\Sigma to T_{n(p)} S^{d-1}. But both tangent spaces T_p \\Sigma and T_{n(p)} S^{d-1} correspond to the same subspace of \\mathbb{R}^d, and so the two can be naturally identified. Thus the derivative of n at a point p \\in \\Sigma gives rise to a linear operator S_p on T_p \\Sigma, self-adjoint with respect to the inner product on T_p \\Sigma given by the dot product. The operator S_p is called the shape operator.\nIntuitively, S_p describes how the normal vectors to \\Sigma vary up to first order around the point p. A vector v is an eigenvector of S_p if and only if the normal vector, to first order, only varies in the direction of v as we travel along a curve on \\Sigma tangent to v at p.\nWe would like to work with the operator S_p in coordinates. Let d = n+1, and consider a coordinate chart \\alpha: \\Sigma \\to \\mathbb{R}^n for \\Sigma. Then at each p \\in \\Sigma, we obtain a basis \\partial_1,\\dots,\\partial_n for T_p \\Sigma given by the columns of the derivative of \\alpha^{-1}, viewed as a map from \\mathbb{R}^n to \\mathbb{R}^d. For v \\in T_p \\Sigma, we let v^\\alpha \\in \\mathbb{R}^n denote the components of v, i.e. the vector such that v = \\sum v^\\alpha_i \\partial_i.\nWe would like to work out the matrix representation of the operator S_p in this coordinate system, i.e. finding the n \\times n matrix A so that for any two vectors v,w \\in T_p \\Sigma, S_p v = w holds if and only if Av^\\alpha = w^\\alpha. It is often easier to work with the second fundamental form in coordinates rather than the shape operator, i.e. the bilinear map \\text{II}_p: T_p \\Sigma \\times T_p \\Sigma \\to \\mathbb{R} given by \\text{II}_p(v,w) = (S_p v) \\cdot w. Thus we also hope to find the matrix B so that for v,w \\in T_p \\Sigma, \\text{II}_p(v,w) = ({v^\\alpha})^T B w^\\alpha. The matrices A and B can be related using the metric on \\Sigma in coordinates. Namely, if we consider the matrix G so that v \\cdot w = (v^\\alpha)^T G w^\\alpha, then B = A^T G.\nComputing the Operator on Hyperbolic Surfaces\nWe now write n = n_1 + n_2, and work with the shape operator on the special case of a hyperbolic surface of the form\n\\Sigma = \\left\\{ (x,y,z) : z = \\frac{|x|^2 - |y|^2}{2} \\right\\}.\nwhere x \\in \\mathbb{R}^{n_1} and y \\in \\mathbb{R}^{n_2}. We will work in the coordinate chart \\alpha given by projection onto the (x,y) axis. At a point p = (x,y,z) on \\Sigma, let us write the resulting basis of T_p \\Sigma from the coordinate chart as \\partial_1^x, \\dots, \\partial_{n_1}^x, \\partial_1^y, \\dots, \\partial_{n_2}^y. We let e^z, e_1^x, \\dots, e_{n_1}^x, e_1^y, \\dots, e^y_{n_2} denote the standard basis for \\mathbb{R}^d.\nComputing the Second Fundamental Form\nDifferentiating \\alpha^{-1}(x,y) = \\left(x,y,\\frac{|x|^2 - |y|^2}{2} \\right), we see that\n\\partial_i^x = e_i^x + x_i e^z \\quad\\text{and}\\quad \\partial_j^y = e_j^y - y_j e^z.\nWe also calculate that the unit normal vector n_p \\in \\mathbb{R}^d to \\Sigma at p is equal to\nn_p = (1/r) (x \\cdot e^x - y \\cdot e^x - e^z),\nwhere r = \\sqrt{1 + |x|^2 + |y|^2}.\nSince we have an expression for n_p involving the (x,y) coordinates, it is simple to compute the directional derivative of n_p in the directions \\partial_i^x and \\partial_i^y by differentiating the expression above in x and y. We thus find by the product rule that there exists constants c_i^x and c_i^y so that\nS_p(\\partial^x_i) = (1/r) e^x_i + c^x_i n_p\nand\nS_p(\\partial_j^y) = (-1/r) e^y_j + c^y_j n_p.\nSince n_p is orthogonal to all elements of T_p \\Sigma, we immediately conclude from this calculation that the matrix B representing the second fundamental form II_p is given by\nB = (1/r) \\begin{pmatrix} + I_{n_1 \\times n_1} &amp; 0_{n_1 \\times n_2} \\\\ 0_{n_2 \\times n_1} &amp; - I_{n_2 \\times n_2} \\end{pmatrix}\nThe Metric in Coordinates\nFrom the expressions of \\partial^x_i and \\partial^y_j in the standard basis vectors on \\mathbb{R}^d, we can immediately compute the matrix G representing the metric. It takes the form\nG = I_{n \\times n} + \\begin{pmatrix} x x^T &amp; - xy^T \\\\ - yx^T &amp;  yy^T \\end{pmatrix}\nInverting this expression gives that\nG^{-1} = I_{n \\times n} - \\frac{1}{1 + |x|^2 + |y|^2} \\begin{pmatrix} xx^T &amp; - xy^T \\\\ - yx^T &amp; yy^T \\end{pmatrix}\nAs can be verified by a simple direct computation. Alternatively, we see that G has x e^x - y e^y as an eigenvector, with eigenvalue 1 + |x|^2 + |y|^2, and G acts as the identity on the orthogonal complement to the line generated by this eigenvector. Conversely, G^{-1} has xe^x - ye^y as an eigenvector, with eigenvalue (1 + |x|^2 + |y|^2)^{-1}, and acts as the identity on the orthogonal complement to the line generated by this eigenvector.\nWe thus conclude from the identity B = A^TG that A = G^{-1} B. Thus we find that\nA &amp;= (1/r) \\begin{pmatrix} I &amp; 0 \\\\ 0 &amp; -I \\end{pmatrix} - (1/r^3) \\begin{pmatrix} xx^T &amp; -xy^T \\\\ -yx^T &amp; yy^T \\end{pmatrix} \\begin{pmatrix} I &amp; 0 \\\\ 0 &amp; -I \\end{pmatrix}\\\\\n&amp;= (1/r) \\begin{pmatrix} I &amp; 0 \\\\ 0 &amp; -I \\end{pmatrix} - (1/r^3) \\begin{pmatrix} xx^T &amp; xy^T \\\\ -yx^T &amp; -yy^T \\end{pmatrix}.\n\\end{aligned}$$\n\nWe note that, even though $S_p$ is self-adjoint with respect to the inner product on $T_p \\Sigma$, the matrix $A$ need not be symmetric since it is not defined with respect to an orthogonal basis. And indeed, this is the case. But $A$ is self-adjoint with respect to a certain inner product, and thus diagonalizable.\n\nClearly vectors with components $(a,0)$ with $a \\cdot x = 0$ are eigenvectors of $A$ with eigenvalue $1/r$. Similarly, vectors with components $(0,b)$ with $b \\cdot y = 0$ are eigenvectors with eigenvalue $-1/r$. If $(x,y) = 0$, then this describes all eigenvectors of $A$. If $x = 0$ but $y \\neq 0$, then the only remaining eigenvector is $(0,y)$, with eigenvalue $-1 / r^3$. If $x \\neq 0$ but $y = 0$, then the only remaining eigenvector is $(x,0)$ with eigenvalue $1/r^3$. Finally, if $x \\neq 0$ and $y \\neq 0$, then we have two remaining eigenvectors. In the basis $x \\cdot e^x$ and $y \\cdot e^y$ for the invariant subspace of $A$ given by the span of the two remaining eigenvectors, the matrix $A$ has the representation as the $2 \\times 2$ matrix\n\nM = (1/r) \\begin{pmatrix} 1 &amp; 0 \\ 0 &amp; -1 \\end{pmatrix} - (1/r^3) \\begin{pmatrix} |x|^2 &amp; |y|^2 \\ -|x|^2 &amp; -|y|^2 \\end{pmatrix}\n\nNow $\\text{tr}(M) = -z/r^3$ and $\\text{det}(M) = -1/r^4$. From this, we compute that the two eigenvalues of $M$, which are the two remaining eigenvalues $\\lambda_+$ and $\\lambda_-$ of $A$, given by\n\n\\lambda_{\\pm} = \\frac{-z \\pm \\sqrt{ z^2 + 4r^2 }}{2r^3}\n\n An eigenvector $v_+$ of $M$ corresponding to $\\lambda_+$ is\n\n\\begin{pmatrix} 2|y|^2 \\ 2 + 2|y|^2 - (-z + \\sqrt{z^2 + 4r^2}) \\end{pmatrix} = \\begin{pmatrix} r^2 - z^2 - 1 \\ 1 + r^2 - \\sqrt{z^2 + 4r^2} \\end{pmatrix}.\n\nAn eigenvector $v_-$ of $M$ corresponding to $\\lambda_-$ is\n\n\\begin{pmatrix}\n2|y|^2 \\ 2 + 2|y|^2 - (-z - \\sqrt{z^2 + 4r^2})\n\\end{pmatrix} = \\begin{pmatrix}\nr^2 - z^2 - 1 \\ 1 + r^2 + \\sqrt{z^2 + 4r^2}\n\\end{pmatrix}\n\nwhich can then be converted into the two remaining eigenvectors of $A$.\n\nNote that when $z = 0$, we get $\\lambda_{\\pm} = \\pm r^{-2}$,\n\nv_+ = \\begin{pmatrix} r+1 \\ r-1 \\end{pmatrix} \\quad\\text{and}\\quad v_- = \\begin{pmatrix} r-1 \\ r+1 \\end{pmatrix},\n\nFor large $r$ these vectors look like almost multiples of one another, but not with respect to the metric $G$.\n##### Wedge Products of Normals With The Shape Operator\n\nNow consider two points $p$, and $q_1,\\dots,q_k$. The curvature condition of Bejanaru states that for unit normal vectors $\\{ n_p, n_{q_1}, \\dots, n_{q_k} \\}$ to caps, if we define $V = \\text{span}(n_p, n_{q_1}, \\dots, n_{q_k} )$, then the linear operator $\\pi_{V^\\perp} \\circ S_p|_{V^\\perp}$ is invertible, where $\\pi_{V^\\perp}$ is the orthogonal projection onto $V^\\perp$.\n\nThis condition fails precisely when there exists a unit vector $v$ in $T_p \\Sigma$ orthogonal to $\\{ n_p, n_{q_1}, \\dots, n_{q_k} \\}$, with the property that $S_pv$ *is* in the span of the unit normal vectors $\\{ n_p, n_{q_1}, \\dots, n_{q_k} \\}$. This would imply that $S_p v \\cdot v = 0$ since $v$ is orthogonal to the unit normal vectors. Thus $v$ lies in the cone $\\Gamma = \\{ a \\cdot \\partial^x + b \\cdot \\partial^y : |a| = |b| \\}$, which is precisely the family of vectors such that $S_p v \\cdot v = 0$, because if $v = a \\cdot \\partial_\\alpha + b \\cdot \\partial_\\beta$ then $S_p v \\cdot v = |a|^2 - |b|^2$. In particular, we see that the curvature condition *fails* for a family of normal vectors $V = \\{ n_p, n_{q_1}, \\dots, n_{q_k} \\}$ whenever $V^\\perp$ contains a vector $v \\in \\Gamma$ such that $S_p v \\in V$.\n\n#### Barron&#039;s Condition on Curvature\n\nConversely, Barron&#039;s condition fails for two points $p$ and $q$ with coordinates $(\\alpha_1,\\beta_1)$ and $(\\alpha_2,\\beta_2)$ whenever $(\\alpha_1 - \\alpha_2) \\cdot \\partial_\\alpha + (\\beta_1 - \\beta_2) \\partial_\\beta \\in \\Gamma$. We claim this condition is, *in the bilinear case*, entirely equivalent to Bejenaru&#039;s condition. In the bilinear case, using the notation of Bejenaru&#039;s condition above, $V^\\perp \\cap T_p \\Sigma$ is a line spanned by the orthogonal projection $\\pi_p(n_q)$ of $n_q$ onto $T_p \\Sigma$. Since $S_p$ is invertible, it follows that Bejanaru&#039;s condition reduces to observing when $S_p^{-1}(\\pi_p(n_q)) \\in B$. The following proposition thus shows that Barron and Bejenaru&#039;s conditions are equivalent.\n\n**Proposition**: Fix $p,q \\in \\Sigma$. Then $S_p^{-1}(\\pi_p(n_q))$ is a constant multiple of $(\\alpha_1 - \\alpha_2) \\cdot \\partial_\\alpha + (\\beta_1 - \\beta_2) \\partial_\\beta$.\n\n*Proof*: The proposition is invariant under linear transformations of the coordinates $(\\alpha,\\beta)$ that preserve $|\\alpha|^2 - |\\beta|^2$. The action of these transformations is transitive on the level sets of the function $|\\alpha|^2 - |\\beta|^2$. It therefore suffices to prove the proposition when $\\alpha = te_1$ and $\\beta = 0$, for some $t \\in \\mathbb{R}$, or when $\\alpha = 0$ and $\\beta = te_1$, for some $t \\in \\mathbb{R}$. We will only focus on the first case (though the second can likely be reduced to the first by applying reflection symmetries).\n\nWrite $\\alpha = (\\lambda,\\gamma)$. Then the metric of $\\Sigma$ at $p$ is given by\n\ng_p = (1 + 4t^2) d\\lambda^2 + d\\gamma^2 + d\\beta\n\nIt thus follows from our formula for $\\text{II}^p$ that\n\nS_p( a \\partial_{\\lambda} + b \\cdot \\partial_{\\gamma} + c \\cdot \\partial_\\beta ) = \\left( \\frac{a}{1 + 4t^2} \\right) \\partial_{\\lambda} + b \\cdot \\partial_{\\gamma} - c \\cdot \\partial_\\beta\n\nRecalling that $q$ has coordinates $(\\alpha_2,\\beta_2) = (\\lambda_2,\\gamma_2,\\beta_2)$, one can verify that the orthogonal projection of $n_q$ onto $T_p\\Sigma$ is given by a constant multiple of\n\n\\left( \\frac{\\lambda_2 - t}{1 + 4t^2} \\right) \\partial_\\lambda + \\gamma_2 \\cdot \\partial_\\gamma - \\beta_2 \\cdot \\partial_\\beta.\n\nApplying $S_p^{-1}$ to this vector, we obtain the vector\n\n\\left( \\lambda_2 - t \\right) \\partial_\\lambda + \\gamma_2 \\cdot \\partial_\\gamma - \\beta_2 \\cdot \\partial_\\beta.\n\nThis vector is negation of $(\\alpha_1 - \\alpha_2) \\cdot \\partial_\\alpha + (\\beta_1 - \\beta_2) \\partial_\\beta$.  □\n\n#### Configurations of Bad Caps\n\nFor a family of caps, Bejenaru&#039;s condition fails for a family of normal vectors $\\{ n_p, n_{q_1}, \\dots, n_{q_k} \\}$ whenever there span $V$ has the property that $V^\\perp$ contains a vector $v$ such that $S_p v \\in V$. It is thus natural to consider the Grassmannian $\\text{Gr}_k(T_p \\Sigma)$, the space of $k$-dimensional subspaces of $T_p \\Sigma$, and to consider the Grassmannian variety\n\n\\mathcal{Z} = { V \\in \\text{Gr}_k(T_p \\Sigma) : \\text{there exists v \\in V^\\perp - \\{ 0 \\} such that S_p v \\in V} }\n\nIndeed, normal vectors $\\{ n_p, n_{q_1}, \\dots, n_{q_k} \\}$ fail Bejenaru&#039;s condition whenever the projection of the vectors $\\{ n_{q_1}, \\dots, n_{q_k} \\}$ onto $T_p \\Sigma$ span an element of $\\mathcal{Z}$.\n\nLet us simplify our analysis by starting with the assumption that $p = 0$. Then $T_p \\Sigma$ is just the $(x,y)$ plane, and the matrix $A$ representing $S_p$ is given by\n\n\\begin{pmatrix} +I_{n_1 \\times n_1} &amp; 0_{n_1 \\times n_2} \\ 0_{n_2 \\times n_1} &amp; -I_{n_2 \\times n_2} \\end{pmatrix}\n\tTo determine the structure of $\\mathcal{Z}$, we apply a system of coordinates to $\\text{Gr}_k(T_p \\Sigma)$. Let us assume for simplicity that $k \\leq n_1$. Let $x = (x^\\alpha,x^\\beta)$, where $x^\\alpha \\in \\mathbb{R}^k$ and $x^\\beta \\in \\mathbb{R}^{n_1 - k}$. Then all elements $V$ of $\\text{Gr}_k(T_p \\Sigma)$ which intersect the $x^\\alpha$ axis transversally (which holds generically) can be written uniquely as $\\{ (x^\\alpha,Mx^\\alpha,Nx^\\alpha) \\}$, for a $(n_1 - k) \\times k$ matrix $M$ and a $n_2 \\times k$ matrix $N$. We view the pair of matrices $M$ and $N$ as coordinates parameterizing an element of $\\text{Gr}_k(T_p \\Sigma)$. We will call them systems of *Grassmann coordinates*, though I don&#039;t think this term is standard.\n\nGiven $V$ parameterized by $M$ and $N$, a vector $(v^\\alpha, v^\\beta, v^y)$ is in $V^\\perp$ when for all $x^\\alpha$,\n\nv^\\alpha \\cdot x^\\alpha + v^\\beta \\cdot M x^\\alpha + v^y \\cdot Nx^\\alpha = 0,\n\ni.e. when $v^\\alpha + M^T v^\\beta + N^T v^y = 0$. Conversely, $S_p(v^\\alpha ,v^\\beta, v^y) = (v^\\alpha, v^\\beta, -v^y)$ is in $V$ when there exists some $x^\\alpha$ with $v^\\alpha = x^\\alpha$, $v^\\beta = Mx^\\alpha$, and $v^y = - Nx^\\alpha$. Combining these equations, we find that it must be true that $(I + M^T M - N^T N) x^\\alpha = 0$, and this condition implies the converse; that is, we conclude that $V$ lies in $\\mathcal{Z}$ if and only if $I + M^T M - N^T N$ is not invertible. This corresponds to a quadratic equation $\\det(I + M^T M - N^T N) = 0$ in the Grassmann coordinates $M$ and $N$ for $V$. Thus we see that $\\mathcal{Z}$ is a quadratic surface in this coordinate system.\n\nExperimentally, it seems that $\\mathcal{Z}$ is a non-degenerate quadratic in all cases but when $n = 2$, $n_1 = n_2 = 1$, and $k = 1$. In this case, $M$ does not really factor into the parameterization since it is a $0 \\times 1$ matrix, $N$ is a $1 \\times 1$ matrix with a single component $b$, and\n\n\\det( I + M^T M - N^T N ) = -(b -1)(b + 1)\n\nThus in this case we thus see that $\\mathcal{Z}$ consists of two points. This corresponds to the fact that Bejenaru&#039;s condition fails in bilinear analysis fails for $\\{ n_p, n_q \\}$ when the projections of $n_q$ onto $n_p$ lies along one of two different lines.\n\nIf we next consider the case $n = 4$, $n_1 = n_2 = 2$, and $k = 1$, then $M$ is a $1 \\times 1$ matrix with some entry $a$, and $N$ a $2 \\times 1$ matrix with entries $b_1$ and $b_2$. In this case\n\n\\det(I + M^T M - N^T N) = 1 + a^2 - b_1^2 - b_2^2.\n\nThis defines an irreducible quadratic in the variables $a$, $b_1$, and $b_2$. In particular, this means that $\\mathcal{Z}$ is infinite in this case, and so Bejenaru&#039;s condition can fail for $\\{ n_p, n_q \\}$ if the projection of $n_q$ onto $n_p$ lie along one of an $2$ dimensional family of &#039;forbidden&#039; lines, which generate a cone.\n\nThings become worse when $k &gt; 1$. If $n = 4$, $n_1 = n_2 = 2$, and $k = 2$, then $M$ is a $0 \\times 2$ matrix, $N$ is a $2 \\times 2$ matrix with entries $\\{ b_{ij} \\}$, and then\n\n\\det(I + M^TM - N^TN) = 1 - b_{11}^2 - b_{12}^2 - b_{21}^2 + b_{12}^2 b_{21}^2 - 2 b_{11} b_{12} b_{21} b_{22} - b_{22}^2 + b_{11}^2 b_{22}\n\nMathematica does not believe that this quantity factors, and graphing the solution set gives what looks to be an irreducible variety. A consequence of this is that Bejenaru&#039;s condition can fail for $\\{ n_p, n_{q_1}, n_{q_2} \\}$ when the projection of $n_{q_1}$ and $n_{q_2}$ onto $T_p \\Sigma$ generate a plane which is contained in one of a $3$ dimensional family of &#039;forbidden&#039; planes.\n\nIf $n_{q_1}$ is fixed, can we find an equation for $n_{q_2}$ that determine when the span of the projections of $n_{q_1}$ and $n_{q_2}$ generate such a forbidden plane? To begin with, if $v$ and $w$ are given, we must convert $V = \\text{span}(v,w)$ into coordinates on the Grassmannian. Then any vector in $V$ can be written as $(av^+ + bw^+, av^- + bw^-)$, so that we see $V = \\{ (v^+, Nv^+) \\}$ where\n\nN = \\begin{pmatrix} v^- &amp; w^- \\end{pmatrix} \\begin{pmatrix} v^+ &amp; w^+ \\end{pmatrix}^{-1}.\n\nWe can simplify, writing\n\n$$\\begin{aligned}\n N &amp;= \\frac{1}{v^+_1 w^+_2 - v^+_2 w^+_1} \\begin{pmatrix} v^-_1 &amp; w^-_1 \\\\ v_2^- &amp; w_2^- \\end{pmatrix} \\begin{pmatrix} w^+_2 &amp; -w^+_1 \\\\ -v^+_2 &amp; v^+_1 \\end{pmatrix}\n\\end{aligned}$$\n\ni.e. so that if $N = \\left( \\begin{smallmatrix} b_{11} &amp; b_{12} \\\\ b_{21} &amp; b_{22} \\end{smallmatrix} \\right)$, where\n\n$$\\begin{aligned}\nb_{11} &amp;= \\frac{v^-_1 w_2^+ - w^-_1 v^+_2}{v_1^+ w_2^+ - v_2^+ w_1^+}\\\\\nb_{12} &amp;= \\frac{- v_1^- w^+_1 + w_1^- v_1^+}{v_1^+ w_2^+ - v_2^+ w_1^+}\\\\\nb_{21} &amp;= \\frac{v^-_2 w_2^+ - w_2^- v^+_2}{v_1^+ w_2^+ - v_2^+ w_1^+}\\\\\nb_{22} &amp;= \\frac{- v_2^- w^+_1 + w_2^- v_1^+}{v_1^+ w_2^+ - v_2^+ w_1^+}\n\\end{aligned}$$\n\nWe can then substitute these parameters into the equation for $\\det(I + M^TM - N^TN)$ above to determine an equation in $v$ and $w$ determining when Bejenaru&#039;s condition fails. This condition becomes equivalent to the vanishing of an irreducible bi-homogeneous polynomial of degree two in each of the variables of $v$ and $w$ (thus a degree four homogeneous polynomial jointly). Thus for a generic choice of $v$, the set of forbidden choices of $w$ lie on an irreducible quadratic in $T_p \\Sigma$.\n\nTo determine the *centers of the caps* that are forbidden, if the center of a cap $q$ has coordinates $(x,y)$, then when $p = 0$, the projection of $n_q$ onto $T_p \\Sigma$ has $(x,y)$ coordinates $(x/r, -y/r)$. Since the polynomials that define the forbidden regions are homogeneous, we can forget about the $r$ parameter. Thus the cap centered $q$ is forbidden when the vector $w = (x,-y)$ is forbidden. On Desmos, this seems to be a cone for many values of $v$, but some of the conics seem different for some values, and I don&#039;t see to understand when such values occur (talk to Jianghao and Jonathan about this).\n\nHow does the case $n = 3$, $n_1 = 2$, $n_2 = 1$, $k = 2$ look? Here $M$ is a $0 \\times 2$ matrix and and $N$ is a  $1 \\times 2$ matrix with entries $b_1$ and $b_2$, and Bejanaru&#039;s condition in coordinates on the Grassmanian is that\n\n1 + b_1^2 - b_2^2 = 0.\n\nGiven two vectors $(v^+,v^-)$ and $(w^+,w^-)$ in $T_p \\Sigma$, we have\n\n$$\\begin{aligned}\n\\begin{pmatrix} b_1 &amp; b_2 \\end{pmatrix} &amp;= \\begin{pmatrix} v^- &amp; w^- \\end{pmatrix} \\begin{pmatrix} v^+ &amp; w^+ \\end{pmatrix}^{-1}\\\\\n&amp;= \\frac{1}{v^+_1 w^+_2 - v^+_2 w^+_1} \\begin{pmatrix} v^- &amp; w^- \\end{pmatrix} \\begin{pmatrix} w^+_2 &amp; - w^+_1 \\\\ - v^+_2 &amp; v^+_1 \\end{pmatrix}.\n\\end{aligned}$$\n\nThus we have\n$$\\begin{aligned}\nb_1 &amp;= \\frac{1}{v^+_1 w^+_2 - v^+_2 w^+_1} \\begin{pmatrix} v^- w^+_2 - w^- v_2^+ \\end{pmatrix}\\\\\nb_2 &amp;= \\frac{1}{v^+_1 w^+_2 - v^+_2 w^+_1} \\begin{pmatrix} -v^- w^+_1 + w^- v_1^+ \\end{pmatrix}\n\\end{aligned}$$\n\nPlugging in the vector $w = (x,-y)$ and observing the output on Desmos, we see that the cap is bad when it lies on one of two flat planes. So we *can* apply our analysis in this situation.\n\nHow does the case $n = 4$, $n_1 = 3$, $n_2 = 1$, $k = 3$ look? Here $M$ is a $0 \\times 3$ matrix and $N$ is a $1 \\times 3$ matrix. If we write the entries of $N$ as $b_1,b_2$, and $b_3$, then the equation for Bejenaru&#039;s condition to fail becomes\n\n1 - b_1^2 - b_2^2 - b_3^2 = 0\n\nGiven three vectors $v = (v^+,v^-)$, $w = (w^+,w^-)$, and $u = (u^+, u^-)$, the Grassmann coordinates of the vector space spanned by $v$ and $w$ are given by\n\n\\begin{pmatrix} b_1 &amp; b_2 &amp; b_3 \\end{pmatrix} = \\begin{pmatrix} v^- &amp; w^- &amp; u^- \\end{pmatrix} \\begin{pmatrix} v^+ &amp; w^+ &amp; u^+ \\end{pmatrix}^{-1}\n\nComputing this inverse and viewing the caps on desmos, we see that for each $v$ and $w$, the set of $u$ that are forbidden forms a cone.\n##### A Possible Line of Attack\n\nOne option that may help us is to consider whether the multilinear restriction theorem holds, under a weaker range of $p$, under *weaker* curvature assumptions on the linear operator $\\pi_{V^\\perp} \\circ S_p|_{V^\\perp}$, i.e. that it has rank at least $l$ for some fixed $l \\leq n-k$. Since Tacy&#039;s argument only requires Stein-Tomas $L^2$ estimates interpolated with transversality estimates, it may be possible to adapt her argument to this more general situation. This may possibly cut down the number of &#039;bad caps&#039; to consider, which may result in better numerology when considering the relevant induction on scales."},"Quick-Notes/Enemies-in-Multilinear-Restriction":{"slug":"Quick-Notes/Enemies-in-Multilinear-Restriction","filePath":"Quick Notes/Enemies in Multilinear Restriction.md","title":"Enemies in Multilinear Restriction","links":["Quick-Notes/Wave-Packet-Decomposition-For-Extension"],"tags":[],"content":"A regulus S is a degree 2 algebraic surface in \\mathbb{R}^3 which is doubly ruled, i.e. there are two families of lines, which we might call horizontal and vertical, and each point lies in a horizontal line and a vertical line.\n\nPlanar Examples:\nReguli: Consider Wave Packets f = \\sum f_T, where the sum is restricted to R^{1/2} \\times R tubes taking from the ruling of S \\cap B_R, with each wave packet having the same L^2 norm. This example is sharp for some bilinear restriction estimates.\n"},"Quick-Notes/Important-Exponents-in-Restriction-Theory":{"slug":"Quick-Notes/Important-Exponents-in-Restriction-Theory","filePath":"Quick Notes/Important Exponents in Restriction Theory.md","title":"Important Exponents in Restriction Theory","links":["Problems/The-Multilinear-Restriction-Conjecture"],"tags":[],"content":"Here we are working with restriction operators for curved hypersurfaces of dimension n in \\mathbb{R}^d. We also look at the value of |1/p - 1/2|, which we call the Distance to 1/2.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nExponentValueDistance to 1/2Restriction Exponent\\frac{2d}{d-1}\\frac{1}{2d}Stein-Tomas Exponent\\frac{2(d+1)}{d+3}\\frac{1}{d+1}Dual Stein-Tomas ExponentDecoupling Exponent\\frac{2(d+1)}{d-1}\\frac{1}{d+1}Keel-Tao ExponentDual Heo-Nazarov-Seeger Exponent\\frac{2(d-1)}{d-3}\\frac{1}{d-1}Heo-Nazarov-Seeger Exponent\\frac{2(d-1)}{d+1}\\frac{1}{d-1}Multilinear Restriction (k-linear)\\frac{2(d+k)}{d+k-2}\\frac{1}{d+k}"},"Quick-Notes/Induction-on-Scales":{"slug":"Quick-Notes/Induction-on-Scales","filePath":"Quick Notes/Induction on Scales.md","title":"Induction on Scales","links":["2006---Bennett-Carbery-Tao---On-The-Multilinear-Restriction-And-Kakeya-Conjectures","1998---Tao-Vargas-Vega---A-Bilinear-Approach-to-the-Restriction-and-Kakeya-Conjectures"],"tags":[],"content":"Suppose C(R) is a finite quantity chosen for each integer R &gt; 0, such that, by some (hopefully trivial) argument, we can justify C(R) = R^{O(1)}. The goal of induction on scales is, by bounding C(R) in terms of C(R&#039;) for a small R&#039;, to obtain a bound C(R) \\lesssim_\\varepsilon R^\\varepsilon for all \\varepsilon &gt; 0. We write A \\lessapprox B if A \\lesssim_\\varepsilon R^\\varepsilon B for all \\varepsilon &gt; 0.\n\nIf C(R) \\lessapprox C(R^\\alpha) for some 0 &lt; \\alpha &lt; 1 and all \\varepsilon &gt; 0, and we know that C(R) \\lesssim R^{O(1)}, then induction on scales can guarantee that C(R) \\lessapprox 1. This is used, for instance in the Bennett Carbery Tao Multilinear Restriction Theorem.\nIf C(R) \\lessapprox C(R^{1 - \\delta}) + R^{O(\\delta)} for all \\delta &gt; 0, then C(R) \\lessapprox 1. This is used, for instance, in Tao Vargas Vega.\nIf C(R) \\lesssim_\\varepsilon (1 + \\varepsilon) C(R/10) then we obtain that C(R) \\lessapprox 1.\n\nIf C(R) \\leq A C(R/10) then A \\leq 10^\\varepsilon"},"Quick-Notes/Keel-Tao-Estimates-on-Subset-of-Variables":{"slug":"Quick-Notes/Keel-Tao-Estimates-on-Subset-of-Variables","filePath":"Quick Notes/Keel-Tao Estimates on Subset of Variables.md","title":"Keel-Tao Estimates on Subset of Variables","links":[],"tags":[],"content":"Consider the Schrödinger operator e^{i t \\Delta} on \\mathbb{R}^d = \\mathbb{R}^n_x \\oplus \\mathbb{R}^m_y, where n + m = d. Then we want to prove that if p = 2m/(m-2), and if \\widehat{f} is supported on the unit ball, then\n\\| e^{it \\Delta} f \\|_{L^2_x(\\mathbb{R}^n) L^p_y(\\mathbb{R}^m)} \\lesssim \\langle t \\rangle^{-1} \\| f \\|_{L^2_x(\\mathbb{R}^n) L^{p&#039;}_y(\\mathbb{R}^m)}.\nThen a Young’s inequality argument in the t variable establishes that the extension operator \\mathcal{E} for the paraboloid \\{ \\tau = |\\xi|^2 + |\\eta|^2 \\} satisfies\n\\| (\\mathcal{E} \\circ \\mathcal{E}^*) f \\|_{L^2_t(I_R) L^2_x(\\mathbb{R}^n) L^p_y(\\mathbb{R}^m)} \\lessapprox \\| f \\|_{L^2_t(I_R) L^2_x(\\mathbb{R}^n) L^{p&#039;}_y(\\mathbb{R}^m)}\nwhich by the TT^* method is sufficient to conclude that \\mathcal{E} is bounded from L^2_\\xi(\\mathbb{R}^n) L^2_\\eta(\\mathbb{R}^m) to L^2_t(\\mathbb{R}^n) L^2_x(\\mathbb{R}^n) L^p_y(\\mathbb{R}^m), which is Proposition 2.2 of Tacy’s paper.\nTo prove the estimate above, we write e^{it \\Delta} = e^{it \\Delta_x} \\circ e^{it \\Delta_y}. Let us assume that\n\\| e^{it \\Delta_x} f \\|_{L^2_x L^1_y} \\lesssim \\| f \\|_{L^2_x L^1_y}.\nApplying the usual dispersive estimates for \\Delta_y, one can conclude that\n\\| e^{it \\Delta_y} f \\|_{L^2_x L^\\infty_y} \\lesssim |t|^{-m/2} \\| f \\|_{L^2_x L^1_y}.\nCombining the above two bounds, we obtain that\n\\| e^{it \\Delta} f \\|_{L^2_x L^\\infty_y} \\lesssim |t|^{-m/2} \\| f \\|_{L^2_x L^1_y}.\nOn the other hand, purely by energy conservation we obtain that\n\\| e^{it \\Delta} f \\|_{L^2_x L^2_y} \\lesssim \\| f \\|_{L^2_x L^2_y}.\nInterpolation then yields that \\| e^{it \\Delta} f \\|_{L^2_x L^p_y} \\lesssim |t|^{-1} \\| f \\|_{L^2_x L^{p&#039;}_y}, as was required."},"Quick-Notes/Local-Constancy-Heuristics-and-the-Uncertainty-Principle":{"slug":"Quick-Notes/Local-Constancy-Heuristics-and-the-Uncertainty-Principle","filePath":"Quick Notes/Local Constancy Heuristics and the Uncertainty Principle.md","title":"Local Constancy Heuristics and the Uncertainty Principle","links":[],"tags":[],"content":"Let f be a function whose Fourier transform is supported on the ball \\{ \\xi : |\\xi| \\leq R \\}. The local constancy heuristic, or the uncertainty principle, says that f is ‘locally constant’ at a scale 1/R. There are several ways of making this precise:\nBernstein’s Inequality\nIf a function f was locally constant at a scale 1/R, then on each ball B of radius 1/R, we might expect the function f as having a certain ‘height’ H. It would then follow that \\| f \\|_{L^p(B)} \\sim H R^{-d/p}. In particular, this would imply that R^{d/p} \\| f \\|_{L^p(B)} \\sim R^{d/q} \\| f \\|_{L^q(B)} for all 1 \\leq p \\leq q \\leq \\infty. This is, heuristically speaking, the case, if we replace local integrals on B with pseudo-local integrals. One direction of this inequality follows immediately from Hölder’s inequality. The other requires slightly more work.\nFirst, Bernstein’s inequality says that\n\\| f \\|_{L^{p,s}(\\mathbb{R}^d)} \\lesssim R^s \\| f \\|_{L^p(\\mathbb{R}^d)}.\nBut this equation can also be localized. Fix r &gt; s, which can be arbitrarily large. For each B, let w_B = \\left\\langle  \\frac{d(x,B)}{\\text{Rad}(B)} \\right\\rangle^{-r}, and let \\tilde{w}_B = \\left\\langle  \\frac{d(x,B)}{\\text{Rad}(B)} \\right\\rangle^{-t} for t \\leq s-r. Then Bernstein’s inequality says that\n\\| f \\|_{L^{p,s}(w_B)} \\lesssim R^s \\| f \\|_{L^p(\\tilde{w}_B)}.\nTo prove this result, we may assume by rescaling symmetries that R = 1. We then find a Schwartz function \\chi with |\\chi(x)| \\geq 1 for |x| \\leq 1, but with \\widehat{\\chi}(\\xi) supported on |\\xi| \\lesssim 1. Applying the usual Bernstein inequality, if we let \\chi_l(x) = \\chi(x / 2^l), then we have\n\\| f \\|_{L^{p,s}(w_B)} \\lesssim \\sum\\nolimits_{l \\geq 0} 2^{-lr} \\| \\chi_l f \\|_{L^{p,s}(\\mathbb{R}^d)} \\lesssim \\sum\\nolimits_{l \\geq 0} 2^{l(s-r)} \\| \\chi_l f \\|_{L^p(\\mathbb{R}^d)} \\lesssim \\| f \\|_{L^p(\\tilde{w}_B)}\nA similar argument using the Sobolev embedding theorem shows that the L^p improving inequality \\| f \\|_{L^q(w_B)} \\lesssim R^{d(1/p - 1/q)} \\| f \\|_{L^p(\\tilde{w}_B)} holds for p \\leq q &lt; \\infty, where w_B and \\tilde{w}_B are defined above, and where s = d(1/p - 1/q). In particular, since in this case s is always bounded by d. Customarily, one uses r &gt; d so that the inequality holds also when q = \\infty.\nPointwise Bounds\nIt follows from Bernstein’s inequality that if r &gt; d, then for each ball B, and for 1 \\leq p \\leq q \\leq \\infty,\n\\| f \\|_{L^q(B)} \\lesssim R^{d(1/p - 1/q)} \\| f \\|_{L^p(w_B)}\nLet us suppose that \\| f \\|_{L^p(w_B)} \\lesssim \\| f \\|_{L^p(B)}. This is often the case in practical considerations whe analyzing balls B which are significant to the L^p norm of the entire function f, i.e. if \\| f \\|_{L^q(B)} \\geq C^{-1} \\| f \\|_{L^q(\\mathbb{R}^d)} for some fixed constant C. Then we have the inequality\n\\| f \\|_{L^q(B)} \\lesssim R^{d(1/p - 1/q)} \\| f \\|_{L^p(B)}.\nIn particular, f is bounded by H_B = R^{d/p} \\| f \\|_{L^p(B)} on B. But this implies that for any \\varepsilon &gt; 0, there exists \\delta &gt; 0, depending only on the implicit constants, such that all but a fraction \\varepsilon of the points in B satisfy\n\\delta H_B \\leq |f(x)| \\lesssim H_B.\nThus we can think of f as having height H_B on almost all points of B, which is a kind of locally constant heuristic.\nMore generally, a version from this result follows if \\| f \\|_{L^p(w_B)} \\sim \\| f \\|_{L^p(\\tilde{w}_B)}, i.e. so that the L^p mass of f is not concentrated too far away from the ball B. We then conclude that for all \\varepsilon &gt; 0, there exists \\delta &gt; 0 so that for all but a fraction \\varepsilon of the points in \\mathbb{R}^d (with the fraction measured with respect to the weight w_B) satisfy \\delta H_B \\leq |f(x)| \\lesssim H_B."},"Quick-Notes/Polynomial-Partitioning":{"slug":"Quick-Notes/Polynomial-Partitioning","filePath":"Quick Notes/Polynomial Partitioning.md","title":"Polynomial Partitioning","links":["2015---Guth-Katz---On-The-Erdos-Distinct-Distances-Problem-in-the-Plane","2008---Dvir---On-the-Size-of-Kakeya-Sets-in-Finite-Fields","1990---Clarkson-Edelsbrunner-Guibas-Sharir-Welzl---Combinatorial-Complexity-Bounds-for-Arrangements-of-Curves-and-Spheres"],"tags":[],"content":"The idea of polynomial partitioning, introduced by Guth and Katz in their 2015 Paper on the Erdos distinct distances problem, is to combine the polynomial incidence geometric methods of Dvir with the divide and conquer approaches of divide and conquer partitioning approach introduced by CEGSW in incidence geometry.\nGiven a set X \\subset \\mathbb{R}^d of N points, the polynomial method allows us to find a polynomial of degree O(N^{1/d}) vanishing on X. In polynomial partitioning, for any D, we can choose a polynomial of degree D defining a hypersurface Z, such that \\mathbb{R}^d - Z is divided into O(D^d) cells, each containing O(N/D^d) points from X. The surface Z is called the cell wall, and the connected components of \\mathbb{R}^d - Z are called the cells. The problem then breaks down into two regimes:\n\nIf X contains few points in the cell wall, it must be evenly divided into each of the cells, so methods akin to  CEGSW apply.\nIf X contains many points in the cell wall, then we obtain structural information akin to Dvir’s Method.\n\nThe problem can also be applied to continuous problems. If f is a function on \\mathbb{R}^d, then for any D we can find a hypersurface Z defined by a polynomial of degree D so that the L^1 norm of f on each cell cut out by the surface Z is the same. However, to fully exploit the polynomial structure in the continuous setting we must often thicken the cell wall, so that e.g. any ‘transverse’ tube passes through the surface Z at most D times, and thus enters at most D + 1 cells. If the tubes we are considering have thickness \\delta, then we should let the \\delta neighborhood Z_\\delta of Z be the cell wall, and let the cells be the connected components of \\mathbb{R}^d - Z_\\delta. This is because it then follows that if a tube passes through a cell of \\mathbb{R}^d - Z_\\delta, then it’s central line passes through the corresponding cell in \\mathbb{R}^d - Z, and can only do this at most D + 1 times."},"Quick-Notes/Random-Rotations-Trick":{"slug":"Quick-Notes/Random-Rotations-Trick","filePath":"Quick Notes/Random Rotations Trick.md","title":"Random Rotations Trick","links":[],"tags":[],"content":""},"Quick-Notes/Rapidly-Decaying-Wave-Packet-Weights":{"slug":"Quick-Notes/Rapidly-Decaying-Wave-Packet-Weights","filePath":"Quick Notes/Rapidly Decaying Wave Packet Weights.md","title":"Rapidly Decaying Wave Packet Weights","links":[],"tags":[],"content":"TODO\nWith translation invariance, can go from local estimates to weighted estimates, so that the inequalities can be composed."},"Quick-Notes/Restricted-Decoupling-+-Kakeya-Implies-Restriction":{"slug":"Quick-Notes/Restricted-Decoupling-+-Kakeya-Implies-Restriction","filePath":"Quick Notes/Restricted Decoupling + Kakeya Implies Restriction.md","title":"Restricted Decoupling + Kakeya Implies Restriction","links":["Quick-Notes/The-Refined-Decoupling-Theorem"],"tags":[],"content":"Recall the The Refined Decoupling Theorem. In this note we discuss how to use this theorem, together with Kakeya type bounds, to prove Restriction Theorems. To begin with, we note that the refined decoupling theorem implies the following bound.\nTheorem: Suppose a family of tubes \\mathbb{T} can be divided into families of tubes \\mathbb{T}_\\theta which are R^{-1/2} direction separated, and \\#(\\mathbb{T}_\\theta) \\leq m for each \\theta. Then if X is a union of R^{1/2} balls, so that m(Q) \\leq M for each Q \\subset X, then\n\\| E_S f \\|_{L^p(X)} \\lessapprox R^{\\frac{n}{p} - \\frac{n-1}{2}} M^{\\frac{1}{p} \\frac{2}{n-1}} m^{1/p - 1/2} \\| f \\|_{L^p(M)}.\nProof: Applying the The Refined Decoupling Theorem, we find that\n\\| E_S f \\|_{L^p(X)}^p \\lessapprox M^{\\frac{2}{n-1}} \\sum\\nolimits_{T \\in \\mathbb{T}} \\| E_S f_T \\|_{L^p(w_R)}^p.\nNow \\| E_S f_T \\|_{L^p(w_R)}^p \\sim R^{ \\frac{p - p_{ST}}{2 - p_{ST}} } \\| f_T \\|_{L^2(M)}^p for each T \\in \\mathbb{T}, so\n\\sum\\nolimits_{T \\in \\mathbb{T}} \\| E_S f_T \\|_{L^p(w_R)}^p \\sim R^{\\frac{p - p_{ST}}{2 - p_{ST}}} \\sum\\nolimits_{T \\in \\mathbb{T}} \\| f_T \\|_{L^2(M)}^p.\nSince all the norms \\| f_T \\|_{L^2(M)} are all comparable, we have that for each \\theta,\n\\sum\\nolimits_{T \\in \\mathbb{T}_\\theta} \\| f_T \\|_{L^2(M)}^p \\sim m^{1 - p/2} \\left( \\sum\\nolimits_{T \\in \\mathbb{T}_\\theta} \\| f_T \\|_{L^2(M)}^2 \\right)^{p/2} \\sim m^{1 - p/2} \\| f_\\theta \\|_{L^2(M)}^p.\nBy H”{o}lder’s inequality, since f_\\theta is supported on a R^{-1/2} cap, we have\n\\| f_\\theta \\|_{L^2(M)}^p \\lesssim R^{- \\left( \\frac{n-1}{2} \\right) (p/2 - 1)} \\| f_\\theta \\|_{L^p(M)}^p.\nCombining these bounds gives that\n    \\| E_S f \\|_{L^p(X)}^p &amp;\\lessapprox M^{\\frac{2}{n-1}} m^{1 - p/2} R^{\\frac{p - p_{ST}}{2 - p_{ST}} - \\left( \\frac{n-1}{2} \\right) (p/2 - 1) } \\| f \\|_{L^p(M)}^p\\\\\n    &amp;= R^{n - \\left( \\frac{n-1}{2} \\right) p} M^{\\frac{2}{n-1}} m^{1 - p/2} \\| f \\|_{L^p(M)}^p.\n\\end{align}$$\n\nSo, if we can show a potential counterexample to a restriction bound is concentrated on a set $X$ upon which $M^{\\frac{2}{n-1}} m^{1 - p/2} \\lessapprox R^{ \\left( \\frac{n-1}{2} \\right) p - n }$, then we will have obtained a contradiction, thus proving the restriction bound. □\n\n*In particular, if $p = p_{ST}$ then the bound becomes*\n\n| E_S f |{L^{p{ST}}(X)} \\lesssim R^{-1/p_{ST}} (M/m)^{\\frac{1}{n+1}} | f |_{L^p(M)},\n*which will be important in a later calculation.*\n\nFor a given family of tubes $\\mathbb{T}$, controlling $M$ and $m$ simultaneously is a Kakeya type problem. If we consider a set $X$ formed from the union of $R^{1/2}$ tubes, such that $|X \\cap T| \\sim \\lambda |T|$ for each $T \\in \\mathbb{T}$, then the full Kakeya maximal conjecture implies the multiplicity of a generic $\\delta$-cube in $X$ is $O(m \\lambda^{1-n})$. So given a set $X$, after thinning $X$ appropriately we can set $M \\lesssim m \\lambda^{1-n}$ in the result above.\n\nLet us try and use this technique to obtain an extension bound. Assume that $\\| f \\|_{L^p(M)} = 1$. Consider a wave packet decomposition $f = \\sum f_{\\theta,\\nu}$ at a scale $R^{-1/2}$, and thus $E_S f = \\sum_{T \\in \\mathbb{T}} g_T$, where $T = \\{ T_{\\theta,\\nu}: f_{\\theta,\\nu} \\neq 0 \\}$. By pigeonholing, we may assume that there is $B &gt; 0$ so that $\\| f_{\\theta,\\nu} \\|_{L^\\infty(M)} \\sim B$ for all $T \\in \\mathbb{T}$. Let $X$ be a set, which we may assume to be $R^{1/2}$ discretized, we try and find $X_0 \\subset X$ with $|X_0| \\geq |X|/10$ so that $\\| E_S f \\|_{L^p(X_0)} \\lesssim 1$. We may assume $X$ is $R^{1/2}$ discretized, and by dyadic pigeonholing, we may find a dyadic scale $\\lambda$ so that $X(T) = X \\cap T$ satisfies $|X(T)| \\sim \\lambda |T|$ for some $\\lambda \\in [0,1]$ and all $T \\in \\mathbb{T}$. Because the functions $\\{ g_T \\}$ are orthogonal on $R^{1/2}$ cubes, they are also orthogonal on $X$, so\n\n| E_S f |{L^2(X)} \\lesssim \\left( \\sum | g_T |{L^2(X)}^2 \\right)^{1/2} \\sim (\\lambda R)^{1/2} \\left( \\sum | f_{\\theta,\\nu} |{L^2(M)}^2 \\right)^{1/2} = (\\lambda R)^{1/2} | f |{L^2(M)}.\n\nOn the other hand, if $p_{ST}$ is the Stein-Tomas exponent, we can find a set $X_0 \\subset X$ with $|X_0| \\geq |X|/10$ so that $M \\lesssim m \\lambda^{-(n-1)}$. If we could somehow improve this bound so we could assume $M \\lesssim m \\lambda^{- \\frac{n-1}{2}}$, then\n\n\\begin{align}\n| E_S f |{L^{p{ST}}(X_0)} &amp;\\lessapprox (M/m)^{ \\frac{1}{n+1}} R^{-\\frac{n-1}{2(n+1)}} | f |{L^{p{ST}}(X_0)}\\\n&amp;\\lessapprox (\\lambda R)^{- 1/p_{ST}} | f |{L^{p{ST}}(X_0)}\n\\end{align}\n\nInterpolating, we obtain that at the critical exponent for the restriction conjecture, i.e. for $p = 2n/(n-1)$,\n\n| E_S f |{L^p(X_0)} \\lesssim | f |{L^p(X_0)}.\n\nThis is sufficient to completely prove the restriction conjecture.\n\nIn general, we will be able to obtain square root cancellation in $\\lambda$ by forcing $X$ to satisfy a two-ends condition, and we can then use this to obtain restriction estimates. Given a set $X$ satisfying the two-ends condition, with $|X \\cap T| \\sim \\lambda |T|$ for each $T \\in \\mathbb{T}$, the bush argument of Bourgain gives that $|X| \\gtrapprox R^{\\frac{3n+1}{4}} \\lambda$, and so the average multiplicity of a cube $Q$ in $X$ is $M \\lesssim m \\lambda^{- \\frac{n-1}{n+1}} R^{-\\frac{(n-1)^2}{4(n+1)}} \\lambda^{-\\frac{n-1}{n+1}}$, which gives\n\n| E_S f |{L^{p{ST}}(X_0)} \\lessapprox R^{-\\frac{(n-1)[3n+1]}{4(n+1)^2}} \\lambda^{- \\frac{n-1}{(n+1)^2}} | f |{L^{p{ST}}}\n\nInterpolation between the $L^2$ estimate gives a result of the form\n\n| E_S f |{L^p(X_0)} \\lessapprox | f |{L^p(X_0)}\n\nfor $p = \\frac{2 + 2n(5n + 2)}{(n-1)(5n + 3)}$. In particular, for $n = 3$ this gives $p = 26/9 \\approx 2.89$."},"Quick-Notes/Reverse-Hölder's-Inequality-For-Fourier-Localized-Functions":{"slug":"Quick-Notes/Reverse-Hölder's-Inequality-For-Fourier-Localized-Functions","filePath":"Quick Notes/Reverse Hölder's Inequality For Fourier Localized Functions.md","title":"Reverse Hölder's Inequality For Fourier Localized Functions","links":["Quick-Notes/Local-Constancy-Heuristics-and-the-Uncertainty-Principle"],"tags":[],"content":"Suppose g_1,\\dots,g_k are functions with Fourier transform supported on balls of radius R. Suppose also that w_B and \\tilde{w}_B are weight functions, where w_B decays at a rate d times faster than \\tilde{w}_B, then for any ball B of radius 1/R,\nR^{d/p} \\prod\\nolimits_j \\| g_j \\|_{L^p(\\tilde{w}_B)}^{1/k} \\lesssim \\left\\| \\prod\\nolimits_j |g_j|^{1/k} \\right\\|_{L^p(w_B)}\nIn particular,\nR^{d/p} \\prod\\nolimits_j \\| g_j \\|_{L^p(B)}^{1/k} \\lesssim \\left\\| \\prod\\nolimits_j |g_j|^{1/k} \\right\\|_{L^p(w_B)}.\nThis is called a reverse Hölder’s Inequality because if we flip the inequality and forget about weights, then the inequality is a special case of Hölder’s inequality.\nRescaling, we may assume R = 1. The result follows by applying the Pointwise Locally Constant Property, together with a union bound, to conclude that 99% of all points in \\mathbb{R}^d, with respect to the weight \\tilde{w}_B, satisfy |g_j(x)| \\gtrsim R^{d/p} \\| g_j \\|_{L^p(w_B)}^{1/k} for each j, and for such points, we thus have \\prod_j |g_j|^{1/k} \\sim R^{d/p} \\prod_j \\| g_j \\|_{L^p(w_B)}^{1/k}. Integrating over this region, the inequality immediately follows.\nAn Alternate Approach\nThis method may have technical problems. The result would follow if we could prove the bilinear result\n\\left\\| f_1 \\right\\|_{L^p(\\tilde{w}_B)} \\| f_2 \\|_{L^p(\\tilde{w}_B)} \\lessapprox \\left\\| |f_1|^t |f_2|^{1-t} \\right\\|_{L^p(\\tilde{w}_B)},\nsince we could then apply induction. Using Bernstein’s inequality, we may assume without loss of generality that p \\geq 2/t, since the result for any particular 1 &lt; p &lt; \\infty implies the result for all p. Find a set S \\subset \\mathbb{R}^d so that \\| 1_S \\|_{L^1(w_B)} \\geq 0.999 \\| 1 \\|_{L^1(w_B)} and for x \\in S, |Ef_{\\theta_2}(x)| \\sim \\| Ef \\|_{L^p(w_B)} K^{-d/p}. Then applying the general reverse Hölder’s inequality for L^p spaces, we have\n\\left\\| |Ef_{\\theta_1}|^t |Ef_{\\theta_2}|^{1-t} 1_S \\right\\|_{L^p(w_B)} &amp;= \\| |Ef_{\\theta_1}|^{tp} |Ef_{\\theta_2}|^{p(1-t)} 1_S \\|_{L^1(w_B)}^{1/p}\\\\\n&amp;\\geq \\| |Ef_{\\theta_1}|^{tp} \\|_{L^{1/2}(w_B)}^{1/p} \\| |Ef_{\\theta_2}|^{p(1-t)} 1_S \\|_{L^{-1}(w_B)}^{1-t}\\\\\n&amp;= \\| Ef_{\\theta_1} \\|_{L^{tp/2}(w_B)}^t \\| Ef_{\\theta_2} 1_S \\|_{L^{-p(1-t)}(w_B)}^{1-t}\\\\\n&amp;\\sim \\left[ K^{(d/p)(2/t - 1)} \\| Ef \\|_{L^p(w_B)} \\right]^t \\left[ \\| Ef \\|_{L^p(w_B)} K^{-d/p} K^{\\frac{-d}{p(1-t)}} \\right]^{1-t}\\\\\n&amp;\\sim \\| Ef \\|_{L^p(w_B)}\n\\end{aligned}$$\n\nWe used the Sobolev embedding term to bound the first term in the second last line. But. now the general result follows by induction, since $\\prod_j Ef_{\\theta_j}$ also satisfies the local constancy property."},"Quick-Notes/Shadings":{"slug":"Quick-Notes/Shadings","filePath":"Quick Notes/Shadings.md","title":"Shadings","links":["Quick-Notes/We-Can-Remove-Exceptional-Sets-From-Lp-Estimates","Quick-Notes/Random-Rotations-Trick","Problems/The-Kakeya-Maximal-Inequality"],"tags":[],"content":"Suppose we have a family of subsets \\mathbb{A} in \\mathbb{R}^n, with |A| \\sim V for each A \\in \\mathbb{A}. Suppose we are trying to prove an inequality\n\\left\\| \\sum\\nolimits_{A \\in \\mathbb{A}} 1_A \\right\\|_{L^p(\\mathbb{R}^n)} \\lesssim C. \\tag{1}\nBy real interpolation, (1) is roughly equivalent to a restricted bound of the form\n\\sum |A \\cap X| \\leq C |X|^{1/d}, \\tag{2}\nwhere d = p&#039;. By dyadic pigeonholing, we may find \\mathbb{A}&#039; \\subset \\mathbb{A} and \\lambda \\in (0,1) so that |A \\cap X| \\sim \\lambda |A| for each A \\in \\mathbb{A}&#039;, and such that \\sum_{A \\in \\mathbb{A}} |A \\cap X| \\approx \\sum_{A \\in \\mathbb{A}&#039;} |A \\cap X|. Normally we have \\# \\mathbb{A} \\lesssim V^{-1}, so that M = (\\# (\\mathbb{A}&#039;) V)^{-1} is large. Then, rearranging, we find (2) is equivalent to\n|X| \\gtrapprox \\left( \\lambda / CM \\right)^d. \\tag{3}\nWe can state this process in the language of shadings. For each A \\in \\mathbb{A}, we pick X(A) \\subset A so that X(A) \\sim \\lambda |A| for each A. Such a choice is called a \\lambda-shading. The L^p inequality we wished to prove above is equivalent to proving that for any subset \\mathbb{A}&#039; of \\mathbb{A}, and any \\lambda-shading of \\mathbb{A}&#039;, the set X = \\bigcup X(A) satisfies |X| \\gtrapprox (\\lambda / CM)^d. Thus we see that upper bounds on L^p sum of indicator functions are roughly equivalent to lower bounding the size of shadings, which is a Kakeya type problem.\nThe Generic Multiplicity of Shadings\nSuppose that each set in \\mathbb{A} is \\delta-discretized (roughly speaking, a union of \\delta balls). For each \\delta ball Q, let M(Q) denote the number of sets in \\mathbb{A} containing Q. Then Markov’s inequality, applied to (1), implies that\n\\# \\{ Q : M(Q) \\geq M_0 \\} \\leq \\delta^{-n} C^p / M_0^p. \\tag{4}\nIf X is a \\delta-discretized \\lambda-shading of \\mathbb{A}&#039;, then (3) implies that X contains at least \\delta^{-n} (\\lambda / CM)^d balls of radius \\lambda. So (3) and (4) together imply that at least half the cubes in X have multiplicity at most O( C^d (M/\\lambda)^{d - 1} ). Conversely, if (3) and (4) hold, then we can obtain inequalities of the form (1) because We Can Remove Exceptional Sets From Lp Estimates.\nThe Special Case of Tubes\nIn the special case where we are studying the Kakeya inequality, \\mathbb{A} is a family of direction separated \\delta-tubes, V = \\delta^{1-n}, and C = \\delta^{1 - n/d}, The Random Rotations Trick allows us to assume that M \\sim 1, so the The Kakeya Maximal Inequality is roughly equivalent to prove that for any family \\mathbb{T} of \\sim \\delta^{1-n} direction separated \\delta tubes, and any \\lambda-shading X of \\mathbb{T}, |X| \\gtrapprox \\lambda^d \\delta^{n-d}. In particular, at least half the cubes in any \\lambda-shading of \\mathbb{T} must have multiplicity at most O(\\delta^{d - n} \\lambda^{1-d}).\nGeometric Means\nSuppose we have proved\n\\left\\| \\left( \\sum\\nolimits_{A_1 \\in \\mathbb{A}, \\dots, A_k \\in \\mathbb{A}_k} 1_{A_1} \\cdots 1_{A_k} \\right)^{1/k} \\right\\|_{L^p(\\mathbb{R}^n)} \\lesssim C. \\tag{1}\nwhere \\mathbb{A}_1,\\dots, \\mathbb{A}_k are families of \\delta discretized sets. The analogous weak bound is that if we let M_i(Q) denote the number of elements of \\mathbb{A}_i which contain a \\delta ball Q, then for any \\delta discretized set X,\n\\sum\\nolimits_{Q \\subset X} [M_1(Q) \\cdots M_k(Q)]^{1/k} \\lesssim C.\nPigeonholing, we may assume that X is a \\lambda-shading of the set of intersections\n\\mathbb{A} = \\{ A_1 \\cap \\cdots \\cap A_k : A_1 \\in \\mathbb{A}_1, \\dots, A_k \\in \\mathbb{A}_k \\}."},"Quick-Notes/Simultaneous-Saturation":{"slug":"Quick-Notes/Simultaneous-Saturation","filePath":"Quick Notes/Simultaneous Saturation.md","title":"Simultaneous Saturation","links":[],"tags":[],"content":"Suppose that T_1,\\dots,T_M are operators, with T_i mapping elements of a Hilbert space H_i to functions on a set X, where \\| T_i \\|_{H_i \\to L^2(X)} \\lesssim B. For each x, we consider the linear functional T_i(x) on H_i given by T_i(x) \\{ v \\} = (T_i v)(x). We identify T_i(x) with the corresponding vector in H_i which gives the linear functional via the inner product. Also fix a parameter \\lambda &gt; 0.\nLet us assume (a) that there is a relationship C_i on X for each i such that if C_i(x,y) does not hold, then \\langle T_i(x), T_i(y) \\rangle \\leq R(\\lambda), and (b) for each m \\leq M, the only \\{ x_1,\\dots,x_m \\} such that C_i(x_i,x_{i+1}) for each i are the trivial solution where x_1 = \\cdots = x_m. (TODO NOT SURE ABOUT DEGENERACY).\nLet N be the largest integer for which there exists N distinct points x_1,\\dots,x_N so that\n\\left| \\prod\\nolimits_{i = 1}^M (T_i v_i)(x_j) \\right|^{1/M} \\geq L \\left( \\prod\\nolimits_{i = 1}^M \\| v_i \\|_{H_i} \\right)^{1/M} \\quad\\text{for each $j \\in \\{ 1, \\dots, N \\}$}.\nSuppose we a priori know some upper bound N \\leq R(\\lambda)^{-\\varepsilon/M^2}, for some \\varepsilon &gt; 0. Then there exists C independent of B, L, and \\lambda so that\nN \\leq \\left( C (B/L)^{2 \\left( \\frac{M}{M-1} \\right)} \\right)^{\\frac{1}{1 - \\varepsilon}}.\nProof: Consider the linear map T from H_N = (\\prod_i H_i)^N to functions on X^{MN} given by\nTv(x) = \\prod\\nolimits_{i = 1}^M \\prod\\nolimits_{j = 1}^N (T_i v_{ij})(x_{ij})\nLet v \\in (\\prod_i H_i)^N be the vector with v_{ij} = f_i for each j \\in \\{ 1, \\dots, N \\}, and let x \\in X^{MN} be the set of all points with x_{ij} = x_j for each i \\in \\{ 1, \\dots, M \\}. Let S_N be the permutation group on N elements. For any \\sigma \\in S_N^M, let x^\\sigma_{ij} = x_{i \\sigma(j)}. Then Tv(x^\\sigma) = Tv(x) for each \\sigma. Each permutation gives rise to a distinct point since the points x_1, \\dots, x_N are distinct. Let S be the set of all x^\\sigma.\nWe give S the uniform probability measure, so that we can consider the Hilbert space L^2(S). We note then that if 1_S \\in L^2(S) is the constant function, then\nL^{MN} \\leq |\\langle Tv, 1_S \\rangle| = |\\langle v ,  T^* 1_S \\rangle| \\leq \\| T^* 1_S \\|_{H_N} = \\langle TT^* 1_S, 1_S \\rangle^{1/2}.\nOne may calculate that\n(TT^* f)(x) = \\sum U(x,y) f(y)\nwhere U(x,y) = \\prod \\langle T_i(x_{ij}), T_i(y_{ij}) \\rangle.\nLemma: 1_S is an eigenfunction of TT^*.\nProof: This follows because \\sum U(x,y) = \\sum U(x^\\sigma, y) for each \\sigma \\in S_N^M, as the two sums are just permutations of one another.\nIf TT^* 1_S = \\Lambda 1_S, then we conclude that L^{MN} \\leq \\Lambda."},"Quick-Notes/The-Polynomial-Wolff-Axioms":{"slug":"Quick-Notes/The-Polynomial-Wolff-Axioms","filePath":"Quick Notes/The Polynomial Wolff Axioms.md","title":"The Polynomial Wolff Axioms","links":["2024-12-HongWangShukunWu-RestrictionEstimatesUsingDecouplingTheoremsAndTwoEndsFurstenbergInequalities.pdf"],"tags":[],"content":"A set of \\delta-tubes \\mathbb{T} satisfy the Polynomial Wolff axioms if, for any semi-algebraic set S,\n\\# \\{ T \\in \\mathbb{T}: |T \\cap S| \\geq \\lambda |T| \\} \\lesssim |S| \\delta^{1-n} \\lambda^{-n} \\tag{1}\nwhere the implicit constants depend only on the complexity of the semi-algebraic set S. Guth, Zahl, Katz, and Rogers proved that a family of tubes pointing in a \\delta-separated family of directions satisfy the Polynomial Wolff Axioms.\nLet us say a tube T is tangent to a \\delta neighborhood S of an algebraic surface \\Sigma if |T \\cap S| \\geq 0.1 |T|. Since |S|  \\lesssim \\delta the Polynomial Wolff Axioms tell us that at most O(\\delta^{2-n}) tubes in \\mathbb{T} are tangent to the surface. If \\mathbb{T} are \\delta separated, we can have \\#(\\mathbb{T}) \\sim \\delta^{1-n}, and so the Polynomial Wolff Axioms tell us most of the tubes in \\mathbb{T} are not tangent to S.\nSuppose \\mathbb{T} contains at most m tubes in each direction. A natural question is to understand how (1) may be quantified in terms of m - this may have applications to restriction theory, e.g. to the methods of Wang and Wu."},"Quick-Notes/The-Refined-Decoupling-Theorem":{"slug":"Quick-Notes/The-Refined-Decoupling-Theorem","filePath":"Quick Notes/The Refined Decoupling Theorem.md","title":"The Refined Decoupling Theorem","links":[],"tags":[],"content":"Suppose p &gt; 2(d+1)/(d-1).\nLet S be a strictly convex, C^2 hypersurface in \\mathbb{R}^d with Gaussian curvature \\sim 1, and consider f: S \\to \\mathbb{C} that can be expanded in a wave-packet decomposition of the form f = \\sum_{T \\in \\mathbb{T}} f_T, where \\mathbb{T} is a family of R-tubes, so that f_T is supported in a radius R^{-1} neighborhood of S, and E_S f_T is essentially supported on T. Assume that the w_R norms of the functions \\{ E_S f_T: T \\in \\mathbb{T} \\} are all comparable (Equivalently, we may assume the norms of the \\{ f_T : T \\in \\mathbb{T} \\} are all comparable). Suppose X \\subset B_R is a union of a family of radius R^{1/2} balls, so that each such ball Q in the union has multiplicity m(Q) = \\# \\{ T \\in \\mathbb{T}: Q \\cap T \\neq \\emptyset \\} at most M. Then\n\\| E_S f \\|_{L^p(X)} \\lessapprox M^{\\frac{2}{n-1}} \\sum\\nolimits_{T \\in \\mathbb{T}} \\| E_S f_T \\|_{L^p(w_R)}^2."},"Quick-Notes/Wang-Wu-Restricted-Decoupling-+-Kakeya-Implies-Restriction":{"slug":"Quick-Notes/Wang-Wu-Restricted-Decoupling-+-Kakeya-Implies-Restriction","filePath":"Quick Notes/Wang-Wu Restricted Decoupling + Kakeya Implies Restriction.md","title":"Wang-Wu Restricted Decoupling + Kakeya Implies Restriction","links":["Quick-Notes/The-Refined-Decoupling-Theorem"],"tags":[],"content":"Recall the The Refined Decoupling Theorem. In this note we discuss how to use this theorem, together with Kakeya type bounds, to prove Restriction Theorems. To begin with, we note that the refined decoupling theorem implies the following bound.\nTheorem: Suppose a family of tubes \\mathbb{T} can be divided into families of tubes \\mathbb{T}_\\theta which are R^{-1/2} direction separated, and \\#(\\mathbb{T}_\\theta) \\leq m for each \\theta. Then if X is a union of R^{1/2} balls, so that m(Q) \\leq M for each Q \\subset X, then\n\\| E_S f \\|_{L^p(X)} \\lessapprox R^{\\frac{n}{p} - \\frac{n-1}{2}} M^{\\frac{1}{p} \\frac{2}{n-1}} m^{1/p - 1/2} \\| f \\|_{L^p(M)}.\nProof: Applying the The Refined Decoupling Theorem, we find that\n\\| E_S f \\|_{L^p(X)}^p \\lessapprox M^{\\frac{2}{n-1}} \\sum\\nolimits_{T \\in \\mathbb{T}} \\| E_S f_T \\|_{L^p(w_R)}^p.\nNow \\| E_S f_T \\|_{L^p(w_R)}^p \\sim R^{ \\frac{p - p_{ST}}{2 - p_{ST}} } \\| f_T \\|_{L^2(M)}^p for each T \\in \\mathbb{T}, so\n\\sum\\nolimits_{T \\in \\mathbb{T}} \\| E_S f_T \\|_{L^p(w_R)}^p \\sim R^{\\frac{p - p_{ST}}{2 - p_{ST}}} \\sum\\nolimits_{T \\in \\mathbb{T}} \\| f_T \\|_{L^2(M)}^p.\nSince all the norms \\| f_T \\|_{L^2(M)} are all comparable, we have that for each \\theta,\n\\sum\\nolimits_{T \\in \\mathbb{T}_\\theta} \\| f_T \\|_{L^2(M)}^p \\sim m^{1 - p/2} \\left( \\sum\\nolimits_{T \\in \\mathbb{T}_\\theta} \\| f_T \\|_{L^2(M)}^2 \\right)^{p/2} \\sim m^{1 - p/2} \\| f_\\theta \\|_{L^2(M)}^p.\nBy H”{o}lder’s inequality, since f_\\theta is supported on a R^{-1/2} cap, we have\n\\| f_\\theta \\|_{L^2(M)}^p \\lesssim R^{- \\left( \\frac{n-1}{2} \\right) (p/2 - 1)} \\| f_\\theta \\|_{L^p(M)}^p.\nCombining these bounds gives that\n    \\| E_S f \\|_{L^p(X)}^p &amp;\\lessapprox M^{\\frac{2}{n-1}} m^{1 - p/2} R^{\\frac{p - p_{ST}}{2 - p_{ST}} - \\left( \\frac{n-1}{2} \\right) (p/2 - 1) } \\| f \\|_{L^p(M)}^p\\\\\n    &amp;= R^{n - \\left( \\frac{n-1}{2} \\right) p} M^{\\frac{2}{n-1}} m^{1 - p/2} \\| f \\|_{L^p(M)}^p.\n\\end{align}$$\n\nSo, if we can show a potential counterexample to a restriction bound is concentrated on a set $X$ upon which $M^{\\frac{2}{n-1}} m^{1 - p/2} \\lessapprox R^{ \\left( \\frac{n-1}{2} \\right) p - n }$, then we will have obtained a contradiction, thus proving the restriction bound. □\n\n*In particular, if $p = p_{ST}$ then the bound becomes*\n\n| E_S f |{L^{p{ST}}(X)} \\lesssim R^{-1/p_{ST}} (M/m)^{\\frac{1}{n+1}} | f |_{L^p(M)},\n*which will be important in a later calculation.*\n\nFor a given family of tubes $\\mathbb{T}$, controlling $M$ and $m$ simultaneously is a Kakeya type problem. If we consider a set $X$ formed from the union of $R^{1/2}$ tubes, such that $|X \\cap T| \\sim \\lambda |T|$ for each $T \\in \\mathbb{T}$, then the full Kakeya maximal conjecture implies the multiplicity of a generic $\\delta$-cube in $X$ is $O(m \\lambda^{1-n})$. So given a set $X$, after thinning $X$ appropriately we can set $M \\lesssim m \\lambda^{1-n}$ in the result above.\n\nLet us try and use this technique to obtain an extension bound. Assume that $\\| f \\|_{L^p(M)} = 1$. Consider a wave packet decomposition $f = \\sum f_{\\theta,\\nu}$ at a scale $R^{-1/2}$, and thus $E_S f = \\sum_{T \\in \\mathbb{T}} g_T$, where $T = \\{ T_{\\theta,\\nu}: f_{\\theta,\\nu} \\neq 0 \\}$. By pigeonholing, we may assume that there is $B &gt; 0$ so that $\\| f_{\\theta,\\nu} \\|_{L^\\infty(M)} \\sim B$ for all $T \\in \\mathbb{T}$. Let $X$ be a set, which we may assume to be $R^{1/2}$ discretized, we try and find $X_0 \\subset X$ with $|X_0| \\geq |X|/10$ so that $\\| E_S f \\|_{L^p(X_0)} \\lesssim 1$. We may assume $X$ is $R^{1/2}$ discretized, and by dyadic pigeonholing, we may find a dyadic scale $\\lambda$ so that $X(T) = X \\cap T$ satisfies $|X(T)| \\sim \\lambda |T|$ for some $\\lambda \\in [0,1]$ and all $T \\in \\mathbb{T}$. Because the functions $\\{ g_T \\}$ are orthogonal on $R^{1/2}$ cubes, they are also orthogonal on $X$, so\n\n| E_S f |{L^2(X)} \\lesssim \\left( \\sum | g_T |{L^2(X)}^2 \\right)^{1/2} \\sim (\\lambda R)^{1/2} \\left( \\sum | f_{\\theta,\\nu} |{L^2(M)}^2 \\right)^{1/2} = (\\lambda R)^{1/2} | f |{L^2(M)}.\n\nOn the other hand, if $p_{ST}$ is the Stein-Tomas exponent, we can find a set $X_0 \\subset X$ with $|X_0| \\geq |X|/10$ so that $M \\lesssim m \\lambda^{-(n-1)}$. If we could somehow improve this bound so we could assume $M \\lesssim m \\lambda^{- \\frac{n-1}{2}}$, then\n\n\\begin{align}\n| E_S f |{L^{p{ST}}(X_0)} &amp;\\lessapprox (M/m)^{ \\frac{1}{n+1}} R^{-\\frac{n-1}{2(n+1)}} | f |{L^{p{ST}}(X_0)}\\\n&amp;\\lessapprox (\\lambda R)^{- 1/p_{ST}} | f |{L^{p{ST}}(X_0)}\n\\end{align}\n\nInterpolating, we obtain that at the critical exponent for the restriction conjecture, i.e. for $p = 2n/(n-1)$,\n\n| E_S f |{L^p(X_0)} \\lesssim | f |{L^p(X_0)}.\n\nThis is sufficient to completely prove the restriction conjecture.\n\nIn general, we will be able to obtain square root cancellation in $\\lambda$ by forcing $X$ to satisfy a two-ends condition, and we can then use this to obtain restriction estimates. Given a set $X$ satisfying the two-ends condition, with $|X \\cap T| \\sim \\lambda |T|$ for each $T \\in \\mathbb{T}$, the bush argument of Bourgain gives that $|X| \\gtrapprox R^{\\frac{3n+1}{4}} \\lambda$, and so the average multiplicity of a cube $Q$ in $X$ is $M \\lesssim m \\lambda^{- \\frac{n-1}{n+1}} R^{-\\frac{(n-1)^2}{4(n+1)}} \\lambda^{-\\frac{n-1}{n+1}}$, which gives\n\n| E_S f |{L^{p{ST}}(X_0)} \\lessapprox R^{-\\frac{(n-1)[3n+1]}{4(n+1)^2}} \\lambda^{- \\frac{n-1}{(n+1)^2}} | f |{L^{p{ST}}}\n\nInterpolation between the $L^2$ estimate gives a result of the form\n\n| E_S f |{L^p(X_0)} \\lessapprox | f |{L^p(X_0)}\n\nfor $p = \\frac{2 + 2n(5n + 2)}{(n-1)(5n + 3)}$. In particular, for $n = 3$ this gives $p = 26/9 \\approx 2.89$."},"Quick-Notes/Wave-Packet-Decomposition-For-Extension":{"slug":"Quick-Notes/Wave-Packet-Decomposition-For-Extension","filePath":"Quick Notes/Wave Packet Decomposition For Extension.md","title":"Wave Packet Decomposition For Extension","links":["1991---Bourgain---Besicovitch-Type-Multiplier-Operators-And-Applications-To-Fourier-Analysis","1969---Fefferman---Inequalities-For-Strongly-Singular-Convolution-Operators","1982---Cordoba---Geometric-Fourier-Analysis","1991---Seeger-Sogge-Stein---Regularity-Properties-of-Fourier-Integral-Operators"],"tags":[],"content":"Given any function f supported on a compact neighborhood of a curved hypersurface \\Sigma, and each R &gt; 0, we can break \\Sigma down finitely overlapping caps \\Theta, each having dimensions R^{-1/2} tangent to \\Sigma, and dimension R^{-1} in the normal direction to \\Sigma. If, for each \\theta \\in \\Theta, we consider a family of tubes \\mathbb{T}(\\theta) pointing in the normal direction to the cap, with dimensions R^{1/2} by R, and then write \\mathbb{T} = \\bigcup \\mathbb{T}(\\theta), then we have an orthogonal decomposition f = \\sum f_T, where for T \\in \\mathbb{T}(\\theta) the following is true:\n\nf_T is supported on \\theta.\nFor x \\in B_R, E_\\Sigma f_T(x) \\approx a_T \\chi_T e^{2 \\pi i \\omega_\\theta x}, where \\omega_\\theta is the center of \\theta, |a_T| \\sim R^{-1/2} \\| f_T \\|_{L^2(\\Sigma)}., and \\chi_T is smooth and adapted to T. In particular, \\| E_\\Sigma f_T \\|_{L^2(B_R)} \\sim R^{1/2} \\| f_T \\|_{L^2(\\Sigma)}.\nThe functions E f_T are locally orthogonal on balls of radius R^{1/2}. That is, for any ball B of radius at least R^{1/2}, \\| Ef \\|_{L^2(B)} \\approx \\sum \\| Ef_T \\|_{L^2(B)}^2.\n\nThe method was widely brought to the attention by Bourgain’s use of the result in a 1991 paper (some claim he introduced the method, though it is also in use by Fefferman and Cordoba in their work on the restriction problem), and is highly similar to the second dyadic decomposition introduced in 1991 by Seeger, Sogge and Stein to analyze Fourier Integral Operators."},"Quick-Notes/We-Can-Remove-Exceptional-Sets-From-Lp-Estimates":{"slug":"Quick-Notes/We-Can-Remove-Exceptional-Sets-From-Lp-Estimates","filePath":"Quick Notes/We Can Remove Exceptional Sets From Lp Estimates.md","title":"We Can Remove Exceptional Sets From Lp Estimates","links":[],"tags":[],"content":"Suppose X_0 has finite measure, and we have to prove an inequality of the form\n\\| f \\|_{L^p(X_0)} \\lesssim C. \\tag{1}\nEquation (1) is almost equivalent to proving that for any subset X of X_0, there exists E \\subset X with |E \\cap X| \\leq 1/2 so that\n\\| f \\|_{L^p(X - E)} \\lesssim C |X|^{1/p&#039;}. \\tag{2}\nCertainly (1) implies (2) by Hölder’s inequality. Conversely, if (2) holds, then we may find E_1 so that if X_1 = X_0 - E_1, then\n\\| f \\|_{L^p(X_1)} \\lesssim C |X|^{1/p&#039;}. \\tag{3}\nIterating, for each n \\geq 1, we can apply (2) with X = X_n to find E_n \\subset X_n so that if X_{n+1} = X_n - E_n,\n\\| f \\|_{L^p(X_{n+1})} \\lesssim C |X_n|^{1/p} \\lesssim 2^{-n/p} C |X_0|^{1/p&#039;}. \\tag{4}\nApplying the triangle inequality, since X - \\bigcup X_n is measure zero, we find\n\\| f \\|_{L^p(X)} \\leq \\sum_n \\| f \\|_{L^p(X_n)} \\lesssim \\sum 2^{-n/p} C |X_0|^{1/p&#039;} \\lesssim C |X_0|^{1/p&#039;}. \\tag{5}"},"index":{"slug":"index","filePath":"index.md","title":"Multilinear Restriction","links":[],"tags":[],"content":"These are some quick notes taken to summarize progress on obtaining new estimates for multilinear restriction, potentially using the methods of Wang and Wu."}}