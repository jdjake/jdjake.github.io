{"Problems/Generalization-of-Decoupling-and-Restricted-Decoupling":{"slug":"Problems/Generalization-of-Decoupling-and-Restricted-Decoupling","filePath":"Problems/Generalization of Decoupling and Restricted Decoupling.md","title":"Generalization of Decoupling and Restricted Decoupling","links":[],"tags":[],"content":"During a talk, Tony Carbery proposed the following result, which generalizes decoupling and restricted decoupling. It states that\n\\int_{B_R} |Eg|^2 w \\lessapprox \\sum\\nolimits_\\nu \\sum\\nolimits_{T \\perp S_\\nu} \\| g_T \\|_{L^2}^2 w_T^\\nu,\nwhere w_T^\\nu = w^{\\frac{n+1}{2}}(T)^{\\frac{2}{n+1}}."},"Problems/The-Kakeya-Maximal-Inequality":{"slug":"Problems/The-Kakeya-Maximal-Inequality","filePath":"Problems/The Kakeya Maximal Inequality.md","title":"The Kakeya Maximal Inequality","links":[],"tags":[],"content":"The Kakeya maximal conjecture states that for a family \\mathbb{T} of \\delta-tubes which are direction separated, then for 0 \\leq d \\leq n,\n \\left\\| \\sum 1_T \\right\\|_{L^{\\frac{d}{d-1}}(\\mathbb{R}^n)} \\lessapprox \\delta^{1-n/d}."},"Problems/The-Multilinear-Restriction-Conjecture":{"slug":"Problems/The-Multilinear-Restriction-Conjecture","filePath":"Problems/The Multilinear Restriction Conjecture.md","title":"The Multilinear Restriction Conjecture","links":["2003---Tao---A-Sharp-Bilinear-Restriction-Estimate-for-Paraboloids-1","2006-BennettCarberyTao-OnTheMultilinearRestrictionAndKakeyaConjectures","Harmonic-Analysis/Multilinear-Methods-in-Restriction-Theory/2022---Bejenaru---The-Almost-Optimal-Multilinear-Restriction-Estimate-For-Hypersurfaces-With-Curvature","2011---Bourgain-Guth---Bounds-on-Oscillatory-Integrals-Using-Multilinear-Estimates","Harmonic-Analysis/Polynomial-Methods-in-Restriction-Theory/2018---Guth---Restriction-Estimates-Using-Polynomial-Partitioning-2","2006---Bennett-Carbery-Tao---On-The-Multilinear-Restriction-And-Kakeya-Conjectures"],"tags":[],"content":"The restriction conjecture states that for 2d/(d-1) &lt; q &lt; \\infty and  1 - \\left( \\frac{d+1}{d-1} \\right) (1/q) \\geq 1/p,\n\\| Ef \\|_{L^q(\\mathbb{R}^d)} \\lesssim \\| f \\|_{L^p(\\Sigma)}.\nThe multilinear restriction conjectures says that for 2 \\leq k \\leq n, if f_1,\\dots,f_k are restricted to transverse subsets of \\Sigma, then for q &gt; 2(d+k)/(d+k-2),\n\\left\\| \\prod\\nolimits_j |Ef_j|^{1/k} \\right\\|_{L^q(B_R)} \\lessapprox \\prod\\nolimits_j \\| f_j \\|_{L^2(\\Sigma)}.\n\nThe case k = 1 is essentially the Stein-Tomas theorem.\nThe conjecture has been proved for k = 2 by Tao.\nThe conjecture has been proved for k = n by Bennett, Carbery, and Tao.\nThe conjecture has been proved for k = n-1 by Bejenaru.\n\nThe methods of Bourgain and Guth show that multilinear estimates for the restriction conjecture imply some restriction estimates. In particular, if the multilinear restriction conjecture was established, then it would imply the results of Guth, who was able to get around using multilinear estimates by using the broad norms.\n\nApparently, the methods of Bennett, Carbery, and Tao imply the result is true for p &gt; 2/(k-1).\nJennifer Duncan has claimed in talks to prove the result for p &gt; 2(k+1)/k.\n"},"Quick-Notes/Broad-Narrow-Analysis":{"slug":"Quick-Notes/Broad-Narrow-Analysis","filePath":"Quick Notes/Broad-Narrow Analysis.md","title":"Broad-Narrow Analysis","links":["2015---Guth---A-Restriction-Estimate-Using-Polynomial-Partitioning","1998---Tao-Vargas-Vega---A-Bilinear-ApproachT-to-the-Restriction-and-Kakeya-Conjectures"],"tags":[],"content":"We aim to obtain a bound\n\\| Ef \\|_{L^p(B_R)} \\lessapprox \\| f \\|_{L^p(\\Sigma)}\nby using multilinear restriction estimates and decoupling estimates.\nFix K &gt; 0, and cover B_R by balls B of radius K. Similarly, decompose \\Sigma into a family \\Theta of caps \\theta of diameter 1/K. For each cap \\theta, we let n(\\theta) denote the normal vector to \\Sigma at the center of the cap. Also note that \\#(\\Theta) = K^{O(1)}.\nFor each ball B, let S(B) be the set of all \\theta \\in \\Theta so that\n\\| Ef_\\theta \\|_{L^p(B)} \\gg \\frac{\\| Ef \\|_{L^p(B)}}{\\#(\\Theta)}.\nThen\n\\| Ef \\|_{L^p(B)} = \\left\\| \\sum\\nolimits_{\\theta \\in S(B)} Ef_\\theta \\right\\|_{L^p(B)}. \nFix k \\in \\{ 2, \\dots, d \\}. We say a ball B is k-narrow if there exists a k-1 dimensional plane H in \\mathbb{R}^d so that the set of vectors \\{ n(\\theta): \\theta \\in S(B) \\} all make an angle at most 1/K with H. Otherwise, call the ball B a k-broad ball.\nIf B is a broad ball, then there exists k caps \\theta_1, \\dots, \\theta_k in S(B) so that\n|n(\\theta_1) \\wedge \\cdots \\wedge n(\\theta_k)| \\geq 1/K.\nIt then follows from a translation trick, Tacy’s theorem (we likely have to make another assumption on the caps so they don’t lie in a non-curved subspace), and a wave packet decomposition of each E f_{\\theta_j} into tubes T_j that\n\\| Ef \\|_{L^p(B)} \\leq K^{O(1)} \\left( \\prod\\nolimits_j \\left\\| \\sum\\nolimits_{\\nu_j \\in S(B,\\theta_j)} f_{\\theta_j,\\nu_j} \\right\\|_{L^2(\\Sigma)} \\right)^{1/k} \\leq K^{O(1)} \\max\\nolimits_j \\left\\| \\sum\\nolimits_{\\nu_j \\in S(B,\\theta_j)} f_{\\theta_j,\\nu_j} \\right\\|_{L^2(\\Sigma)}.\nSince each \\nu_j is in S(B,\\theta_j) for at most K^{O(1)} different balls B, L^2 orthogonality of tubes implies that\n\\| Ef \\|_{L^p(\\text{Broad})} \\leq K^{O(1)} \\| f \\|_{L^2(\\Sigma)} \\leq K^{O(1)} \\| f \\|_{L^p(\\Sigma)}.\nNow we deal with the narrow case using decoupling inequalities. Suppose that B is a narrow ball, and S(B) is such that we have a decoupling inequality\n\\| Ef \\|_{L^p(B)} \\lesssim K^{O(1)} \\left( \\sum \\| Ef_\\theta \\|_{L^p(B)}^2 \\right)^{1/2}.\nSumming over all narrow balls B using the finite overlap property, we obtain that\n\\| Ef \\|_{L^p(\\text{Narrow})} \\lesssim K^{O(1)} \\left( \\sum \\| Ef_\\theta \\|_{L^p(B_R)}^2 \\right)^{1/2}.\nWe now bound each term \\| Ef_\\theta \\|_{L^p(B_R)} using induction on scales. Namely, we can find a function g_\\theta on \\Sigma for each \\theta so that \\| g \\|_{L^p(\\Sigma)} = K^{\\frac{d-1}{p}} \\| f_\\theta \\|_{L^p(\\Sigma)} and \\| Ef_\\tau \\|_{L^p(B_R)} \\lesssim K^{\\frac{d+1}{p} - (d-1)} \\| Eg \\|_{L^p(B_{R/K})}. Applying induction on scales, letting C(R) be the best constant in the extension inequality on B_R, we find that\n\\| Ef \\|_{L^p(\\text{Narrow})} \\lesssim K^{\\frac{2d}{p} - (d-1)} C(R/K).\nPutting together the analysis of the broad and narrow cases, we find that\nC(R) \\lesssim K^{O(1)} + C K^{\\frac{2d}{p} - (d-1)} C(R/K).\nSince p &gt; 2d(d-1), for all \\varepsilon &gt; 0, if we choose K = R^\\delta for \\delta sufficiently small, depending on \\varepsilon, we conclude that C(R) \\lesssim_\\varepsilon R^\\varepsilon.\nWe likely can use decoupling in the right range provided that the k-1 dimensional hypersurface on which the caps are concentrated is appropriately curved. The amount of curvature required is not completely apparent I need to ask Jonathan what the range of decoupling estimates are known in the case that we have degenerate hyper-surfaces.\nGuth Polynomial Partitioning Broad Narrow Argument\nFix K &gt; 0, and divide a hypersurface \\Sigma in \\mathbb{R}^d into caps \\tau of diameter O(K^{-1}). Given a function f on \\Sigma, let g = Ef. Then a point x \\in \\mathbb{R}^d is \\alpha broad if \\max |Ef_\\tau(x)| \\leq \\alpha |Ef(x)|. If a point is not \\alpha broad, then it is \\alpha narrow, which means there is some \\tau_0 with |Ef(x)| \\leq \\alpha^{-1} |Ef_{\\tau_0}(x)|. This gives a smaller scale which can bound the current scale of analysis, so induction on scales often allows us to bound the behavior of the extension operator at narrow points, and we may thus restrict our attention to the behavior at broad points.\nMore precisely, if we define \\text{Br}_\\alpha(g) to be equal to g at broad points, and equal to zero at narrow points, then we have a pointwise bound\n |g| \\leq |\\text{Br}_\\alpha(g)| + \\alpha^{-1} \\max\\nolimits_{\\tau_0} |Ef_{\\tau_0}|\nInduction on scales bounds |Ef_{\\tau_0}| uniformly, so it suffices to estimate |\\text{Br}_\\alpha(g)|. The advantage of reducing to the broad case is that one can often reduce to multilinear estimates, given that the caps \\{ \\tau_0 \\} are suitably transverse to one another.\nIn more sophisticated contexts, it is useful to be more quantitative, especially when considering estimates closer to k-linear analysis. We define a measure \\mu = \\mu_a^p, locally constant at a scale K^2, so that for a  ball of radius K^2,\n \\mu^p(f,B) = \\min\\nolimits_{V_1,\\dots,V_a} \\max\\nolimits_{\\tau \\in \\text{Tr}(V_1,\\dots,V_a)} \\int_B |Ef_\\tau|^p\nwhere V_1,\\dots,V_a are k-dimensional subspaces, and \\text{Tr}(V_1,\\dots,V_A) is the set of caps transverse to all V_1,\\dots,V_a, more precisely, making an angle greater than 1/K with each subspace. We then define, for a set U constant at a scale K^2,\n \\| Ef \\|_{\\text{BL}_{k,a}^p(U)} = \\left( \\sum\\nolimits_{B \\subset U} \\mu^p(f,B) \\right)^{1/p}\nThe need to choose a &gt; 1 is required so that the broad norm is semi-additive and satisfies the Holder inequality. We often choose a \\sim 1. On a particular ball of radius K^2, we are only bounding those \\| Ef_{\\tau_0} \\|_{L^p(B)} for which there exists \\tau_1,\\dots,\\tau_{k-1} with \\tau_0 \\wedge \\cdots \\wedge \\tau_{k-1} \\gtrsim 1 and \\| Ef_{\\tau_i} \\|_{L^p(B)} \\gtrsim \\| Ef_\\tau \\|_{L^p(B)}. The most useful property of the broad norm is that if we are only studying tubes that are tangent to a k-1 dimensional variety, then the broad norm of Ef is essentially zero (for whenever the tubes intersect, they do so in a way that is not k transverse).\nWhen estimating the broad norm rather than the usual L^p norm, tubes that are concentrated on k-1 dimensional varieties are\nIn the multilinear case, what gets thrown out?\n\nGuth uses the method to prove his L^\\infty(\\Sigma) \\to L^p(\\mathbb{R}^3) restriction estimate for p &gt; 3.25.\nGuth states that his broad narrow analysis is similar to the bilinear restriction methods of Tao, Vargas, and Vega, but I have not looked into this paper.\n"},"Quick-Notes/Calculations-With-The-Shape-Operator":{"slug":"Quick-Notes/Calculations-With-The-Shape-Operator","filePath":"Quick Notes/Calculations With The Shape Operator.md","title":"Calculations With The Shape Operator","links":[],"tags":[],"content":"Let \\Sigma be an orientable surface in \\mathbb{R}^d. Then we can define a vector field n: \\Sigma \\to S^{d-1}. The differential of n at a point p \\in \\Sigma then gives a linear map from T_p \\Sigma to T_{n(p)} \\Sigma, and since T_{n(p)} \\Sigma can be naturally identified with T_p \\Sigma, we obtain a linear operator S_p on T_p \\Sigma, self-adjoint with respect to the inner product on T_p \\Sigma called the shape operator.\nUsing the Riemannian metric on \\Sigma, since S_p is a linear map on T_p \\Sigma, which can be viewed as a (1,1) tensor, we can identify S_p with a 2-tensor \\text{II}^p on T_p \\Sigma, called the shape tensor, or second fundamental form. This identification is precisely the identification such that, if we view \\text{II}^p as a bilinear form on T_p \\Sigma, then\n\\text{II}^p(v,w) = (S_pv) \\cdot w.\nThe advantage of switching to the second fundamental form is that the expressions for \\text{II}^p are much simpler in coordinates than S_p. Indeed, consider a coordinate chart \\alpha: \\Sigma \\to \\mathbb{R}^n for \\Sigma, where d = n + 1. Then \\partial_{\\alpha^1}, \\dots, \\partial_{\\alpha^n} forms a basis for T_p \\Sigma. Thus we can write\n\\text{II}^p = \\sum \\text{II}^p_{ij} d\\alpha^i d\\alpha^j,\nwhere\n\\text{II}^p_{ij} = (S_p \\partial_{\\alpha^i}) \\cdot \\partial_{\\alpha^j} = \\frac{\\partial n}{\\partial \\alpha^i} \\cdot \\partial_{\\alpha^j}.\nThe expression for S_p is more complicated in coordinates. Namely, we must consider the metric g on \\Sigma in coordinates, writing g = \\sum g_{ij} d\\alpha^i d\\alpha^j. Then we must invert the metric, i.e. letting g^{ij} denote the entries of the inverse matrix to g_{ij}. Then\nS_p v = \\sum_{i,j,k} \\left( \\frac{\\partial n}{\\partial \\alpha^j} \\cdot v \\right) g^{ij} \\partial_{\\alpha^i}.\nThe presence of the inverse metric coefficients make things more complicated to calculate.\nWe now work with the shape operator on the special case of a hyperbolic paraboloid of the form\n\\Sigma = \\{ z = |x|^2 - |y|^2 \\}.\nWe will work in the coordinate chart (\\alpha,\\beta) on \\Sigma given by \\alpha^i = x^i and \\beta^j = y^j (i.e. the coordinate chart just projects down into the x and y variables).\nComputing the Second Fundamental Form\nWe calculate directly from the definition of the coordinates \\alpha and \\beta that\n\\partial_{\\alpha^i} = \\partial_{x^i} + 2x^i \\partial_z\nand\n\\partial_{\\beta^j} = \\partial_{y^j} - 2y^j \\partial_z.\nIn coordinates, at a point p with coordinates \\alpha and \\beta, the unit normal vector n_p takes the form\nn_p = (1/r) (2 \\alpha \\cdot \\partial_x - 2 \\beta \\cdot \\partial_y - \\partial_z),\nwhere r = \\sqrt{4|\\alpha|^2 + 4|\\beta|^2 + 1}. Then we find that, working modulo n_p (which will not effect inner products with \\partial_{\\alpha^i} and \\partial_{\\beta^j} because n_p is orthogonal to this vector),\nn_*(\\partial_{\\alpha^i}) = \\frac{\\partial n}{\\partial \\alpha^i} = (2/r) \\partial_{x^i} + \\mathbb{R} n_p\nand\nn_*(\\partial_{\\beta^j}) = \\frac{\\partial n}{\\partial \\beta^j} = (-2/r) \\partial_{y^j} + \\mathbb{R} n_p.\nSo we can calculate directly that\n\\text{II}^p = (2/r) [d\\alpha^2 - d\\beta^2],\ni.e. so given two tangent vectors v = a_1 \\cdot \\partial_\\alpha + b_1 \\cdot \\partial_\\beta and w = a_2 \\cdot \\partial_\\alpha + b_2 \\cdot \\partial_\\beta in T_p \\Sigma,\nS_p v \\cdot w = (2/r)(a_1 \\cdot a_2 - b_1 \\cdot b_2).\nThe Metric in Coordinates\nThe metric g = dx^2 + dy^2 + dz^2 on \\Sigma can also be expressed in the coordinates on \\Sigma. Namely, we can write the metric as\nA^{ij} d\\alpha^i d\\alpha^j + B^{ij} d\\alpha^i d \\beta^j + C^{ij} d\\beta^i d\\beta^j.\nwhere\nA^{ij} = \\partial_{\\alpha^i} \\cdot \\partial_{\\alpha^j}, \\quad B^{ij} = \\partial_{\\alpha^i} \\cdot \\partial_{\\beta^j},\\quad\\text{and}\\quad C^{ij} = \\partial_{\\beta^i} \\cdot \\partial_{\\beta^j}.\nUsing the calculations of these tangent vectors above, we see that A^{ij} = \\delta^{ij} + 4 \\alpha^i \\alpha^j, B^{ij} = -4 \\alpha^i \\beta^j, and C^{ij} = \\delta^{ij} + 4 \\beta^i \\beta^j.\nWedge Products of Normals With The Shape Operator\nNow consider two points p, and q_1,\\dots,q_k. The curvature condition of Bejanaru states that for unit normal vectors \\{ n_p, n_{q_1}, \\dots, n_{q_k} \\} to caps, if we define V = \\text{span}(n_p, n_{q_1}, \\dots, n_{q_k} ), then the linear operator \\pi_{V^\\perp} \\circ S_p|_{V^\\perp} is invertible, where \\pi_{V^\\perp} is the orthogonal projection onto V^\\perp.\nThis condition fails precisely when there exists a unit vector v in T_p \\Sigma orthogonal to \\{ n_p, n_{q_1}, \\dots, n_{q_k} \\}, with the property that S_pv is in the span of the unit normal vectors \\{ n_p, n_{q_1}, \\dots, n_{q_k} \\}. This would imply that S_p v \\cdot v = 0 since v is orthogonal to the unit normal vectors. Thus v lies in the set B = \\{ a \\cdot \\partial_\\alpha + b \\cdot \\partial_\\beta : |a| = |b| \\}, which is precisely the family of vectors such that S_p v \\cdot v = 0, because if v = a \\cdot \\partial_\\alpha + b \\cdot \\partial_\\beta then S_p v \\cdot v = |a|^2 - |b|^2. In particular, we see that the curvature condition fails for a family of normal vectors V = \\{ n_p, n_{q_1}, \\dots, n_{q_k} \\} whenever V^\\perp contains a vector v \\in B such that S_p v \\in V.\nBarron’s Condition on Curvature\nConversely, Barron’s condition fails for two points p and q with coordinates (\\alpha_1,\\beta_1) and (\\alpha_2,\\beta_2) whenever (\\alpha_1 - \\alpha_2) \\cdot \\partial_\\alpha + (\\beta_1 - \\beta_2) \\partial_\\beta \\in B. We claim this condition is, in the bilinear case, entirely equivalent to Bejenaru’s condition. In the bilinear case, using the notation of Bejenaru’s condition above, V^\\perp \\cap T_p \\Sigma is a line spanned by the orthogonal projection \\pi_p(n_q) of n_q onto T_p \\Sigma. Since S_p is invertible (this follows by observing that \\text{II}^p is always a non-degenerate bilinear form), it follows that Bejanaru’s condition reduces to observing when S_p^{-1}(\\pi_p(n_q)) \\in B. The following proposition thus shows that Barron and Bejenaru’s conditions are equivalent.\nProposition: Fix p,q \\in \\Sigma. Then S_p^{-1}(\\pi_p(n_q)) is a constant multiple of (\\alpha_1 - \\alpha_2) \\cdot \\partial_\\alpha + (\\beta_1 - \\beta_2) \\partial_\\beta.\nProof: The proposition is invariant under isometries. So we may assume without loss of generality that \\alpha_1 = (t,0,\\cdots,0) and that \\beta_1 = 0, for some t \\in \\mathbb{R}.\nWrite \\alpha = (\\lambda, \\gamma), where \\lambda \\in \\mathbb{R} and \\gamma \\in \\mathbb{R}^{k-1}. Under the reduction above, the metric of \\Sigma at p is given by\ng_p = (1 + 4t^2) d\\lambda^2 + d\\gamma^2 + d\\beta^2\nIt thus follows from our formula for \\text{II}^p that\nS_p( a \\partial_\\lambda + b \\cdot \\partial_\\gamma + c \\cdot \\partial_\\beta ) = \\frac{a}{1 + 4t^2} \\partial_\\lambda + b \\cdot \\partial_\\gamma - c \\cdot \\partial_\\beta\nRecalling that q has coordinates (\\alpha_2,\\beta_2) = (\\lambda_2,\\gamma_2,\\beta)), the orthogonal projection of  onto  is given by a constant multiple of\n\\left( \\frac{\\lambda_2 - t}{1 + 4t^2} \\right) \\partial_\\lambda + \\gamma_2 \\cdot \\partial_\\gamma - \\beta_2 \\cdot \\partial_\\beta.\nApplying S_p^{-1} to this vector, we obtain the vector\n\\left( \\lambda_2 - t \\right) \\partial_\\lambda + \\gamma_2 \\cdot \\partial_\\gamma - \\beta_2 \\cdot \\partial_\\beta.\nBut now we see that the proof is completed. □\nA Possible Line of Attack\nOne option that may help us is to consider whether the multilinear restriction theorem holds, under a weaker range of p, under weaker curvature assumptions on the linear operator \\pi_{V^\\perp} \\circ S_p|_{V^\\perp}, i.e. that it has rank at least l for some fixed l \\leq n-k. Since Tacy’s argument only requires Stein-Tomas L^2 estimates interpolated with transversality estimates, it may be possible to adapt her argument to this more general situation. This may possibility cut down the number of ‘bad caps’ to consider, which may result in better numerology when considering the relevant induction on scales."},"Quick-Notes/Induction-on-Scales":{"slug":"Quick-Notes/Induction-on-Scales","filePath":"Quick Notes/Induction on Scales.md","title":"Induction on Scales","links":["2006---Bennett-Carbery-Tao---On-The-Multilinear-Restriction-And-Kakeya-Conjectures","1998---Tao-Vargas-Vega---A-Bilinear-Approach-to-the-Restriction-and-Kakeya-Conjectures"],"tags":[],"content":"Suppose C(R) is a finite quantity chosen for each integer R &gt; 0, such that, by some (hopefully trivial) argument, we can justify C(R) = R^{O(1)}. The goal of induction on scales is, by bounding C(R) in terms of C(R&#039;) for a small R&#039;, to obtain a bound C(R) \\lesssim_\\varepsilon R^\\varepsilon for all \\varepsilon &gt; 0. We write A \\lessapprox B if A \\lesssim_\\varepsilon R^\\varepsilon B for all \\varepsilon &gt; 0.\n\nIf C(R) \\lessapprox C(R^\\alpha) for some 0 &lt; \\alpha &lt; 1 and all \\varepsilon &gt; 0, and we know that C(R) \\lesssim R^{O(1)}, then induction on scales can guarantee that C(R) \\lessapprox 1. This is used, for instance in the Bennett Carbery Tao Multilinear Restriction Theorem.\nIf C(R) \\lessapprox C(R^{1 - \\delta}) + R^{O(\\delta)} for all \\delta &gt; 0, then C(R) \\lessapprox 1. This is used, for instance, in Tao Vargas Vega.\nIf C(R) \\lesssim_\\varepsilon (1 + \\varepsilon) C(R/10) then we obtain that C(R) \\lessapprox 1.\n"},"Quick-Notes/Polynomial-Partitioning":{"slug":"Quick-Notes/Polynomial-Partitioning","filePath":"Quick Notes/Polynomial Partitioning.md","title":"Polynomial Partitioning","links":["2015---Guth-Katz---On-The-Erdos-Distinct-Distances-Problem-in-the-Plane","2008---Dvir---On-the-Size-of-Kakeya-Sets-in-Finite-Fields","1990---Clarkson-Edelsbrunner-Guibas-Sharir-Welzl---Combinatorial-Complexity-Bounds-for-Arrangements-of-Curves-and-Spheres"],"tags":[],"content":"The idea of polynomial partitioning, introduced by Guth and Katz in their 2015 Paper on the Erdos distinct distances problem, is to combine the polynomial incidence geometric methods of Dvir with the divide and conquer approaches of divide and conquer partitioning approach introduced by CEGSW in incidence geometry.\nGiven a set X \\subset \\mathbb{R}^d of N points, the polynomial method allows us to find a polynomial of degree O(N^{1/d}) vanishing on X. In polynomial partitioning, for any D, we can choose a polynomial of degree D defining a hypersurface Z, such that \\mathbb{R}^d - Z is divided into O(D^d) cells, each containing O(N/D^d) points from X. The surface Z is called the cell wall, and the connected components of \\mathbb{R}^d - Z are called the cells. The problem then breaks down into two regimes:\n\nIf X contains few points in the cell wall, it must be evenly divided into each of the cells, so methods akin to  CEGSW apply.\nIf X contains many points in the cell wall, then we obtain structural information akin to Dvir’s Method.\n\nThe problem can also be applied to continuous problems. If f is a function on \\mathbb{R}^d, then for any D we can find a hypersurface Z defined by a polynomial of degree D so that the L^1 norm of f on each cell cut out by the surface Z is the same. However, to fully exploit the polynomial structure in the continuous setting we must often thicken the cell wall, so that e.g. any ‘transverse’ tube passes through the surface Z at most D times, and thus enters at most D + 1 cells. If the tubes we are considering have thickness \\delta, then we should let the \\delta neighborhood Z_\\delta of Z be the cell wall, and let the cells be the connected components of \\mathbb{R}^d - Z_\\delta. This is because it then follows that if a tube passes through a cell of \\mathbb{R}^d - Z_\\delta, then it’s central line passes through the corresponding cell in \\mathbb{R}^d - Z, and can only do this at most D + 1 times."},"Quick-Notes/Random-Rotations-Trick":{"slug":"Quick-Notes/Random-Rotations-Trick","filePath":"Quick Notes/Random Rotations Trick.md","title":"Random Rotations Trick","links":[],"tags":[],"content":""},"Quick-Notes/Restricted-Decoupling-+-Kakeya-Implies-Restriction":{"slug":"Quick-Notes/Restricted-Decoupling-+-Kakeya-Implies-Restriction","filePath":"Quick Notes/Restricted Decoupling + Kakeya Implies Restriction.md","title":"Restricted Decoupling + Kakeya Implies Restriction","links":["Quick-Notes/The-Refined-Decoupling-Theorem"],"tags":[],"content":"Recall the The Refined Decoupling Theorem. In this note we discuss how to use this theorem, together with Kakeya type bounds, to prove Restriction Theorems. To begin with, we note that the refined decoupling theorem implies the following bound.\nTheorem: Suppose a family of tubes \\mathbb{T} can be divided into families of tubes \\mathbb{T}_\\theta which are R^{-1/2} direction separated, and \\#(\\mathbb{T}_\\theta) \\leq m for each \\theta. Then if X is a union of R^{1/2} balls, so that m(Q) \\leq M for each Q \\subset X, then\n\\| E_S f \\|_{L^p(X)} \\lessapprox R^{\\frac{n}{p} - \\frac{n-1}{2}} M^{\\frac{1}{p} \\frac{2}{n-1}} m^{1/p - 1/2} \\| f \\|_{L^p(M)}.\nProof: Applying the The Refined Decoupling Theorem, we find that\n\\| E_S f \\|_{L^p(X)}^p \\lessapprox M^{\\frac{2}{n-1}} \\sum\\nolimits_{T \\in \\mathbb{T}} \\| E_S f_T \\|_{L^p(w_R)}^p.\nNow \\| E_S f_T \\|_{L^p(w_R)}^p \\sim R^{ \\frac{p - p_{ST}}{2 - p_{ST}} } \\| f_T \\|_{L^2(M)}^p for each T \\in \\mathbb{T}, so\n\\sum\\nolimits_{T \\in \\mathbb{T}} \\| E_S f_T \\|_{L^p(w_R)}^p \\sim R^{\\frac{p - p_{ST}}{2 - p_{ST}}} \\sum\\nolimits_{T \\in \\mathbb{T}} \\| f_T \\|_{L^2(M)}^p.\nSince all the norms \\| f_T \\|_{L^2(M)} are all comparable, we have that for each \\theta,\n\\sum\\nolimits_{T \\in \\mathbb{T}_\\theta} \\| f_T \\|_{L^2(M)}^p \\sim m^{1 - p/2} \\left( \\sum\\nolimits_{T \\in \\mathbb{T}_\\theta} \\| f_T \\|_{L^2(M)}^2 \\right)^{p/2} \\sim m^{1 - p/2} \\| f_\\theta \\|_{L^2(M)}^p.\nBy H”{o}lder’s inequality, since f_\\theta is supported on a R^{-1/2} cap, we have\n\\| f_\\theta \\|_{L^2(M)}^p \\lesssim R^{- \\left( \\frac{n-1}{2} \\right) (p/2 - 1)} \\| f_\\theta \\|_{L^p(M)}^p.\nCombining these bounds gives that\n    \\| E_S f \\|_{L^p(X)}^p &amp;\\lessapprox M^{\\frac{2}{n-1}} m^{1 - p/2} R^{\\frac{p - p_{ST}}{2 - p_{ST}} - \\left( \\frac{n-1}{2} \\right) (p/2 - 1) } \\| f \\|_{L^p(M)}^p\\\\\n    &amp;= R^{n - \\left( \\frac{n-1}{2} \\right) p} M^{\\frac{2}{n-1}} m^{1 - p/2} \\| f \\|_{L^p(M)}^p.\n\\end{align}$$\n\nSo, if we can show a potential counterexample to a restriction bound is concentrated on a set $X$ upon which $M^{\\frac{2}{n-1}} m^{1 - p/2} \\lessapprox R^{ \\left( \\frac{n-1}{2} \\right) p - n }$, then we will have obtained a contradiction, thus proving the restriction bound. □\n\n*In particular, if $p = p_{ST}$ then the bound becomes*\n\n| E_S f |{L^{p{ST}}(X)} \\lesssim R^{-1/p_{ST}} (M/m)^{\\frac{1}{n+1}} | f |_{L^p(M)},\n*which will be important in a later calculation.*\n\nFor a given family of tubes $\\mathbb{T}$, controlling $M$ and $m$ simultaneously is a Kakeya type problem. If we consider a set $X$ formed from the union of $R^{1/2}$ tubes, such that $|X \\cap T| \\sim \\lambda |T|$ for each $T \\in \\mathbb{T}$, then the full Kakeya maximal conjecture implies the multiplicity of a generic $\\delta$-cube in $X$ is $O(m \\lambda^{1-n})$. So given a set $X$, after thinning $X$ appropriately we can set $M \\lesssim m \\lambda^{1-n}$ in the result above.\n\nLet us try and use this technique to obtain an extension bound. Assume that $\\| f \\|_{L^p(M)} = 1$. Consider a wave packet decomposition $f = \\sum f_{\\theta,\\nu}$ at a scale $R^{-1/2}$, and thus $E_S f = \\sum_{T \\in \\mathbb{T}} g_T$, where $T = \\{ T_{\\theta,\\nu}: f_{\\theta,\\nu} \\neq 0 \\}$. By pigeonholing, we may assume that there is $B &gt; 0$ so that $\\| f_{\\theta,\\nu} \\|_{L^\\infty(M)} \\sim B$ for all $T \\in \\mathbb{T}$. Let $X$ be a set, which we may assume to be $R^{1/2}$ discretized, we try and find $X_0 \\subset X$ with $|X_0| \\geq |X|/10$ so that $\\| E_S f \\|_{L^p(X_0)} \\lesssim 1$. We may assume $X$ is $R^{1/2}$ discretized, and by dyadic pigeonholing, we may find a dyadic scale $\\lambda$ so that $X(T) = X \\cap T$ satisfies $|X(T)| \\sim \\lambda |T|$ for some $\\lambda \\in [0,1]$ and all $T \\in \\mathbb{T}$. Because the functions $\\{ g_T \\}$ are orthogonal on $R^{1/2}$ cubes, they are also orthogonal on $X$, so\n\n| E_S f |{L^2(X)} \\lesssim \\left( \\sum | g_T |{L^2(X)}^2 \\right)^{1/2} \\sim (\\lambda R)^{1/2} \\left( \\sum | f_{\\theta,\\nu} |{L^2(M)}^2 \\right)^{1/2} = (\\lambda R)^{1/2} | f |{L^2(M)}.\n\nOn the other hand, if $p_{ST}$ is the Stein-Tomas exponent, we can find a set $X_0 \\subset X$ with $|X_0| \\geq |X|/10$ so that $M \\lesssim m \\lambda^{-(n-1)}$. If we could somehow improve this bound so we could assume $M \\lesssim m \\lambda^{- \\frac{n-1}{2}}$, then\n\n\\begin{align}\n| E_S f |{L^{p{ST}}(X_0)} &amp;\\lessapprox (M/m)^{ \\frac{1}{n+1}} R^{-\\frac{n-1}{2(n+1)}} | f |{L^{p{ST}}(X_0)}\\\n&amp;\\lessapprox (\\lambda R)^{- 1/p_{ST}} | f |{L^{p{ST}}(X_0)}\n\\end{align}\n\nInterpolating, we obtain that at the critical exponent for the restriction conjecture, i.e. for $p = 2n/(n-1)$,\n\n| E_S f |{L^p(X_0)} \\lesssim | f |{L^p(X_0)}.\n\nThis is sufficient to completely prove the restriction conjecture.\n\nIn general, we will be able to obtain square root cancellation in $\\lambda$ by forcing $X$ to satisfy a two-ends condition, and we can then use this to obtain restriction estimates. Given a set $X$ satisfying the two-ends condition, with $|X \\cap T| \\sim \\lambda |T|$ for each $T \\in \\mathbb{T}$, the bush argument of Bourgain gives that $|X| \\gtrapprox R^{\\frac{3n+1}{4}} \\lambda$, and so the average multiplicity of a cube $Q$ in $X$ is $M \\lesssim m \\lambda^{- \\frac{n-1}{n+1}} R^{-\\frac{(n-1)^2}{4(n+1)}} \\lambda^{-\\frac{n-1}{n+1}}$, which gives\n\n| E_S f |{L^{p{ST}}(X_0)} \\lessapprox R^{-\\frac{(n-1)[3n+1]}{4(n+1)^2}} \\lambda^{- \\frac{n-1}{(n+1)^2}} | f |{L^{p{ST}}}\n\nInterpolation between the $L^2$ estimate gives a result of the form\n\n| E_S f |{L^p(X_0)} \\lessapprox | f |{L^p(X_0)}\n\nfor $p = \\frac{2 + 2n(5n + 2)}{(n-1)(5n + 3)}$. In particular, for $n = 3$ this gives $p = 26/9 \\approx 2.89$."},"Quick-Notes/Shadings":{"slug":"Quick-Notes/Shadings","filePath":"Quick Notes/Shadings.md","title":"Shadings","links":["Quick-Notes/We-Can-Remove-Exceptional-Sets-From-Lp-Estimates","Quick-Notes/Random-Rotations-Trick","Problems/The-Kakeya-Maximal-Inequality"],"tags":[],"content":"Suppose we have a family of subsets \\mathbb{A} in \\mathbb{R}^n, with |A| \\sim V for each A \\in \\mathbb{A}. Suppose we are trying to prove an inequality\n\\left\\| \\sum\\nolimits_{A \\in \\mathbb{A}} 1_A \\right\\|_{L^p(\\mathbb{R}^n)} \\lesssim C. \\tag{1}\nBy real interpolation, (1) is roughly equivalent to a restricted bound of the form\n\\sum |A \\cap X| \\leq C |X|^{1/d}, \\tag{2}\nwhere d = p&#039;. By dyadic pigeonholing, we may find \\mathbb{A}&#039; \\subset \\mathbb{A} and \\lambda \\in (0,1) so that |A \\cap X| \\sim \\lambda |A| for each A \\in \\mathbb{A}&#039;, and such that \\sum_{A \\in \\mathbb{A}} |A \\cap X| \\approx \\sum_{A \\in \\mathbb{A}&#039;} |A \\cap X|. Normally we have \\# \\mathbb{A} \\lesssim V^{-1}, so that M = (\\# (\\mathbb{A}&#039;) V)^{-1} is large. Then, rearranging, we find (2) is equivalent to\n|X| \\gtrapprox \\left( \\lambda / CM \\right)^d. \\tag{3}\nWe can state this process in the language of shadings. For each A \\in \\mathbb{A}, we pick X(A) \\subset A so that X(A) \\sim \\lambda |A| for each A. Such a choice is called a \\lambda-shading. The L^p inequality we wished to prove above is equivalent to proving that for any subset \\mathbb{A}&#039; of \\mathbb{A}, and any \\lambda-shading of \\mathbb{A}&#039;, the set X = \\bigcup X(A) satisfies |X| \\gtrapprox (\\lambda / CM)^d. Thus we see that upper bounds on L^p sum of indicator functions are roughly equivalent to lower bounding the size of shadings, which is a Kakeya type problem.\nThe Generic Multiplicity of Shadings\nSuppose that each set in \\mathbb{A} is \\delta-discretized (roughly speaking, a union of \\delta balls). For each \\delta ball Q, let M(Q) denote the number of sets in \\mathbb{A} containing Q. Then Markov’s inequality, applied to (1), implies that\n\\# \\{ Q : M(Q) \\geq M_0 \\} \\leq \\delta^{-n} C^p / M_0^p. \\tag{4}\nIf X is a \\delta-discretized \\lambda-shading of \\mathbb{A}&#039;, then (3) implies that X contains at least \\delta^{-n} (\\lambda / CM)^d balls of radius \\lambda. So (3) and (4) together imply that at least half the cubes in X have multiplicity at most O( C^d (M/\\lambda)^{d - 1} ). Conversely, if (3) and (4) hold, then we can obtain inequalities of the form (1) because We Can Remove Exceptional Sets From Lp Estimates.\nThe Special Case of Tubes\nIn the special case where we are studying the Kakeya inequality, \\mathbb{A} is a family of direction separated \\delta-tubes, V = \\delta^{1-n}, and C = \\delta^{1 - n/d}, The Random Rotations Trick allows us to assume that M \\sim 1, so the The Kakeya Maximal Inequality is roughly equivalent to prove that for any family \\mathbb{T} of \\sim \\delta^{1-n} direction separated \\delta tubes, and any \\lambda-shading X of \\mathbb{T}, |X| \\gtrapprox \\lambda^d \\delta^{n-d}. In particular, at least half the cubes in any \\lambda-shading of \\mathbb{T} must have multiplicity at most O(\\delta^{d - n} \\lambda^{1-d}).\nGeometric Means\nSuppose we have proved\n\\left\\| \\left( \\sum\\nolimits_{A_1 \\in \\mathbb{A}, \\dots, A_k \\in \\mathbb{A}_k} 1_{A_1} \\cdots 1_{A_k} \\right)^{1/k} \\right\\|_{L^p(\\mathbb{R}^n)} \\lesssim C. \\tag{1}\nwhere \\mathbb{A}_1,\\dots, \\mathbb{A}_k are families of \\delta discretized sets. The analogous weak bound is that if we let M_i(Q) denote the number of elements of \\mathbb{A}_i which contain a \\delta ball Q, then for any \\delta discretized set X,\n\\sum\\nolimits_{Q \\subset X} [M_1(Q) \\cdots M_k(Q)]^{1/k} \\lesssim C.\nPigeonholing, we may assume that X is a \\lambda-shading of the set of intersections\n\\mathbb{A} = \\{ A_1 \\cap \\cdots \\cap A_k : A_1 \\in \\mathbb{A}_1, \\dots, A_k \\in \\mathbb{A}_k \\}."},"Quick-Notes/The-Polynomial-Wolff-Axioms":{"slug":"Quick-Notes/The-Polynomial-Wolff-Axioms","filePath":"Quick Notes/The Polynomial Wolff Axioms.md","title":"The Polynomial Wolff Axioms","links":["2024-12-HongWangShukunWu-RestrictionEstimatesUsingDecouplingTheoremsAndTwoEndsFurstenbergInequalities.pdf"],"tags":[],"content":"A set of \\delta-tubes \\mathbb{T} satisfy the Polynomial Wolff axioms if, for any semi-algebraic set S,\n\\# \\{ T \\in \\mathbb{T}: |T \\cap S| \\geq \\lambda |T| \\} \\lesssim |S| \\delta^{1-n} \\lambda^{-n} \\tag{1}\nwhere the implicit constants depend only on the complexity of the semi-algebraic set S. Guth, Zahl, Katz, and Rogers proved that a family of tubes pointing in a \\delta-separated family of directions satisfy the Polynomial Wolff Axioms.\nLet us say a tube T is tangent to a \\delta neighborhood S of an algebraic surface \\Sigma if |T \\cap S| \\geq 0.1 |T|. Since |S|  \\lesssim \\delta the Polynomial Wolff Axioms tell us that at most O(\\delta^{2-n}) tubes in \\mathbb{T} are tangent to the surface. If \\mathbb{T} are \\delta separated, we can have \\#(\\mathbb{T}) \\sim \\delta^{1-n}, and so the Polynomial Wolff Axioms tell us most of the tubes in \\mathbb{T} are not tangent to S.\nSuppose \\mathbb{T} contains at most m tubes in each direction. A natural question is to understand how (1) may be quantified in terms of m - this may have applications to restriction theory, e.g. to the methods of Wang and Wu."},"Quick-Notes/The-Refined-Decoupling-Theorem":{"slug":"Quick-Notes/The-Refined-Decoupling-Theorem","filePath":"Quick Notes/The Refined Decoupling Theorem.md","title":"The Refined Decoupling Theorem","links":[],"tags":[],"content":"Suppose p &gt; 2(d+1)/(d-1).\nLet S be a strictly convex, C^2 hypersurface in \\mathbb{R}^d with Gaussian curvature \\sim 1, and consider f: S \\to \\mathbb{C} that can be expanded in a wave-packet decomposition of the form f = \\sum_{T \\in \\mathbb{T}} f_T, where \\mathbb{T} is a family of R-tubes, so that f_T is supported in a radius R^{-1} neighborhood of S, and E_S f_T is essentially supported on T. Assume that the w_R norms of the functions \\{ E_S f_T: T \\in \\mathbb{T} \\} are all comparable (Equivalently, we may assume the norms of the \\{ f_T : T \\in \\mathbb{T} \\} are all comparable). Suppose X \\subset B_R is a union of a family of radius R^{1/2} balls, so that each such ball Q in the union has multiplicity m(Q) = \\# \\{ T \\in \\mathbb{T}: Q \\cap T \\neq \\emptyset \\} at most M. Then\n\\| E_S f \\|_{L^p(X)} \\lessapprox M^{\\frac{2}{n-1}} \\sum\\nolimits_{T \\in \\mathbb{T}} \\| E_S f_T \\|_{L^p(w_R)}^2."},"Quick-Notes/Wave-Packet-Decomposition-For-Extension":{"slug":"Quick-Notes/Wave-Packet-Decomposition-For-Extension","filePath":"Quick Notes/Wave Packet Decomposition For Extension.md","title":"Wave Packet Decomposition For Extension","links":["1991---Bourgain---Besicovitch-Type-Multiplier-Operators-And-Applications-To-Fourier-Analysis","1969---Fefferman---Inequalities-For-Strongly-Singular-Convolution-Operators","1982---Cordoba---Geometric-Fourier-Analysis","1991---Seeger-Sogge-Stein---Regularity-Properties-of-Fourier-Integral-Operators"],"tags":[],"content":"Given any function f supported on a compact neighborhood of a curved hypersurface \\Sigma, and each R &gt; 0, we can break \\Sigma down finitely overlapping caps \\Theta, each having dimensions R^{-1/2} tangent to \\Sigma, and dimension R^{-1} in the normal direction to \\Sigma. If, for each \\theta \\in \\Theta, we consider a family of tubes \\mathbb{T}(\\theta) pointing in the normal direction to the cap, with dimensions R^{1/2} by R, and then write \\mathbb{T} = \\bigcup \\mathbb{T}(\\theta), then we have an orthogonal decomposition f = \\sum f_T, where for T \\in \\mathbb{T}(\\theta) the following is true:\n\nf_T is supported on \\theta.\nFor x \\in B_R, E_\\Sigma f_T(x) \\approx a_T \\chi_T e^{2 \\pi i \\omega_\\theta x}, where \\omega_\\theta is the center of \\theta, |a_T| \\sim R^{-1/2} \\| f_T \\|_{L^2(\\Sigma)}., and \\chi_T is smooth and adapted to T. In particular, \\| E_\\Sigma f_T \\|_{L^2(B_R)} \\sim R^{1/2} \\| f_T \\|_{L^2(\\Sigma)}.\nThe functions E f_T are locally orthogonal on balls of radius R^{1/2}. That is, for any ball B of radius at least R^{1/2}, \\| Ef \\|_{L^2(B)} \\approx \\sum \\| Ef_T \\|_{L^2(B)}^2.\n\nThe method was widely brought to the attention by Bourgain’s use of the result in a 1991 paper (some claim he introduced the method, though it is also in use by Fefferman and Cordoba in their work on the restriction problem), and is highly similar to the second dyadic decomposition introduced in 1991 by Seeger, Sogge and Stein to analyze Fourier Integral Operators."},"Quick-Notes/We-Can-Remove-Exceptional-Sets-From-Lp-Estimates":{"slug":"Quick-Notes/We-Can-Remove-Exceptional-Sets-From-Lp-Estimates","filePath":"Quick Notes/We Can Remove Exceptional Sets From Lp Estimates.md","title":"We Can Remove Exceptional Sets From Lp Estimates","links":[],"tags":[],"content":"Suppose X_0 has finite measure, and we have to prove an inequality of the form\n\\| f \\|_{L^p(X_0)} \\lesssim C. \\tag{1}\nEquation (1) is almost equivalent to proving that for any subset X of X_0, there exists E \\subset X with |E \\cap X| \\leq 1/2 so that\n\\| f \\|_{L^p(X - E)} \\lesssim C |X|^{1/p&#039;}. \\tag{2}\nCertainly (1) implies (2) by Hölder’s inequality. Conversely, if (2) holds, then we may find E_1 so that if X_1 = X_0 - E_1, then\n\\| f \\|_{L^p(X_1)} \\lesssim C |X|^{1/p&#039;}. \\tag{3}\nIterating, for each n \\geq 1, we can apply (2) with X = X_n to find E_n \\subset X_n so that if X_{n+1} = X_n - E_n,\n\\| f \\|_{L^p(X_{n+1})} \\lesssim C |X_n|^{1/p} \\lesssim 2^{-n/p} C |X_0|^{1/p&#039;}. \\tag{4}\nApplying the triangle inequality, since X - \\bigcup X_n is measure zero, we find\n\\| f \\|_{L^p(X)} \\leq \\sum_n \\| f \\|_{L^p(X_n)} \\lesssim \\sum 2^{-n/p} C |X_0|^{1/p&#039;} \\lesssim C |X_0|^{1/p&#039;}. \\tag{5}"},"index":{"slug":"index","filePath":"index.md","title":"Multilinear Restriction","links":[],"tags":[],"content":"These are some quick notes taken to summarize progress on obtaining new estimates for multilinear restriction, potentially using the methods of Wang and Wu."}}